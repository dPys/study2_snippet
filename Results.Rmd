---
classoption: notitlepage
header-includes:
  \AtBeginDocument{\let\maketitle\relax}
  \pagenumbering{gobble}
output:
  pdf_document:
    citation_package: natbib
    keep_tex: yes
    latex_engine: xelatex
    toc: false
    fig_caption: no
    template: template.tex
  html_document: default
  css:
  - custom.css
---
```{r echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
# install.packages(c("reticulate", "devtools", "tidyverse", "Hmisc", "huxtable", "dplyr", "ggpubr", "purrr", "scales", "readr", "bestNormalize", "parcats", "stats", "haven", "easyalluvial", "MKinfer", "RColorBrewer", "gridExtra", "plyr", "ggplot2", "purrr", "sensitivity", "stringr", "rpart", "htmlTable", "rstatix", "gt", "maptree", "rattle", "fs", "ggExtra", "rpart.plot", "pracma", "car", "sjPlot", "sjmisc", "sjlabelled", "grid", "ggalluvial", "manipulateWidget", "plotly", "ggsci", "shades", "bookdown", "multisensi", "rmarkdown", "knitr", "finalfit", "kableExtra", "magrittr", "vip", "caret", "factoextra", "xfun", "data.table", "lme4", "lmerTest", "report", "MuMIn", "emmeans", "ggdark"))
# remotes::install_github("rstudio/webshot2")

library(reticulate); library(devtools); library(emmeans); library(lme4); library(lmerTest); library(report); library(MuMIn); library(tidyverse); library(Hmisc); library(huxtable); library(plyr); library(dplyr); library(ggpubr); library(purrr); library(scales); library(readr); library(bestNormalize); library(parcats); library(stats); library(haven); library(easyalluvial); library(MKinfer); library(RColorBrewer); library(gridExtra); library(ggplot2); library(purrr); library(sensitivity); library(stringr); library(rpart); library(htmlTable); library(rstatix); library(gt); library(maptree); library(rattle); library(fs); library(ggExtra); library(rpart.plot); library(pracma); library(car); library(sjPlot); library(sjmisc); library(sjlabelled); library(grid); library(ggalluvial); library(manipulateWidget); library(plotly); library(ggsci); library(shades); library(bookdown); library(multisensi); library(webshot2); library(rmarkdown); library(knitr); library(finalfit); library(kableExtra); library(magrittr); library(vip); library(caret); library(factoextra); library(data.table); library(xfun); library(ggdark)

DARK_THEME_GRAY <- theme(plot.background = element_rect(fill="black", colour = 'black'), panel.background = element_rect(fill = "#141414"), legend.key = element_rect(fill = "#0D0D0D"), panel.grid = element_line(colour = "#000000"), axis.ticks = element_line(colour = "#CCCCCC"), legend.background = element_rect(fill = "#141414"), strip.background = element_rect(fill = "#262626"), line = element_line(colour = "#FFFFFF"), rect=element_rect(fill="#000000", colour="#FFFFFF"))

root.dir = dirname(dirname(dirname(rstudioapi::getSourceEditorContext()$path)))
base_dir <- paste0(root.dir, '/Chapter_IV/')
repro_dir <- paste0(root.dir, '/Chapter_III/results')
use_python(Sys.which("/usr/local/anaconda3/bin/python"))
options(Encoding="UTF-8")
knitr::opts_chunk$set(dev = 'pdf')
data_dir <- paste0(base_dir, "data/")
results_dir <- paste0(base_dir, "results/")
setwd(base_dir)
interactive = FALSE
sys = import('sys')
sys$stdout$flush()
knitr::knit_hooks$set(crop = knitr::hook_pdfcrop)
knitr::opts_chunk$set(comment = NA, fig.path=paste(base_dir, 'figures/', sep=''), fig.show='hide', echo = FALSE, warning=FALSE, error=FALSE, strip.white = TRUE)
options(knitr.kable.NA = '')

css_text <- "
h1 {
    width:1400px;
    margin: 0 auto;
    font-weight: 400;
    text-transform: uppercase;
    font-size: 28px;
    background: black;
    display: flex;
    color: white;
    justify-content: center;
    align-items: center;
    text-align: center;
    vertical-align: bottom;
}
h2 {
    width:1400px;
    margin: 0 auto;
    font-weight: 400;
    text-transform: uppercase;
    font-size: 28px;
    background: black;
    display: flex;
    color: white;
    justify-content: center;
    align-items: center;
    text-align: center;
    vertical-align: bottom;
}
"

css <- htmltools::tags$style(type = "text/css", css_text)

Mode <- function(x) {
    ux <- unique(x)
    ux[which.max(tabulate(match(x, ux)))]
}

pergain <- function(v1, v2) {
    return(paste(round(100*((v2-v1)/v1), 2), "%", sep=''))
}

oddsfactor <- function(v1, v2) {
    return(round(1/((v2-v1)/v1)-1, 0))
}

center_apply <- function(x) {
    apply(x, 2, function(y) y - mean(y, na.rm = T))
}

ReturnTopUni <- function(df, meta, pheno) {
    val <- df %>% filter(Phenotype==pheno) %>% dplyr::select(!!as.name(meta)) %>% pull(!!as.name(meta)) %>% as.character()
return(val)
}

`%rin%` = function (pattern, list) {
     vapply(pattern, function (p) any(grepl(p, list)), logical(1L), USE.NAMES = FALSE)
}

report_f <- function(f_out, test_ix){
  f_test_out <- report_statistics(f_out)
  return(str_split(gsub(") =", paste(c(', ', as.character(round(as.numeric(str_split(report_sample(f_out, select='DenDF')[[1,2]], ' ')[[1]][1], 0))), ") ="), collapse = ''), f_test_out[[!!test_ix]]), ';')[[1]][1])
}

skew <- function(x){
  S2 <- (x - mean(x, na.rm = T))^2 %>% sum(na.rm = T) %>% 
    `/`(length(x[!is.na(x)]))
  S3 <- (x - mean(x, na.rm = T))^3 %>% sum(na.rm = T) %>% 
    `/`(length(x[!is.na(x)]))
  S3 / (S2)^(3/2)
}
kurtosis <- function(x){
  S2 <- (x - mean(x, na.rm = T))^2 %>% sum(na.rm = T) %>% 
    `/`(length(x[!is.na(x)]))
  S4 <- (x - mean(x, na.rm = T))^4 %>% sum(na.rm = T) %>%
    `/`(length(x[!is.na(x)]))
  S4 / (S2)^2 - 3
}
screen_plot <- function(x, label){
  y <- density(x)$y
  s <- skew(x)
  k <- kurtosis(x)
  p <- qplot(x, geom = "density") + theme_bw() + xlab(label) +
    annotate("text", x = max(x) - (.25 * (max(x) - min(x))),
             y = max(y) - (.25 * (max(y) - min(y))),
             label = paste("skew = ", round(s,2), "\nkurtosis = ",
                           round(k,2), sep = ""))
  print(p)
}

outlierKD <- function(dt, var) {
  var_name <- eval(substitute(var),eval(dt))
  tot <- sum(!is.na(var_name))
  na1 <- sum(is.na(var_name))
  m1 <- mean(var_name, na.rm = T)
  outlier <- boxplot.stats(var_name)$out
  mo <- mean(outlier)
  var_name <- ifelse(var_name %in% outlier, NA, var_name)
  na2 <- sum(is.na(var_name))
  m2 <- mean(var_name, na.rm = T)
  dt[as.character(substitute(var))] <- invisible(var_name)
  df <- as.character(as.list(match.call())$dt)
  return(invisible(dt))
}

colMedians <- function( x, na.rm = FALSE ) {

   if( is.data.frame( x ) ) {
      x <- as.matrix( x )
   }
   if( !is.array( x ) ) {
      stop( "argument 'x' must be a data.frame, matrix, or array" )
   }
   if( !is.numeric( x ) ) {
      stop( "argument 'x' must be numeric" )
   }

   result <- array( NA, dim = dim( x )[-1] )
   dimnames( result ) <- dimnames( x )[-1]

   for( i in 1:dim( x )[ 2 ] ) {
      if( length( dim( x ) ) == 2 ) {
         result[ i ] <- median( x[ , i ], na.rm = na.rm )
      } else {
         result[ slice.index( result, 1 ) == i ] <-
            colMedians( array( x[ slice.index( x, 2 ) == i ],
               dim = dim( x )[ -2 ] ), na.rm = na.rm )
      }
   }

   return( result )
}

rowMedians <- function( x, na.rm = FALSE ) {
   if( is.null( dim( x ) ) || length( dim( x ) ) != 2 ) {
      stop( "argument 'x' must be a matrix or a data.frame" )
   }
   return( colMedians( t( x ), na.rm = na.rm ) )
}

get_legend<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)}

one_hot <- function(dt, cols="auto", sparsifyNAs=FALSE, naCols=FALSE, dropCols=TRUE, dropUnusedLevels=FALSE){

  OHEID <- NULL
  
  # Automatically get the unordered factor columns
  if(cols[1] == "auto") cols <- colnames(dt)[which(sapply(dt, function(x) is.factor(x) & !is.ordered(x)))]
  
  # If there are no columns to encode, return dt
  if(length(cols) == 0) return(dt)
  
  # Build tempDT containing and ID column and 'cols' columns
  tempDT <- dt[, cols, with=FALSE]
  tempDT[, OHEID := .I]
  for(col in cols) set(tempDT, j=col, value=factor(paste(col, tempDT[[col]], sep="_"), levels=paste(col, levels(tempDT[[col]]), sep="_")))
  
  # One-hot-encode
  melted <- melt(tempDT, id = 'OHEID', value.factor = T, na.rm=TRUE)
  if(dropUnusedLevels == TRUE){
    newCols <- dcast(melted, OHEID ~ value, drop = T, fun.aggregate = length)
  } else{
    newCols <- dcast(melted, OHEID ~ value, drop = F, fun.aggregate = length)
  }
  
  # Fill in potentially missing rows
  newCols <- newCols[tempDT[, list(OHEID)]]
  newCols[is.na(newCols[[2]]), setdiff(paste(colnames(newCols)), "OHEID") := 0L]
  
  if(!sparsifyNAs | naCols){
    
    # Determine which columns have NAs
    na_cols <- character(0)
    for(col in cols) if(any(is.na(tempDT[[col]]))) na_cols <- c(na_cols, col)
    
    # If sparsifyNAs is TRUE, find location of NAs in dt and insert them in newCols
    if(!sparsifyNAs)
      for(col in na_cols) newCols[is.na(tempDT[[col]]), intersect(levels(tempDT[[col]]), colnames(newCols)) := NA_integer_]
    
    # If naCols is TRUE, build a vector for each column with an NA value and 1s indicating the location of NAs
    if(naCols)
      for(col in na_cols) newCols[, eval(paste0(col, "_NA")) := is.na(tempDT[[col]]) * 1L]
  }
  
  result <- cbind(dt, newCols[, !"OHEID"])
  
  # Reorder columns
  possible_colnames <- character(0)
  for(col in colnames(dt)){
    possible_colnames <- c(possible_colnames, col)
    if(col %in% cols){
      possible_colnames <- c(possible_colnames, paste0(col, "_NA"))
      possible_colnames <- c(possible_colnames, paste(levels(tempDT[[col]])))
    }
  }
  sorted_colnames <- intersect(possible_colnames, colnames(result))
  setcolorder(result, sorted_colnames)
  
  if(dropCols == TRUE) result <- result[, !cols, with=FALSE]
  
  return(result)
}

# Functional Connectome Grid-Plot
grid_plot_func <- function(df, y_name, mean_imp, grid_labs=c("Phenotype", "NetworkDefinition", "NodeGranularity", "SmoothingTolerance", "FrequencyBandwidth", "ExtractionMethod", "ConnectivityEstimator"), interactive=FALSE) {
    df <- df[,colSums(is.na(df))<nrow(df)]
    df <- df[!is.na(names(df))]
    df <- df %>% dplyr::select(!!y_name, Phenotype, network, res, smooth, hpass, extract, model)
    df <- df %>% mutate(!!y_name := replace(!!as.name(y_name), is.na(!!as.name(y_name)), mean(!!as.name(y_name), na.rm=TRUE))) %>% na.omit() %>% mutate(!!y_name := round(!!as.name(y_name), 3))
    y <- df %>% pull(y_name)
      
    grid_order <- c(y_name, grid_labs)

    names(df) <- grid_order
    
    dspace_df <- df %>%
      dplyr::select(!!y_name, all_of(grid_labs))

    y_cut <- df %>% dplyr::select(!!y_name) %>% pull(!!y_name) %>% as.data.frame() %>% pull(.)
    
    df_clust <- df %>% dplyr::select(!!y_name)
    
    set.seed(42)
    disc_clusts <- kmeans(x=df_clust, centers=3)
    centers <- disc_clusts$centers[,1]
    
    levels(dspace_df$Phenotype) <- c("Depression-Severity", "Rumination-Severity", "Depression-Persistence", "Rumination-Persistence", "Age")
    levels(dspace_df$NetworkDefinition) <- c("TN-inter", "TN-union", "TN-union")
    
    bin_labs <- c(paste0("R2 ~ ", round(centers[1], 2)[[1]]), paste0("R2 ~ ", round(centers[2], 2)[[1]]), paste0("R2 ~ ", round(centers[3], 2)[[1]], ") "))

    y_bins <- mapvalues(as.factor(disc_clusts$cluster), from=levels(as.factor(disc_clusts$cluster)), to=rbind(bin_labs))
    
    Y <- as.factor(y_bins)
    names(Y) <- seq(1:length(Y))
    
    palette <- colorRampPalette(pal_tron(alpha=0.30)(dspace_df %>% purrr::map(nlevels) %>% as.vector() %>% as.tibble() %>% max() %>% na.omit() %>% as.vector()))
    pal <- adjustcolor(palette(df %>% purrr::map(nlevels) %>% as.vector() %>% as.tibble() %>% max() %>% na.omit() %>% as.vector()), 0.15)
    
    # p <- ggscatter(mtcars, x = "wt", y = "mpg",
    #                color = "mpg")
    # p
    # p + gradient_color(pal)

    p = alluvial_model_response(pred = Y, dspace = dspace_df %>% dplyr::select(-!!y_name), imp = mean_imp, pred_train = dspace_df %>% dplyr::select(!!y_name) %>% pull(.), degree = 8, params_bin_numeric_pred = list( bins = length(centers), center = T, transform = T, scale = T), bin_labels = bin_labs, NA_label = 'NA', method='pdp', 
                                auto_rotate_xlabs=FALSE, stratum_label_size=2,
                                stratum_labels = F,
                                col_vector_flow = gray.colors(n=3, start=0.80, end=1, alpha=0.15),
                                col_vector_value = pal,
                                stratum_width = 1/7, force = TRUE) + 
      geom_label(stat ="stratum") +
      theme_minimal() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
                              panel.grid.minor = element_blank(), axis.text.y = element_blank(), 
                              axis.text.x = element_text(angle = 45, vjust=0.50, size = 13, colour="white"), 
                              plot.title = element_blank(), plot.background = element_rect(fill = "black", colour = 'black'), panel.background = element_rect(fill = "black", colour = 'black'), legend.key = element_rect(fill = "black"), legend.position='bottom', legend.direction = "horizontal", legend.title = element_blank()) +
      labs(y=toupper(y_name), title=paste('Sensitivity of', str_to_title(toupper(y_name)), 'to \nFunctional Connectome Hyperparameters', sep=' ')) +
      scale_x_discrete(limits = grid_labs, drop=FALSE, )
    p$labels$subtitle <- NULL
    p$labels$caption <- NULL
    
    p$layout$clip[p$layout$name=="panel"] <- "off"
    
    # p_grid = add_marginal_histograms(p, data_input = cbind(Y, dspace_df %>% dplyr::select(-!!y_name))
    #                                  , plot = F
    #                                  , scale = 50
    # ) %>%
    #   add_imp_plot( p = p, data_input = cbind(Y, dspace_df %>% dplyr::select(-!!y_name)))
      
   if (interactive == TRUE){
    p1<-parcats::parcats(p, dspace, marginal_histogram = FALSE, imp = FALSE, hoverinfo='probability', labelfont=list(size = 16, color = 'black'), tickfont=list(size = 14, color = 'black'))
    p1$x$layout$annotations[[6]] <- NULL
    p1$x$layout$annotations[6] <- NULL
    p1$x$traces$`imp_total\nalluvial` <- NULL
    p1$x$traces$parcats$dimensions[[1]]$label <- y_name
    p1$x$traces$parcats$hoveron <- 'color'
    p_final <- p1
   } else {
     p_final <- p
     ggsave(paste("../figures/gridsearch_func_", y_name, ".pdf", sep=''), plot = p_final, width = 20, height = 14, units = "cm", dpi = 600)
   }
   # dev.off()
    return(p_final)
}

# Structural Connectome Grid-Plot
grid_plot_dwi <- function(df, y_name, mean_imp, grid_labs=c("Phenotype", "NetworkDefinition", "NodeGranularity", "SmoothingTolerance", "MinimumFiberLength", "ExtractionMethod", "ConnectivityEstimator"), interactive=FALSE) {
    df <- df[,colSums(is.na(df))<nrow(df)]
    df <- df[!is.na(names(df))]
    df <- df %>% dplyr::select(!!y_name, Phenotype, network, res, tol, minlength, directget, model)
    df <- df %>% mutate(!!y_name := replace(!!as.name(y_name), is.na(!!as.name(y_name)), mean(!!as.name(y_name), na.rm=TRUE))) %>% na.omit() %>% mutate(!!y_name := round(!!as.name(y_name), 3))
    y <- df %>% pull(y_name)
      
    grid_order <- c(y_name, grid_labs)

    names(df) <- grid_order
    
    dspace_df <- df %>%
      dplyr::select(!!y_name, all_of(grid_labs))

    y_cut <- df %>% dplyr::select(!!y_name) %>% pull(!!y_name) %>% as.data.frame() %>% pull(.)
    
    df_clust <- df %>% dplyr::select(!!y_name)
    
    set.seed(42)
    disc_clusts <- kmeans(x=df_clust, centers=3)
    centers <- disc_clusts$centers[,1]

    levels(dspace_df$Phenotype) <- c("Depression-Severity", "Rumination-Severity", "Depression-Persistence", "Rumination-Persistence", "Age")
    levels(dspace_df$NetworkDefinition) <- c("TN-inter", "LN-dorsal")
    
    bin_labs <- c(paste0("R2 ~ ", round(centers[1], 2)[[1]]), paste0("R2 ~ ", round(centers[2], 2)[[1]]), paste0("R2 ~ ", round(centers[3], 2)[[1]], ") "))
    
    y_bins <- mapvalues(as.factor(disc_clusts$cluster), from=levels(as.factor(disc_clusts$cluster)), to=rbind(bin_labs))
    
    Y <- as.factor(y_bins)
    names(Y) <- seq(1:length(Y))
    
    palette <- colorRampPalette(pal_tron(alpha=0.30)(dspace_df %>% purrr::map(nlevels) %>% as.vector() %>% as.tibble() %>% max() %>% na.omit() %>% as.vector()))
    pal <- adjustcolor(palette(df %>% purrr::map(nlevels) %>% as.vector() %>% as.tibble() %>% max() %>% na.omit() %>% as.vector()), 0.15)
    
    # p <- ggscatter(mtcars, x = "wt", y = "mpg",
    #                color = "mpg")
    # p
    # p + gradient_color(pal)

    p = alluvial_model_response(Y, dspace_df %>% dplyr::select(-!!y_name), imp = mean_imp, pred_train = dspace_df %>% dplyr::select(!!y_name) %>% pull(.), degree = 7, params_bin_numeric_pred = list( bins = length(centers), center = T, transform = T, scale = T), bin_labels = bin_labs, NA_label = 'NA', method='pdp', 
                                auto_rotate_xlabs=FALSE, stratum_label_size=2,
                                stratum_labels = F,
                                col_vector_flow = gray.colors(n=3, start=0.80, end=1, alpha=0.20),
                                col_vector_value = pal,
                                stratum_width = 1/7, force = TRUE) + 
      geom_label(stat ="stratum") +
      theme_minimal() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
                              panel.grid.minor = element_blank(), axis.text.y = element_blank(), 
                              axis.text.x = element_text(angle = 45, vjust=0.50, size = 13, colour="white"), 
                              plot.title = element_blank(), plot.background = element_rect(fill = "black", colour = 'black'), panel.background = element_rect(fill = "black", colour = 'black'), legend.key = element_rect(fill = "black"), legend.position='bottom', legend.direction = "horizontal", legend.title = element_blank()) +
      labs(y=toupper(y_name), title=paste('Sensitivity of', str_to_title(toupper(y_name)), 
                                          'to \nStructural Connectome Hyperparameters', sep=' ')) +
      scale_x_discrete(limits = grid_labs, drop=FALSE, )
    p$labels$subtitle <- NULL
    p$labels$caption <- NULL
    
    p$layout$clip[p$layout$name=="panel"] <- "off"
    
    # p_grid = add_marginal_histograms(p, data_input = cbind(Y, dspace_df %>% dplyr::select(-!!y_name))
    #                                  , plot = F
    #                                  , scale = 50
    # ) %>%
    #   add_imp_plot( p = p, data_input = cbind(Y, dspace_df %>% dplyr::select(-!!y_name)))
    
   if (interactive == TRUE){
    p1<-parcats::parcats(p, dspace, marginal_histogram = FALSE, imp = FALSE, hoverinfo='probability', labelfont=list(size = 16, color = 'black'), tickfont=list(size = 14, color = 'black'))
    p1$x$layout$annotations[[6]] <- NULL
    p1$x$layout$annotations[6] <- NULL
    p1$x$traces$`imp_total\nalluvial` <- NULL
    p1$x$traces$parcats$dimensions[[1]]$label <- y_name
    p1$x$traces$parcats$hoveron <- 'color'
    p_final <- p1
   } else {
     p_final <- p
     ggsave(paste("../figures/gridsearch_dwi_", y_name, ".pdf", sep=''), plot = p_final, width = 20, height = 14, units = "cm", dpi = 600)
   }
   # dev.off()
  return(p_final)
}

KS_sensitivity <- function(df, y_name, factors) {
  meta_ks_D_list = list()
  i = 1
  for (meta in factors) {
    pairs <- combn(levels(as.factor(df %>% dplyr::select(!!meta) %>% pull(!!meta))), 2, paste, collapse="-")
    D.vect <- vector(length=length(pairs))
    j = 1
    for (pair in pairs) {
      group1 <- df %>% filter(!!rlang::sym(meta) == strsplit(pair, "-")[[1]][1]) %>% pull(!!y_name)
      group2 <- df %>% filter(!!rlang::sym(meta) == strsplit(pair, "-")[[1]][2]) %>% pull(!!y_name)
      out1 <- ks.test(group1, group2)
      D.vect[j] <- out1$statistic
      j = j + 1
      gc()
    }
    meta_ks_D_list[[factors[i]]] <- median(D.vect, na.rm=TRUE)
    i = i + 1
    gc()
  }
  df_ks <- data.frame(meta_ks_D_list)
  return (df_ks)
}

cv_decision_tree_func <- function(df, y_name) {
      df$FrequencyBandwidth <- factor(df$hpass)
      df$SmoothingTolerance <- factor(df$smooth)
      df$Granularity <- factor(df$res)
      df$ExtractionMethod <- factor(df$extract)
      df$ConnectivityModel <- factor(df$model)
      df$NetworkDefinition <- factor(df$network)
      
      df <- df %>% dplyr::select(grid, SmoothingTolerance, FrequencyBandwidth, ExtractionMethod, ConnectivityModel, Granularity, NetworkDefinition, y_name) %>% na.omit()
      
      y <- df %>% pull(y_name)
      
      factors<-c("SmoothingTolerance", "FrequencyBandwidth", "ExtractionMethod", "ConnectivityModel", "Granularity", "NetworkDefinition")
          
      f <- as.formula(
      paste(y_name, 
            paste(factors, collapse = " + "), 
            sep = " ~ "))
      
      tree_fit <- train(f, data = df, method = "rpart", preProcess = c("center", "scale"), trControl = trainControl(method = "repeatedcv", repeats = 3, number = 10), tuneLength = 20)
      tree_fit_res <- list(tree_fit, df)
      return (tree_fit_res)
}

cv_decision_tree_dwi <- function(df, y_name) {
      df$MinFiberLength <- factor(df$minlength)
      df$SmoothingTolerance <- factor(df$tol)
      df$Granularity <- factor(df$res)
      df$ExtractionMethod <- factor(df$directget)
      df$DiffusionConnectivityModel <- factor(df$model)
      df$NetworkDefinition <- factor(df$network)
      
      df <- df %>% dplyr::select(grid, SmoothingTolerance, MinFiberLength, ExtractionMethod, DiffusionConnectivityModel, Granularity, NetworkDefinition, y_name) %>% na.omit()
      
      y <- df %>% pull(y_name)
      
      factors<-c("SmoothingTolerance", "MinFiberLength", "ExtractionMethod", "DiffusionConnectivityModel", "Granularity", "NetworkDefinition")
          
      f <- as.formula(
      paste(y_name, 
            paste(factors, collapse = " + "), 
            sep = " ~ "))
      tree_fit <- train(f, data = df, method = "rpart", preProcess = c("center", "scale"), trControl = trainControl(method = "repeatedcv", repeats = 3, number = 10, returnResamp = "all"), tuneLength = 20)
      tree_fit_res <- list(tree_fit, df)
      return (tree_fit_res)
}

force_bind = function(df1, df2) {
    colnames(df2) = colnames(df1)
    bind_rows(df1, df2)
}

violin_boxplot <- function(dat, x, y, method, paired, title, 
                           facet=NULL, ID_COL="boot", null=FALSE){
  if (null == TRUE) {
    FILL="black"
    ALPHA="0.00001"
    PALETTE='black'
    PALETTE_alpha = 0.00001
    BACKGROUND_color = "#000000"
  } else {
    FILL="black"
    ALPHA="0.5"   
    PALETTE='tron'
    PALETTE_alpha = 0.50
    BACKGROUND_color = "#000000"
    #BACKGROUND_color = "#ffffff"
  }
  for (i in y) {
    for (j in x) {
      ifelse(paired == TRUE,
        p <- ggpaired(dat,
          x = colnames(dat[j]), y = colnames(dat[i]),
          color = colnames(dat[j]),
          fill='black',
          palette = 'tron',
          line.color = 'lightgrey',
          line.size = 0.1,
          point.size = 1,
          width = 0.25,
          legend = "none",
          xlab = gsub('_', ' ', colnames(dat[j])),
          ylab = colnames(dat[i]),
          add = "jitter",
          title = title,
          facet.by = facet,
          id = ID_COL,
          add.params = list(alpha=ALPHA)
        ) + DARK_THEME_GRAY + 
          theme(
    plot.title = element_text(hjust = 0.5, size = 12, colour="white"),
    axis.text=element_text(size=8, colour="white"), 
    strip.text.x = element_text(size = 10, colour="white"),
    strip.text.y = element_text(size = 10, colour="white"),
    axis.title = element_text(size=10, colour="white"), 
    plot.background = element_rect(fill = "black", colour = 'black'), 
    panel.border=element_blank(), legend.position='none') + 
      scale_fill_tron(alpha=0.50),
        p <- ggviolin(dat,
          x = colnames(dat[j]), y = colnames(dat[i]),
          color = colnames(dat[j]),
          fill = colnames(dat[j]),
          palette = PALETTE,
          alpha = ALPHA,
          legend = "none",
          add = "jitter",
          title = title,
          add.params = list(alpha=0.1)
        ) + DARK_THEME_GRAY + 
      geom_boxplot(color='black', alpha=0.6, width=0.2) +
      theme(plot.title = element_text(size = 12, hjust = 0.5, colour="white"), 
            axis.text=element_text(size=12, colour="white"), 
            axis.title = element_text(size=14, colour="white"), 
            plot.background = element_rect(fill = "black", colour = 'black'), 
            panel.background = element_rect(fill = "black"), 
            legend.key = element_rect(fill = "black"),
            panel.border=element_blank())
      )
      gc()
    }
    gc()
  }
  if (null == TRUE) {
    p <- p + scale_fill_grey(start = 0, end = .01) + 
      theme(axis.text.x=element_text(colour="lightgrey"), 
            legend.text=element_text(colour="lightgrey"), 
            axis.text.y=element_text(colour="lightgrey"), 
            axis.title.x=element_text(colour="lightgrey"), 
            axis.title.y=element_text(colour="lightgrey")) + 
      geom_boxplot(alpha=0.0000000001, colour="lightgrey", 
                   width = 0.25, outlier.shape = 19, outlier.size = 1.5, 
                   outlier.stroke = 0.5, fill = "lightgrey", 
                   outlier.alpha = 0.0000000001) + 
      geom_point(alpha=0.0000000001, colour="lightgrey")
    p$layers[[3]] <- NULL
    p$layers[[1]]$geom_params$outlier.colour <- "lightgrey"
    p$layers[[1]]$geom_params$outlier.alpha <- 0.0000000001
    p$layers[[3]]$geom_params$outlier.colour <- "lightgrey"
    p$layers[[3]]$geom_params$outlier.alpha <- 0.0000000001
    
  } else {
    p <- p + scale_fill_tron(alpha=PALETTE_alpha)
    p$layers[[3]]$geom_params$alpha <- 0.50
    p$layers <- c(p$layers[[2]], p$layers[[1]], p$layers[[3]])
  }
  return(p)
}
      
vio_plot <- function(df, X_var, Y_var, x_lab, y_lab, col_scheme) {
  x.var <- rlang::sym(X_var)
  y.var <- rlang::sym(Y_var)
  
  point_color = 'white'
  
  x_lab <- str_trim(gsub('([[:upper:]])', ' \\1', x_lab))
  
  X_levs = levels(as.list(unique(as.vector(df %>% dplyr::select(X_var))))[[1]])
  Y_levs = levels(as.list(unique(as.vector(df %>% dplyr::select(Y_var))))[[1]])
  
  out_vio <- ggplot(data = df, aes(x = !! x.var, y = !! y.var, fill = !! x.var)) +
     geom_violin(alpha=0.4, trim = FALSE) +
     geom_point( shape = 21, size=0.1, position = position_jitterdodge(), 
                 color= point_color, alpha=0.85)+
    scale_fill_manual(
      values = saturation(col_scheme, seq(from = 0.3, to = 1, 
                                          length.out = length(X_levs) + 6)))+
     DARK_THEME_GRAY +
     ylab(c(y_lab)) +
     xlab(c(x_lab)) +
     geom_boxplot(color='white', alpha=0.7, width=0.2) +
     theme(axis.ticks = element_line(size=0.1,color="white"),
           axis.ticks.length = unit(0.1,"cm"), 
           legend.title = element_text(size=14, colour="white"), 
           plot.title = element_blank(),
           text =  element_text(size=12, colour="white"), 
           legend.text = element_text(size=12, colour="white"), 
           plot.margin = unit(c(3,2,3,3), "cm"),
           axis.text.x = element_text(size=10, colour="white"), 
           axis.text.y = element_text(size=10, colour="white"), 
           axis.title.x = element_text(size=12, vjust=-0.30, colour="white"), 
           axis.title.y = element_text(size=12, angle=90, vjust=0.85, 
                                       colour="white"))
  return(out_vio)
}

grid_plot_multi <- function(df, metaparams, color_order, y_name, title=NULL) {
  
      if ("hpass" %in% colnames(df)){
          df <- dplyr::rename(df, NetworkDefinition = network)
          df <- dplyr::rename(df, SmoothingTolerance = smooth)
          df <- dplyr::rename(df, FrequencyBandwidth = hpass)
          df <- dplyr::rename(df, ExtractionMethod = extract)
          df <- dplyr::rename(df, ConnectivityEstimator = model)
          df <- dplyr::rename(df, NodeGranularity = res)
      } else if ("minlength" %in% colnames(df)){
          df <- dplyr::rename(df, NetworkDefinition = network)
          df <- dplyr::rename(df, SmoothingTolerance = tol)
          df <- dplyr::rename(df, MinimumFiberLength = minlength)
          df <- dplyr::rename(df, ExtractionMethod = directget)
          df <- dplyr::rename(df, ConnectivityEstimator = model)
          df <- dplyr::rename(df, NodeGranularity = res) 
      }
      
      if (is.null(title)) {
          title <- str_trim(gsub("([[:lower:]])([[:upper:]])", "\\1 \\2", y_name))
      }
      
      meta_param_ics <- list()
      
      if (color_order == 1){
          color_scheme_vec <- pal_tron(alpha=0.9)(7)
      } else if (color_order == 2){
        color_scheme_vec <- rev(pal_tron(alpha=0.9)(7))
      }
      
      i = 1
      letters <- c("A", "B", "D", "E", "F", "G", "H", "I", "J")
      for (metaparam in metaparams){
      sens <- KS_sensitivity(df, y_name, metaparam)[[1]]
      plt_init <- vio_plot(df, metaparam,
                          y_name, 
                          metaparam, y_name, 
                          color_scheme_vec[1])
      if (sens < 0.15) {
        # plt_init$layers[[3]] <- NULL
        # plt_init$layers[[2]] <- NULL
        # plt_init$layers[[1]]$aes_params$alpha <- 0.075
        # plt_init <- plt_init + scale_fill_grey(start = 0, end = .01) + theme(axis.text.x=element_text(colour="lightgrey"), legend.text=element_text(colour="lightgrey"), axis.text.y=element_text(colour="lightgrey"), axis.title.x=element_text(colour="lightgrey"), axis.title.y=element_text(colour="lightgrey")) + geom_violin(alpha=0.0000000001, colour="lightgrey", trim = FALSE)
        next
      }
      meta_param_ics[[paste0("element", i)]] <- plt_init + labs(tag = letters[[i]], colour = "white")
      i = i + 1
      }
      plt <- list(do.call(c, list(lapply(meta_param_ics, "+", theme(plot.margin=ggplot2::margin(30,30,30,30))))))
      #plt <- do.call(grid.arrange, list(grobs=plt[[1]], nrow = length(meta_param_ics), ncol=1, top = grobTree( rectGrob(gp=gpar(fill_color = "black", size = 0.2)), textGrob(title, gp=gpar(fontsize=16, col="white", fontface="bold"))))
      
      grid.newpage()
      grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
      plt <- do.call(grid.arrange, list(grobs=plt[[1]], ncol=1, vp=viewport(height=0.9, y = unit(0.45, "npc")), top = grobTree( rectGrob(gp=gpar(fill="black", color = "black", size = 0.2)), textGrob(title, gp=gpar(fontsize=16, col="white", fontface="bold")))))
      grid.draw(plt)
      grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
      grid.draw(plt)

      return(plt)
}

clean_grid_col <- function(df){
  df$grid <- gsub('\\(', '', df$grid)
  df$grid <- gsub('\\)', '', df$grid)
  df$grid <- gsub(', ', '_', df$grid)
  df$grid <- gsub('\'', '', df$grid)
  df$grid <- gsub('40_', '30_', df$grid)
  df$grid <- gsub('20_', '30_', df$grid)
  df$grid <- gsub('kmeans_', 'TN_intersection_', df$grid)
  df$grid <- gsub('inter_', 'TN_intersection_', df$grid)
  df$grid <- gsub('triple_', 'TN_union_', df$grid)
  df$grid <- gsub('language_', 'LN_dorsal_', df$grid)
  df$grid <- gsub('77', '200', df$grid)
  df$grid <- gsub('135', '400', df$grid)
  df$grid <- gsub('180', '600', df$grid)
  df$grid <- gsub('228', '800', df$grid)
  df$res <- gsub('77', '200', df$res)
  df$res <- gsub('135', '400', df$res)
  df$res <- gsub('180', '600', df$res)
  df$res <- gsub('228', '800', df$res)
  if (any(grepl("minlength", colnames(df)))){
    df$minlength <- gsub(50, 30, df$minlength)
    df$minlength <- as.factor(gsub('50', '30', df$minlength))
    df$minlength <- gsub(40, 30, df$minlength)
    df$minlength <- as.factor(gsub('40', '30', df$minlength))
    df$minlength <- gsub(20, 30, df$minlength)
    df$minlength <- as.factor(gsub('20', '30', df$minlength))
  }
  df$network <- gsub('kmeans', 'TN_intersection', df$network)
  df$network <- gsub('triple', 'TN_union', df$network)
  df$network <- gsub('language', 'LN_dorsal', df$network)
  df$network <- gsub('TN_TN_', 'TN_', df$network)  
  df$network <- gsub('LN_TN_', 'LN_', df$network)  
#  if (any(grepl("Rsquared", colnames(df)))){
#    df <- df %>% dplyr::rename(Score = Rsquared)
#  }
#  if (any(grepl("MSE", colnames(df)))){
#    df <- df %>% dplyr::rename(Error = MSE)
#  }
  if (any(grepl("embedding_type", colnames(df)))){
    df <- df %>% dplyr::rename(embedding = embedding_type)
  }
  return(df)
}

join_cols_by_grid <- function(df1, df2){
  df_joined <- df1 %>% full_join(df2, by = "grid", keep=TRUE) %>% 
    rename_at(vars(ends_with(".x")), ~str_replace(., "\\..$","")) %>% 
    select_at(vars(-ends_with(".y"))) %>% distinct(grid, .keep_all = TRUE)
  return(df_joined)
}

add_spaces = function(inames) {
  library(stringr)
  uppers = str_locate_all(inames, '[A-Z]')
  w = sapply(uppers, nrow)==2
  pos = sapply(uppers[w], function(x) x[2,1])
  inames[w] = mapply(function(x,y) {
    paste(substr(x, 1, y-1), substr(x, y, nchar(x)))
  }, inames[w], pos)
  return(inames)
}

get_legend<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)}

grid_arrange_shared_legend <- function(..., nrow = 1, ncol = length(list(...)), position = c("bottom", "right"), title=NULL) {
  require(ggplot2)
  require(gridExtra)
  require(grid)
  plots <- list(...)
  position <- match.arg(position)
  g <- ggplotGrob(plots[[1]] + theme(legend.position = position, plot.background = element_rect(color="black", fill="black"), legend.title = element_text(size=14, colour="white"), legend.text = element_text(size=12, colour="white"), legend.background = element_rect(color="black")))$grobs
  legend <- g[[which(sapply(g, function(x) x$name) == "guide-box")]]
  lheight <- sum(legend$height)
  lwidth <- sum(legend$width)
  gl <- lapply(plots, function(x) x + theme(legend.position = "none"))
  gl <- c(gl, nrow = nrow, ncol = ncol)
  
  combined <- switch(position,
                     "bottom" = arrangeGrob(do.call(arrangeGrob, gl),
                                            legend,
                                            ncol = 1,
                                            heights = unit.c(unit(1, "npc") - lheight, lheight), top = grobTree( rectGrob(gp=gpar(fill="black", color = "black", size = 0.2)), textGrob(title, gp=gpar(fontsize=24, col="white", fontface="bold")))),
                     "right" = arrangeGrob(do.call(arrangeGrob, gl),
                                           legend,
                                           ncol = 2,
                                           widths = unit.c(unit(1, "npc") - lwidth, lwidth)), top = grobTree( rectGrob(gp=gpar(fill="black", color = "black", size = 0.2)), textGrob(title, gp=gpar(fontsize=24, col="white", fontface="bold"))))

  grid.newpage()
  grid.draw(grobTree(rectGrob(gp=gpar(fill="black", lwd = 0))))
  grid.draw(combined)
  return(combined)
}

```

```{r eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
if (file.exists(paste(root.dir, "/../AllCache_frequentist.RData", sep = ''))) load(paste(root.dir, "/../AllCache_frequentist.RData", sep = ''))
```

# (Part I) Learning a Depression-Persistent Connectotype
```{python eval=FALSE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
## Prepare dataframes
source_file_path = '/home/dpys/Documents/Dissertation/Chapter_IV/data/tuning_set'

import pandas as pd
import seaborn as sns
from pynets.core.utils import flatten
import os
import ast
import numpy as np
import json
import scipy.stats as st
from collections import Counter
from sklearn.preprocessing import MinMaxScaler, StandardScaler

def dist_fit(data, dist_names):
    data = reject_outliers(data)
    x = np.arange(len(data))
    size = len(data)
    #sc=StandardScaler(with_$R^{2}$=False)
    sc=MinMaxScaler(feature_range=(0.0001, 1))
    sc.fit(data.reshape(-1, 1))
    data_std = sc.transform(data.reshape(-1, 1))
    #data_std = data
    data_std = data_std.flatten()
    data_std = data_std[~np.isnan(data_std)]
    
    # Set up 50 bins for chi-square test
    # Observed data will be approximately evenly distrubuted aross all bins
    percentile_bins = np.linspace(0,100,51)
    percentile_cutoffs = np.percentile(data_std, percentile_bins)
    observed_frequency, bins = (np.histogram(data_std, bins=np.round(percentile_cutoffs, 6)))
    cum_observed_frequency = np.nancumsum(observed_frequency)
    
    chi_square = []
    p_values = []
    # Loop through candidate distributions
    for distribution in dist_names:
        # Set up distribution and get fitted distribution parameters
        dist = getattr(st, distribution)
        param = dist.fit(data_std)
        
        # Obtain the KS test P statistic, round it to 5 decimal places
        p = st.kstest(data_std, distribution, args=param)[1]
        p = np.around(p, 5)
        p_values.append(p)    
        
        # Get expected counts in percentile bins
        # This is based on a 'cumulative distrubution function' (cdf)
        cdf_fitted = dist.cdf(percentile_cutoffs, *param[:-2], loc=param[-2], 
                              scale=param[-1])
        expected_frequency = []
        for bin in range(len(percentile_bins)-1):
            expected_cdf_area = cdf_fitted[bin+1] - cdf_fitted[bin]
            expected_frequency.append(expected_cdf_area)
        
        # calculate chi-squared
        expected_frequency = np.array(expected_frequency) * size
        cum_expected_frequency = np.cumsum(expected_frequency)
        ss = np.nansum(((cum_expected_frequency - cum_observed_frequency)**2) / cum_observed_frequency)
        chi_square.append(ss)
            
    # Collate results and sort by goodness of fit (best at top)
    results = pd.DataFrame()
    results['Distribution'] = dist_names
    results['chi_square'] = chi_square
    results['p_value'] = p_values
    results.sort_values(['chi_square'], inplace=True)
    
    dist_name = results['Distribution'].iloc[0:1].values[0]
    # Set up distribution and store distribution paraemters
    dist = getattr(st, dist_name)
    param = dist.fit(data_std, floc=0)
    
    if dist_name == 'lognorm':
        shape, loc, scale = param
        param = np.log(scale), shape #mu, sigma
    elif dist_name == 'beta':
        a, b, loc, scale = param
        param = a, b #a, b
    elif dist_name == 'gamma':
        a, loc, scale = param
        param = a, 1/scale
    elif dist_name == 'normal':
        shape, loc, scale = param      
    return dist_name, param

def reject_outliers(data, m = 3.):
    d = np.abs(data - np.median(data))
    mdev = np.median(d)
    s = d/mdev if mdev else 0.
    return data[s<m]
    
def conform_tup_order(g):
    idx=[4,0,1,2,3,5]
    a = np.array(ast.literal_eval(g))
    return tuple(a[idx])

def eval_code(code):
    parsed = ast.parse(code, mode='eval')
    fixed = ast.fix_missing_locations(parsed)
    compiled = compile(fixed, '<string>', 'eval')
    ast.literal_eval(compiled)
    
def get_hyperparams(g_list, n_samples):
    # Filter out hyperparams for any failed models
    g_list = [i for i in g_list if '0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0' not in i and '1e-08' not in i]
    
    if len(g_list) == 0:
        return [], []
        
    out = [[ast.literal_eval(str(i).split('betas=')[1].split('_')[0]) for i in g_list], [float(str(i).split('intercept=')[1].split('_')[0]) for i in g_list], [float(str(i).split('lambda1=')[1].split('_')[0]) for i in g_list], [float(str(i).split('lambda2=')[1].split('_')[0]) for i in g_list], [float(str(i).split('alpha-')[1].split('_')[0]) for i in g_list], [float(str(i).split('l1ratio-')[1].split('_')[0]) for i in g_list]]
    
    df = pd.DataFrame(out).T 
   
    # Reconstruct the betas and the intercept from the coefficients and the regul. strength
    df_weights = pd.DataFrame(np.array([df[0].tolist()[0]])).T 
    df_weights.columns = ['w'+str(x) for x in range(1,len(df[0].tolist())+1)]
    betas = df_weights
    intercept = df[1]
    
    #df['L2'] = (1. / df[4]) * (1 - df[5]) * n_samples
    #df['L1'] = (1. / df[4]) * df[5] * n_samples
    #betas = pd.concat([(0.5 * df['L2'] * (df_weights[w])**2) + (df['L1'] * (df_weights[w])) for w in df_weights.columns], axis=1)
    #intercept = (0.5 * df['L2'] * (df[1])**2) + (df['L1'] * (df[1]))
    return betas, intercept
        
def get_best_distribution(data, dist_names):
    if len(data) > 0:
        if isinstance(data, pd.DataFrame):
            df = data
            best_dists = []
            for i in data.columns:
                best_dists.append(dist_fit(np.array(df[i].values), dist_names)[0])
            c = Counter(best_dists)
            comm_dist = c.most_common(1)[0][0]
            indices = [i for i, x in enumerate(best_dists) if x == comm_dist]
            return dist_fit(np.array(df[df.columns[indices].tolist()].values), dist_names)
        else:
            return dist_fit(data.reshape(1, -1), dist_names)
    else:
        return None, None

def preparare_grid_dfs(fname, source_file_path, metaparams):
    if not os.path.isfile(f"{source_file_path}/{fname}.csv"):
        raise FileNotFoundError(f"File {source_file_path}/{fname}.csv not found!")
    frame = pd.read_csv(f"{source_file_path}/{fname}.csv", index_col=False)
    if "Unnamed: 0" in frame.columns:
        frame.drop(frame.filter(regex="Unnamed: 0"), axis=1, inplace=True)
    if 'Score' in frame.columns:
        frame.loc[frame['Score'].isnull(), 'Score'] = frame[['Score_95CI_lower', 'Score_95CI_upper']].mean(axis=1)
    if 'Error' in frame.columns:
        frame.loc[frame['Error'].isnull(), 'Error'] = frame[['Error_95CI_lower', 'Error_95CI_upper']].mean(axis=1)

    df_grid = frame.dropna(axis=1, how='all')
    df_best_est = df_grid.copy()
    
    df_grid['grid'] = df_grid['grid'].str.replace('77', '200')
    df_grid['grid'] = df_grid['grid'].str.replace('135', '400')
    df_grid['grid'] = df_grid['grid'].str.replace('180', '600')
    df_grid['grid'] = df_grid['grid'].str.replace('228', '800')
    
    try:
        df_grid[metaparams] = pd.DataFrame([eval(i) for i in df_grid['grid'].tolist()], index=df_grid.index)
    except:
        df_grid[metaparams[1:]] = pd.DataFrame([eval(i) for i in df_grid['grid'].tolist()], index=df_grid.index)
    df_grid['grid'] = df_grid['grid'].apply(conform_tup_order)
    
    df_grid.lp_importance = df_grid.lp_importance.values[0].replace('\n','').replace(' ',', ')

    df_best_final = df_grid.copy()
    
    df_best_final['Score_mean'] = df_best_final.Score.apply(lambda x: np.nanmean([float(i) for i in str(x.replace('\n', '').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ', ').replace(', ]', ']').replace('[ ', '[').replace('  ', ' ').replace(',,,', ',').replace(',,', ',').replace('[','').replace(']','')).split(', ')]))

    df_best_final['Score_std'] = df_best_final.Score.apply(lambda x: np.nanstd([float(i) for i in str(x.replace('\n', '').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ', ').replace(', ]', ']').replace('[ ', '[').replace('  ', ' ').replace(',,,', ',').replace(',,', ',').replace('[','').replace(']','')).split(', ')]))

    df_best_final['Error_mean'] = df_best_final.Error.apply(lambda x: np.nanmean([float(i) for i in str(x.replace('\n', '').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ', ').replace(', ]', ']').replace('[ ', '[').replace('  ', ' ').replace(',,,', ',').replace(',,', ',').replace('[','').replace(']','')).split(', ')]))

    df_best_final['Error_std'] = df_best_final.Error.apply(lambda x: np.nanstd([float(i) for i in str(x.replace('\n', '').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ', ').replace(', ]', ']').replace('[ ', '[').replace('  ', ' ').replace(',,,', ',').replace(',,', ',').replace('[','').replace(']','')).split(', ')]))
    
    df_scores = pd.DataFrame(df_grid.T.iloc[6])
    df_scores_list = df_scores['Score'].values.tolist()
    df_scores_new = pd.DataFrame([pd.Series([float(i) for i in df_scores_list[j].replace('[','').replace(']','').split(', ')]) for j in range(len(df_scores_list))]).T
    
    sc=MinMaxScaler(feature_range=(0, 1))
    best_recipe_ixs = [i for i in pd.Series(sc.fit_transform(np.array(df_scores_new.mean()/df_scores_new.std().values).reshape(-1, 1)).T.flatten()).argsort()[-200:][::-1].values.tolist() if i > 0]
    #    df_scores_new.mean().argsort()[-10:][::-1].values.tolist()

    best_ests = []
    for best_recipe_ix in best_recipe_ixs:
        df = df_best_est.iloc[[best_recipe_ix]][['best_estimator', 'Predicted_y']]
        num_obs = len(ast.literal_eval(df['Predicted_y'].values.tolist()[0].replace('\n', '').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ', ').replace(', ]', ']').replace('[ ', '[').replace('  ', ' ').replace(',,,', ',').replace(',,', ','). replace('[, ', '[')))
        est_list = ast.literal_eval(df['best_estimator'].values.tolist()[0].replace('\n', '').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ', ').replace(', ]', ']').replace('[ ', '[').replace('  ', ' ').replace(',,,', ',').replace(',,', ','). replace('[, ', '['))
        df_best_est_p = pd.DataFrame(est_list, columns=['best_estimator'])
        df_out = pd.concat([df_best_est_p, df_scores_new[best_recipe_ix]], axis=1)
        df_out = df_out.loc[df_out[best_recipe_ix]>0.20]
        df_out = df_out.loc[~df_out.best_estimator.str.contains('1e-08')]
        df_out = df_out.reset_index(drop=True)
        best_ests.append(df_out['best_estimator'])
    
    df_best_est_p_all = pd.DataFrame(pd.concat(best_ests, axis=0))
    df_best_est_p_all = df_best_est_p_all.reset_index(drop=True)

    best_hyp_tups = []
    for index, row in df_best_est_p_all.iterrows():
        est = df_best_est_p_all.iloc[[index]].values.tolist()[0]
        print(est)
        if len(set([ast.literal_eval(est[0].split('betas=')[1].split('_')[0])])) == 0:
            continue
        outy = get_hyperparams(est, n_samples=num_obs)
        if len(outy[0]) == 0:
            continue
        best_hyp_tups.append(outy)
    
    if len(best_hyp_tups) == 0:
        df_best_final.to_csv(f"{source_file_path}/{fname}_clean.csv", index=False)
        print(f"Final File: {source_file_path}/{fname}_clean.csv")
        return [], [], [], []
        
    best_hyp_tups = [i for i in best_hyp_tups if i[0].empty is False]
    betas = pd.concat([i[0] for i in best_hyp_tups])
    betas = betas[~np.all(betas == 0, axis=1)]
    #betas = pd.DataFrame(betas.replace(0, np.nan).median()).T
    intercepts = pd.DataFrame([i[1].values.tolist()[0] for i in best_hyp_tups]).values

    if 'func' in fname:
        dist_names = ['norm', 'uniform']
    else:
        dist_names = ['norm', 'uniform']
    beta_prior_dist, beta_prior_params = get_best_distribution(betas.dropna(axis=1), dist_names)
    
    if 'dwi' in fname:
        dist_names = ['norm', 'uniform']
    else:
        dist_names = ['norm', 'uniform']
    intercept_prior_dist, intercept_prior_params = get_best_distribution(intercepts, dist_names)

    print(f"Mean Intercept: {np.nanmean(intercepts)}")
    print(f"Mean Beta: {np.nanmean(betas)}")

    df_best_final.to_csv(f"{source_file_path}/{fname}_clean.csv", index=False)
    print(f"Final File: {source_file_path}/{fname}_clean.csv")
    
    return beta_prior_dist, beta_prior_params, intercept_prior_dist, intercept_prior_params


func_files = ['final_predictions_modality-func_rsn-union_gradient-ASE_outcome-rum_1_boots-100_search-grid',
'final_predictions_modality-func_rsn-union_gradient-ASE_outcome-rum_persistence_boots-100_search-grid',
'final_predictions_modality-func_rsn-union_gradient-ASE_outcome-dep_1_boots-100_search-grid', 
'final_predictions_modality-func_rsn-union_gradient-ASE_outcome-dep_persistence_boots-100_search-grid',
'final_predictions_modality-func_rsn-union_gradient-ASE_outcome-age_boots-100_search-grid',
'final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-rum_1_boots-100_search-grid', 
'final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-rum_persistence_boots-100_search-grid', 
'final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-dep_1_boots-100_search-grid', 
'final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-dep_persistence_boots-100_search-grid',
'final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-age_boots-100_search-grid']

dwi_files = ['final_predictions_modality-dwi_rsn-inter_gradient-ASE_outcome-rum_1_boots-100_search-grid',
'final_predictions_modality-dwi_rsn-inter_gradient-ASE_outcome-dep_1_boots-100_search-grid', 'final_predictions_modality-dwi_rsn-inter_gradient-ASE_outcome-dep_persistence_boots-100_search-grid',
'final_predictions_modality-dwi_rsn-inter_gradient-ASE_outcome-rum_persistence_boots-100_search-grid', 
'final_predictions_modality-dwi_rsn-inter_gradient-ASE_outcome-age_boots-100_search-grid', 
'final_predictions_modality-dwi_rsn-language_gradient-ASE_outcome-rum_1_boots-100_search-grid',
'final_predictions_modality-dwi_rsn-language_gradient-ASE_outcome-rum_persistence_boots-100_search-grid',
'final_predictions_modality-dwi_rsn-language_gradient-ASE_outcome-dep_persistence_boots-100_search-grid',
'final_predictions_modality-dwi_rsn-language_gradient-ASE_outcome-dep_1_boots-100_search-grid',
'final_predictions_modality-dwi_rsn-language_gradient-ASE_outcome-age_boots-100_search-grid']
 
func_priors_dict = {}
for pheno in ['dep_persistence', 'rum_persistence', 'dep_1', 'rum_1', 'age']:
    func_priors_dict[pheno] = {}
    for file_ in [i for i in func_files if pheno in i]:
        rsn = file_.split('rsn-')[1].split('_')[0]
        if rsn not in func_priors_dict[pheno].keys():
            func_priors_dict[pheno][rsn] = {}
        beta_prior_dist, beta_prior_params, intercept_prior_dist, intercept_prior_params = preparare_grid_dfs(file_, f"{source_file_path}", ['extract', 'hpass', 'model', 'res', 'network', 'smooth']) 
        func_priors_dict[pheno][rsn]['betas'] = [beta_prior_dist, beta_prior_params]
        func_priors_dict[pheno][rsn]['intercept'] = [intercept_prior_dist, intercept_prior_params]

dwi_priors_dict = {}
for pheno in ['dep_persistence', 'rum_persistence', 'dep_1', 'rum_1', 'age']:
    dwi_priors_dict[pheno] = {}
    for file_ in [i for i in dwi_files if pheno in i]:
        rsn = file_.split('rsn-')[1].split('_')[0]
        if rsn not in dwi_priors_dict[pheno].keys():
            dwi_priors_dict[pheno][rsn] = {}
        beta_prior_dist, beta_prior_params, intercept_prior_dist, intercept_prior_params = preparare_grid_dfs(file_, f"{source_file_path}", ['directget', 'minlength', 'model', 'res', 'network', 'tol']) 
        dwi_priors_dict[pheno][rsn]['betas'] = [beta_prior_dist, beta_prior_params]
        dwi_priors_dict[pheno][rsn]['intercept'] = [intercept_prior_dist, intercept_prior_params]
```

```{r message=FALSE, warning=FALSE, echo=FALSE, cache=FALSE, eval=FALSE}
setwd(data_dir)
func_metas <- c("network", "hpass", "smooth", "res", "model", "extract")
embedding_types = c('ASE')
nets = c('inter', 'union')
phenos = c("dep_1", "rum_1", "dep_persistence", "rum_persistence", "age")
df_func <- NULL
for (pheno in phenos) {
    for (net in nets) {
        for (embedding_type in embedding_types) {
            df_pheno_func <- read.csv(paste(data_dir, "/tuning_set/final_predictions_modality-func_rsn-", net, "_gradient-", embedding_type, "_outcome-", pheno, "_boots-100_search-grid_clean.csv", sep=''))
            df_pheno_func <- df_pheno_func %>% mutate_each_(funs(factor(.)), func_metas)
            df_pheno_func <- clean_grid_col(df_pheno_func)
            df_pheno_func$R2 <- as.numeric(df_pheno_func$Score_mean)
            df_pheno_func$Pheno <- as.factor(pheno)
            df_pheno_func$Error <- as.numeric(df_pheno_func$Error_mean)
            df2 <- df_pheno_func %>% dplyr::select(grid, extract, hpass, model, res, smooth, network, embedding, Pheno, R2, Error_mean, Score_95CI_lower, Score_95CI_upper, Error_95CI_lower, Error_95CI_upper)
            if (is.null(df_func)) {
              df_func <- df2
            } else {
              df_func <- bind_rows(df_func, df2)
            }
            gc()
        }
        gc()
    }
    gc()
}

df_func <- df_func[which(!is.na(df_func$R2)),]

write.csv(x=df_func, file=paste0(results_dir, "raw_tuning_func.csv"))

df_func <- df_func %>% mutate_if(is.character,as.factor)
levels(df_func$network) <- c('TN_intersection', 'TN_intersection', 'TN-union', 'TN_union')
levels(df_func$Pheno) <- c("Depression_Severity", "Rumination_Severity", "Depression_Persistence", "Rumination_Persistence", "Age")
levels(df_func$hpass) <- c('0.0 Hz', '0.028 Hz','0.08 Hz')
levels(df_func$model) <- c("Correlation", "Covariance", "Partial Correlation")
levels(df_func$smooth) <- c('0mm', '3mm', '6mm')
levels(df_func$res) <- c("200", "400", "600", "800")
```

```{r message=FALSE, warning=FALSE, echo=FALSE, cache=FALSE, eval=FALSE}
setwd(data_dir)
dwi_metas <- c("network", "minlength", "tol", "res", "model", "directget")
embedding_types = c('ASE')
nets = c('language', 'inter')
phenos = c("dep_1", "rum_1", "dep_persistence", "rum_persistence", "age")
df_dwi <- NULL
for (pheno in phenos) {
    for (net in nets) {
        for (embedding_type in embedding_types) {
            df_pheno_dwi <- read.csv(paste(data_dir, "/tuning_set/final_predictions_modality-dwi_rsn-", net, "_gradient-", embedding_type, "_outcome-", pheno, "_boots-100_search-grid_clean.csv", sep=''))
            df_pheno_dwi <- df_pheno_dwi %>% mutate_each_(funs(factor(.)), dwi_metas)
            df_pheno_dwi <- clean_grid_col(df_pheno_dwi)
            df_pheno_dwi$R2 <- as.numeric(df_pheno_dwi$Score_mean)
            df_pheno_dwi$Pheno <- as.factor(pheno)
            df_pheno_dwi$Error <- as.numeric(df_pheno_dwi$Error_mean)
            df2 <- df_pheno_dwi %>%  dplyr::select(grid, network, minlength, tol, model, res, directget, embedding, Pheno, R2, Error_mean, Score_95CI_lower, Score_95CI_upper, Error_95CI_lower, Error_95CI_upper)
            if (is.null(df_dwi)) {
              df_dwi <- df2
            } else {
              df_dwi <- bind_rows(df_dwi, df2)
            }
            gc()
        }
        gc()
    }
    gc()
}

df_dwi <- df_dwi[which(!is.na(df_dwi$R2)),]

write.csv(x=df_dwi, file=paste0(results_dir, "raw_tuning_dwi.csv"))

df_dwi <- df_dwi %>% mutate_if(is.character,as.factor)
levels(df_dwi$network) <- c('TN_intersection', 'LN_dorsal')
levels(df_dwi$Pheno) <- c("Depression_Severity", "Rumination_Severity", "Depression_Persistence", "Rumination_Persistence", "Age")
levels(df_dwi$minlength) <- c('Short', 'Medium', 'Long')
levels(df_dwi$tol) <- c('5mm', '10mm')
levels(df_dwi$model) <- c("CSA", "SFM")
levels(df_dwi$directget) <- c("Deterministic", "Probabilistic")
#levels(df_dwi$res) <- c("200", "400", "600", "800")
levels(df_dwi$res) <- c("200", "400")
```

## Source domain descriptives
```{r tuning_behavioral, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, eval=FALSE}
sub_list <- '^25632$|^25636$|^25637$|^25644$|^25649$|^25652$|^25657$|^25658$|^25659$|^25660$|^25661$|^25663$|^25665$|^25666$|^25667$|^25670$|^25671$|^25674$|^25676$|^25677$|^25680$|^25681$|^25683$|^25684$|^25685$|^25686$|^25687$|^25688$|^25689$|^25690$|^25691$|^25693$|^25694$|^25695$|^25696$|^25697$|^25698$|^25700$|^25705$|^25709$|^25713$|^25714$|^25715$|^25738$|^25739$|^25740$|^25741$|^25742$|^25743$|^25744$|^25745$|^25748$|^25753$|^25758$|^25765$|^25769$|^25770$|^25771$|^25773$|^25776$|^25778$|^25782$|^25785$|^25788$|^25796$|^25798$|^25799$|^25802$|^25806$|^25807$|^25808$|^25811$|^25812$|^25813$|^25814$|^25815$|^25816$|^25817$|^25819$|^25821$|^25822$|^25824$|^25827$|^25829$|^25830$|^25833$|^25834$|^25835$|^25836$|^25837$|^25848$|^25850$|^25851$|^25852$|^25853$|^25854$|^25856$|^25857$|^25858$|^25859$|^25860$|^25861$|^25862$|^25863$|^30714$|^30740$|^30744$|^30753$|^30763$|^30766$|^30776$|^30780$|^30815$|^30816$|^30822$|^30856$|^30882$|^30883$|^30885$|^30908$|^30909$|^30918$|^30920$|^31005$|^31037$|^31039$|^A00027544$|^A00028694$|^A00028929$|^A00028995$|^A00029303$|^A00031605$|^A00031683$|^A00032007$|^A00033640$|^A00033903$|^A00037229$|^A00037378$|^A00037421$|^A00037511$|^A00038411$|^A00038718$|^A00039074$|^A00039143$|^A00039257$|^A00039276$|^A00039277$|^A00039755$|^A00039952$|^A00040151$|^A00040439$|^A00040493$|^A00040517$|^A00040604$|^A00040827$|^A00043283$|^A00043762$|^A00044405$|^A00045589$|^A00050998$|^A00052117$|^A00053578$|^A00054857$|^A00054895$|^A00056949$|^A00058503$|^A00059344$|^A00059662$|^A00061203$|^A00061387$|^A00061656$|^A00062351$|^A00062917$|^A00064323$|^A00065478$|^A00065480$|^A00065572$|^A00065722$|^A00065935$|^A00065962$|^A00065974$|^A00065995$|^A00066132$|^A00066245$|^A00066282$|^A00066460$|^A00066735$|^A00066782$|^A00066800$|^A00066864$|^A00067062$|^A00073230$|^A00073283$|^A00073525$|^A00073611$|^A00073677$|^A00074113$|^A00074114$|^A00074439$|^A00074639$|^A00074657$|^A00074701$|^A00074709$|^A00074768$|^A00074769$|^A00074784$|^A00074787$|^A00074800$|^A00074942$|^A00074977$|^A00074989$|^A00075220$|^A00075653$|^A00075735$|^A00075741$|^A00075757$|^A00075806$|^A00076380$|^A00076381$|^A00076546$|^A00076559$|^A00076586$|^A00076744$|^A00076775$|^A00077088$|^A00077188$|^A00077252$|^A00077304$|^A00077391$|^A00077413$|^A00077528$|^A00079724$|^A00079850$|^A00079977$|^A00080811$|^A00080819$|^A00080942$|^A00081103$|^A00081123$|^A00081142$|^A00081175$|^A00081552$|^A00081724$|^A00081725$|^A00081734$|^A00081785$|^A00081794$|^A00081962$|^A00081963$|^A00082215$|^A00082216$|^A00082524$|^A00082556$|^A00082563$|^A00082580$|^A00082635$|^A00082804$|^A00082807$|^A00082969$|^A00083142$|^A00083207$|^A00083631$|^A00084901$|^A00084956$|^A00085290$|^A00085297$|^A00085665$|^A00085906$|^A00085927$|^A00085951$|^A00086169$|^A00086238$|^A00086474$|^s002$|^s004$|^s006$|^s007$|^s008$|^s009$|^s012$|^s013$|^s014$|^s016$|^s018$|^s020$|^s021$|^s023$|^s025$|^s026$|^s028$|^s030$|^s033$|^s034$|^s035$|^s036$|^s037$|^s039$|^s042$|^s043$|^s046$|^s047$|^s048$|^s049$|^s050$|^s051$|^s052$|^s053$|^s054$|^s055$|^s056$|^s057$|^s059$|^s060$|^s061$'
df_tuning_descriptives <- read_csv(paste0(data_dir, 'tuning_set/df_rum_persist_all_with_class.csv')) %>% mutate(participant_id = as.character(participant_id)) %>% filter(grepl(sub_list, participant_id)) %>% na.omit()

df_clust <- as.matrix(cbind(df_tuning_descriptives$total_study_duration, df_tuning_descriptives$num_visits))
  
silhouette_score <- function(k, df_clust){
  km <- kmeans(x=df_clust, centers=k, nstart=3)
  ss <- silhouette(km$cluster, dist(df_clust))
  mean(ss[, 3])
}

#for (k in 3:9){
#  print(paste("k:", k, sep=" "))
#  print(silhouette_score(k, df_clust))
#}
set.seed(42)
time_clusts <- kmeans(x=df_clust, centers=7)
centers <- time_clusts$centers[,1]
df_tuning_descriptives$time_clusters <- as.factor(time_clusts$cluster)

df_tuning_descriptives$time_clusters <- factor(df_tuning_descriptives$time_clusters,
levels = c(1, 2, 3, 4, 5, 6, 7),
labels = c(paste(round(time_clusts$centers[,1][1]/30.417, digit=0), "mo  ", round(time_clusts$centers[,2][1], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][2]/30.417, digit=0), "mo ", round(time_clusts$centers[,2][2], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][3]/30.417, digit=0), "mo ", round(time_clusts$centers[,2][3], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][4]/30.417, digit=0), "mo ", round(time_clusts$centers[,2][4], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][5]/30.417, digit=0), "mo ", round(time_clusts$centers[,2][5], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][6]/30.417, digit=0), "mo ", round(time_clusts$centers[,2][6], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][7]/30.417, digit=0), "mo ", round(time_clusts$centers[,2][7], digit=0)[[1]], " visits", sep="")))
time_clust_labs_tuning <- fct_count(df_tuning_descriptives$time_clusters)
time_clust_labs_tuning$`Longitudinal Study Participation Clusters` <- time_clust_labs_tuning$f
time_clust_labs_tuning$N <- time_clust_labs_tuning$n
time_clust_labs_tuning <- time_clust_labs_tuning %>% dplyr::select(-"f", -"n")

names(time_clust_labs_tuning) <- NULL

time_clust_labs_tuning_t <- t(time_clust_labs_tuning)

time_clust_labs_tuning_t <- as.data.frame(sapply(time_clust_labs_tuning_t %>% `colnames<-`(.[1, ]) %>% .[-1, ], as.numeric))

names(time_clust_labs_tuning_t) <- "N"
  
knitr::kable(time_clust_labs_tuning_t %>% mutate_if(is.numeric, format, digits=4), format = "latex", booktabs = TRUE) %>%
          kable_styling(latex_table_env = "tabular", latex_options = c("striped"), full_width = FALSE, position = "left", protect_latex = TRUE) %>% gsub("\\\\end\\{table\\}\n", "", .) %>% gsub("\n\\\\begin\\{table\\}", "", .) %>% gsub("\n\\\\centering", "", .) %>% gsub("\\_", "-", .) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% save_kable("tuning_sample_duration_descriptives.tex")

time_clusts$cluster <- df_tuning_descriptives$time_clusters

out <- fviz_cluster(time_clusts, data = df_tuning_descriptives %>% dplyr::select(total_study_duration, num_visits), repel=TRUE, xlab="Duration of Study Participation", ylab="Number of Study Visits", ggtheme=theme_void(), main = "Longitudinal Study Visit-Duration Clusters", geom = c("point"), palette = pal_tron(alpha=0.75)(7), stand=FALSE) + theme(plot.title = element_text(hjust = 0.5, colour="white"), axis.text=element_text(size=18, colour="white"), axis.title.y=element_text(size=18, angle = 90, colour="white"), axis.title.x=element_text(size=18, colour="white"), legend.title=element_text(size=16, colour="white"), legend.text=element_text(size=14, colour="white"), plot.background = element_rect(fill = "black"), panel.background = element_rect(fill = "black"), legend.key = element_rect(fill = "black"))
out

df_tuning_descriptives$sex <- ordered(df_tuning_descriptives$sex,
levels = c(0, 1),
labels = c("Male", "Female"))
gender_labs <- fct_count(df_tuning_descriptives$sex)

df_tuning_descriptives$dataset <- ordered(df_tuning_descriptives$dataset,
levels = c(0, 1, 3),
labels = c("SWU", "NKI", "UT-ABM"))
dataset_labs <- fct_count(df_tuning_descriptives$dataset)

sample_summary1 <- df_tuning_descriptives %>%
  summarize(
    `Total N` = length(participant_id),
    `Mean Age` = paste(
      round(mean(age, na.rm = T), 1), " (SD = ",
      round(sd(age, na.rm = T), 1),
      ")", sep = ""
    ),
    `Gender` = paste(levels(gender_labs$f)[1], ' = ', gender_labs$n[1], ', ', levels(gender_labs$f)[2], ' = ', gender_labs$n[2], sep = ""),
    `Datasets` = paste(levels(dataset_labs$f)[1], ' = ', dataset_labs$n[1], ', ', levels(dataset_labs$f)[2], ' = ', dataset_labs$n[2], ', ', levels(dataset_labs$f)[3], ' = ', dataset_labs$n[3], sep = ""),
    `Mean Number of Visits` = paste(
      round(mean(num_visits, na.rm=T), 1), " (SD = ",
      round(sd(num_visits, na.rm=T), 1),
      ")", sep = ""
    ),
    `Mean Time Between Visits` = paste(
      round(mean(total_study_duration, na.rm=T), 1), " days", sep = ""
    )
)

knitr::kable(sample_summary1 %>% mutate_if(is.numeric, format, digits=4), format = "latex", booktabs = TRUE) %>%
          kable_styling(latex_table_env = "tabular", latex_options = c("striped"), full_width = FALSE, position = "left", protect_latex = TRUE) %>% gsub("\\\\end\\{table\\}\n", "", .) %>% gsub("\n\\\\begin\\{table\\}", "", .) %>% gsub("\n\\\\centering", "", .) %>% gsub("\\_", "-", .) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% save_kable("tuning_sample_demographic_descriptives.tex")

df_tuning_descriptives$rum_1 <- scales::rescale(df_tuning_descriptives$rum_1, to=c(0,100))

df_tuning_descriptives$rum_2 <- scales::rescale(df_tuning_descriptives$rum_2, to=c(0,100))

sample_summary2 <-df_tuning_descriptives %>% 
  summarize(
     `BDI-II Total baseline` = paste(
      round(mean(dep_1, na.rm = T), 3), " (SD = ",
      round(sd(dep_1, na.rm = T), 3), ")", sep = ""
    ),
    `BDI-II Total follow-up` = paste(
      round(mean(dep_2, na.rm = T), 3), " (SD = ",
      round(sd(dep_2, na.rm = T), 3), ")", sep = ""
    ),
    `RRS Brooding baseline (Rescaled)` = paste(
      round(mean(rum_1, na.rm = T), 3), " (SD = ",
      round(sd(rum_1, na.rm = T), 3), ")", sep = ""
    ),
    `RRS Brooding follow-up (Rescaled)` = paste(
      round(mean(rum_2, na.rm = T), 3), " (SD = ",
      round(sd(rum_2, na.rm = T), 3), ")", sep = ""
    )
)

knitr::kable(sample_summary2 %>% mutate_if(is.numeric, format, digits=4), format = "latex", booktabs = TRUE) %>%
          kable_styling(latex_table_env = "tabular", latex_options = c("striped"), full_width = FALSE, position = "left", protect_latex = TRUE) %>% gsub("\\\\end\\{table\\}\n", "", .) %>% gsub("\n\\\\begin\\{table\\}", "", .) %>% gsub("\n\\\\centering", "", .) %>% gsub("\\_", "-", .) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% save_kable("tuning_sample_clinical_characteristics.tex")
```

::: {.center data-latex=""}
\begin{sidewaystable}
\begin{minipage}{\textwidth}
\centering
\adjustbox{width=\textwidth,height=\textheight,keepaspectratio=true}{\subfile{Chapter_IV/results/tuning_sample_demographic_descriptives}}
\subcaption{\label{tab:tuning_sample_demographic_descriptives}\scriptsize{Demographic}}
\vspace{\baselineskip}
\adjustbox{width=\textwidth,height=\textheight,keepaspectratio=true}{\subfile{Chapter_IV/results/tuning_sample_clinical_characteristics}}
\subcaption{\label{tab:tuning_sample_clinical_characteristics}\scriptsize{Clinical}}
\end{minipage}
\caption{(Source Domain) \scriptsize{The table summarizes depression and rumination severity of the tuning sample subjects based on contemporaneous BDI-II and RRS-Brooding scores, respectively, and depression and rumination persistence in the form of shared variance across time-points for each of these scales as estimated by PC1.}}
\end{sidewaystable}
\setlength{\belowcaptionskip}{-10pt}
:::

As summarized in Table \ref{tab:tuning_sample_demographic_descriptives}, the data analyzed in the source domain consisted of N = `r sample_summary1 %>% pull("Total N")` participants, recruited across two continents and spanning three aggregated data sets (SWU = `r sample_summary1$Datasets`). The majority of participants in the sample were young adults, but ages varied widely across the 18-65 range, with a mean age of `r sample_summary1 %>% pull("Mean Age")`. There was an approximately 3:2 ratio of females to males, a slight imbalance that if anything reflects the known tendency of females to report more depression symptoms~\cite{Butler1994}. All included participants in the sample were examined for at least two and at most four visits, spanning a variety of time-scales, ranging from one month to three years, with the average time at just under one year. To conceptualize the degree of longitudinal participation, we performed k-means clustering on the dual basis of both number of visits and total number of days participated. Based on the Silhouette method~\cite{Rousseeuw1987}, k=`r length(levels(time_clusts$cluster))` distinct clusters was the optimal partitioning and can be visualized in Figure \ref{fig:tuning_set_longitudinal_profiles} as well as summarized in Table \ref{fig:tuning_set_longitudinal_profiles}. To avoid substantial missing data for those participants with only two time points of data, depression and rumination severity data were collapsed into two time points (baseline and follow-up) and their study duration data was treated as a random effect that we deconfounded from subsequent linear regression models, along with age, gender, and respective study site. Again, this involved residualizing the input features by subtracting the contributions of their confounding variables~\cite{Chyzhyk2018,Rao2017}. Although SCID diagnostic interview data was not available for the data analyzed in the source domain included participants were either sub-clinically depressed or dysphoric as evaluated informally based on depression symptom severity on the BDI-II questionnaire. More specifically, N = `r length(df_tuning_descriptives %>% filter((dep_1 >= 4 | dep_2 >= 4) & (dep_1 <= 14 & dep_2 <= 14)) %>% pull("participant_id"))` had elevated but sub-clinical (4 < BDI <= 14) depressive symptoms, N = `r length(df_tuning_descriptives %>% filter((dep_1 > 14 | dep_2 > 14) & (dep_1 <= 20 & dep_2 <= 20)) %>% pull("participant_id"))` participants were mildly depressed (14 <= BDI < 20), and N = `r length(df_tuning_descriptives %>% filter((dep_1 > 20 | dep_2 > 20)) %>% pull("participant_id"))` participants would be considered moderately or severely depressed (BDI > 20) for at least one time-point. Average depression and rumination severity is summarized in Table \ref{tab:tuning_sample_clinical_characteristics}. Since ruminative brooding was assessed using both the RRS, RSQ, and a Chinese version across multiple data-sets, we harmonized this measure within each time-point by re-scaling to a feature range of 0-100.

::: {.center data-latex=""}
\begin{figure}
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio=true,angle=270]{../figures/tuning_behavioral-1.pdf}
\caption{(Source Domain) \label{fig:tuning_set_longitudinal_profiles}\scriptsize{The figure depicts the heterogeneous geometry of longitudinal study participation in the form of a K=7 cluster solution when performing K-Means clustering on cumulative days participated with the cumulative number of visits.}}
\end{figure}
\setlength{\belowcaptionskip}{-10pt}
:::

## Predictive Performance Descriptives
```{r prediction_performance_overview, message=FALSE, warning=FALSE, fig.width = 15, fig.height= 10, fig.align="center", echo=FALSE, include=FALSE, cache=FALSE, eval=TRUE}
vio_plot <- function(df, X_var, Y_var, x_lab, y_lab, col_scheme) {
  x.var <- rlang::sym(X_var)
  y.var <- rlang::sym(Y_var)
  
  point_color = 'white'
  
  x_lab <- str_trim(gsub('([[:upper:]])', ' \\1', x_lab))
  
  X_levs = levels(as.list(unique(as.vector(df %>% dplyr::select(X_var))))[[1]])
  Y_levs = levels(as.list(unique(as.vector(df %>% dplyr::select(Y_var))))[[1]])
  
  out_vio <- ggplot(data = df, aes(x = !! x.var, y = !! y.var, fill = !! x.var)) +
     geom_violin(alpha=0.4, trim = FALSE) +
     geom_point( shape = 21, size=0.1, position = position_jitterdodge(), 
                 color= point_color, alpha=0.85)+
    scale_fill_manual(
      values = saturation(col_scheme, seq(from = 0.3, to = 1, 
                                          length.out = length(X_levs) + 6)))+
     DARK_THEME_GRAY +
     ylab(c(y_lab)) +
     xlab(c(x_lab)) +
     geom_boxplot(color='white', alpha=0.7, width=0.2) +
     theme(axis.ticks = element_line(size=0.1,color="white"),
           axis.ticks.length = unit(0.1,"cm"), 
           legend.title = element_text(size=14, colour="white"), 
           plot.title = element_blank(),
           text =  element_text(size=12, colour="white"), 
           legend.text = element_text(size=12, colour="white"), 
           plot.margin = unit(c(3,2,3,3), "cm"),
           axis.text.x = element_text(size=10, colour="white"), 
           axis.text.y = element_text(size=10, colour="white"), 
           axis.title.x = element_text(size=12, vjust=-0.30, colour="white"), 
           axis.title.y = element_text(size=12, angle=90, vjust=0.85, 
                                       colour="white"))
  return(out_vio)
}

meta_comp <- do.call(grid.arrange, list(grobs=list(grid_plot_multi(df_func %>% filter(embedding=='ASE') %>% dplyr::rename(Phenotype = Pheno) %>% na.omit(), "Phenotype", 1, "R2", "Functional"), grid_plot_multi(df_dwi %>% filter(embedding=='ASE', res=='400') %>% dplyr::rename(Phenotype = Pheno) %>% na.omit(), "Phenotype", 2, "R2", "Structural")), nrows=2, top = grobTree( rectGrob(gp=gpar(fill="black", color = "black", size = 0.2)), textGrob("\nExplained Variance in Depressive Phenotypes Across the Connectome Multiverse", vjust=0.5, gp=gpar(fontsize=20, col="white", fontface="bold")))))
grid.draw(meta_comp)
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
grid.draw(meta_comp)
meta_comp
```

As shown in Figure \ref{fig:prediction_performance_overview}, some but not all embedded connectome feature spaces weakly predicted contemporaneous depression and rumination severity ($R^{2}_{dep}$=`r round(mean(rbind(df_dwi %>% filter(Pheno=="Depression_Severity") %>% na.omit() %>% pull(R2), df_func %>% filter(Pheno=="Depression_Severity") %>% na.omit() %>% pull(R2))), 3)` $\pm$ `r round(sd(rbind(df_dwi %>% filter(Pheno=="Depression_Severity") %>% na.omit() %>% pull(R2), df_func %>% filter(Pheno=="Depression_Severity") %>% na.omit() %>% pull(R2))), 3)`; $R^{2}_{rum}$=`r round(mean(rbind(df_dwi %>% filter(Pheno=="Rumination_Severity") %>% na.omit() %>% pull(R2), df_func %>% filter(Pheno=="Rumination_Severity") %>% na.omit() %>% pull(R2))), 3)` $\pm$ `r round(sd(rbind(df_dwi %>% filter(Pheno=="Rumination_Severity") %>% na.omit() %>% pull(R2), df_func %>% filter(Pheno=="Rumination_Severity") %>% na.omit() %>% pull(R2))), 3)`), and some but not all connectome feature spaces predicted moderate variance ($R^{2}>0.2$) in depression and rumination persistence when controlling for baseline depression severity ($R^{2}_{dep}$=`r round(mean(rbind(df_dwi %>% filter(Pheno=="Depression_Persistence") %>% na.omit() %>% pull(R2), df_func %>% filter(Pheno=="Depression_Persistence") %>% na.omit() %>% pull(R2))), 3)` $\pm$ `r round(sd(rbind(df_dwi %>% filter(Pheno=="Depression_Persistence") %>% na.omit() %>% pull(R2), df_func %>% filter(Pheno=="Depression_Persistence") %>% na.omit() %>% pull(R2))), 3)`; $R^{2}_{rum}$=`r round(mean(rbind(df_dwi %>% filter(Pheno=="Rumination_Persistence") %>% na.omit() %>% pull(R2), df_func %>% filter(Pheno=="Rumination_Persistence") %>% na.omit() %>% pull(R2))), 3)` $\pm$ `r round(sd(rbind(df_dwi %>% filter(Pheno=="Rumination_Persistence") %>% na.omit() %>% pull(R2), df_func %>% filter(Pheno=="Rumination_Persistence") %>% na.omit() %>% pull(R2))), 3)`). Both structural and functional connectomes were generally better predictors of depression phenotypes ($R^{2}_{dwi}$=`r round(mean(df_dwi %>% filter(grepl("Depression", Pheno)) %>% na.omit() %>% pull(R2)), 3)` $\pm$ `r round(sd(df_dwi %>% filter(grepl("Depression", Pheno)) %>% na.omit() %>% pull(R2)), 3)`; $R^{2}_{func}$=`r round(mean(df_func %>% filter(grepl("Rumination", Pheno)) %>% na.omit() %>% pull(R2)), 3)` $\pm$ `r round(sd(df_func %>% filter(grepl("Rumination", Pheno)) %>% na.omit() %>% pull(R2)), 3)`) as compared to rumination phenotypes ($R^{2}_{dwi}$=`r round(mean(df_dwi %>% filter(grepl("Rumination", Pheno)) %>% na.omit() %>% pull(R2)), 3)` $\pm$ `r round(sd(df_dwi %>% filter(grepl("Rumination", Pheno)) %>% na.omit() %>% pull(R2)), 3)`; $R^{2}_{func}$=`r round(mean(df_func %>% filter(grepl("Rumination", Pheno)) %>% na.omit() %>% pull(R2)), 3)` $\pm$ `r round(sd(df_func %>% filter(grepl("Rumination", Pheno)) %>% na.omit() %>% pull(R2)), 3)`). In general, however, connectomes were better at predicting the persistence phenotypes (mean $R^{2}_{persist}$=`r round(mean(rbind(df_func %>% filter(grepl("Persistence", Pheno)) %>% na.omit() %>% pull(R2), df_dwi %>% filter(grepl("Persistence", Pheno)) %>% na.omit() %>% pull(R2))), 3)` $\pm$ `r round(sd(rbind(df_func %>% filter(grepl("Persistence", Pheno)) %>% na.omit() %>% pull(R2), df_dwi %>% filter(grepl("Persistence", Pheno)) %>% na.omit() %>% pull(R2))), 3)`) as compared to the severity phenotypes (mean $R^{2}_{severity}$=`r round(mean(rbind(df_func %>% filter(grepl("Severity", Pheno)) %>% na.omit() %>% pull(R2), df_dwi %>% filter(grepl("Severity", Pheno)) %>% na.omit() %>% pull(R2))), 3)` $\pm$ `r round(sd(rbind(df_func %>% filter(grepl("Severity", Pheno)) %>% na.omit() %>% pull(R2), df_dwi %>% filter(grepl("Severity", Pheno)) %>% na.omit() %>% pull(R2))), 3)`). Whereas overall, the majority of both structural (`r round(100*sum(df_dwi %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2) > 0.2)/length(df_dwi %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2)), 2)`%) and functional (`r round(100*sum(df_func %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2) > 0.2)/length(df_func %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2)), 2)`%) connectomes were good predictors ($R^{2}>0.2$) of depression persistence, a substantial proportion of connectome recipes (`r round(100*sum(df_dwi %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2) < 0.2)/length(df_dwi %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2)), 2)`% and `r round(100*sum(df_func %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2) < 0.2)/length(df_func %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2)), 2)`%, respectively) were also poor predictors ($R^{2}<0.2$). This tracked with the observation that connectome predictions of depression persistence had higher variance (SD=`r round(sd(rbind(df_func %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2), df_dwi %>% filter(grepl("Depression_Persistence", Pheno)) %>% na.omit() %>% pull(R2))), 3)`) than did those of rumination persistence (SD=`r round(sd(rbind(df_func %>% filter(grepl("Rumination_Persistence", Pheno)) %>% na.omit() %>% pull(R2), df_dwi %>% filter(grepl("Rumination_Persistence", Pheno)) %>% na.omit() %>% pull(R2))), 3)`).

We also tuned connectomes attributes to predict brain age as a null model. Among other advantages, this approach could help to determine the extent to which structural and functional connectivity attributes that best predicted the temporal dimension of mood persistence reflect the same latent developmental processes as the brain's natural course of maturation. If they did reflect a shared latent process, then the best predictors of brain age should conceivably be bona fide predictors of mood persistence as well. If not, then the best predictors of brain age should be different from those of mood persistence. And if it turned out that this extent further depends upon choice of structural versus functional data modality, then that information would help to establish how their differential sensitivity to developmental variance across different time scales might render them more or less predictive of depression prognosis. On average, functional connectomes showed highly inconsistent and generally poor predictors of brain age ($R^{2}_{func}$=`r round(mean(df_func %>% filter(grepl("Age", Pheno)) %>% na.omit() %>% pull(R2)), 3)` $\pm$ `r round(sd(df_func %>% filter(grepl("Age", Pheno)) %>% na.omit() %>% pull(R2)), 3)`), such that only `r round(100*sum(df_func %>% filter(grepl("Age", Pheno)) %>% na.omit() %>% pull(R2) > 0.2)/length(df_func %>% filter(grepl("Age", Pheno)) %>% na.omit() %>% pull(R2)), 2)`\% of recipes might be considered good predictors ($R^{2}>0.2$). By contrast, structural connectomes explained more variance in brain age on average ($R^{2}_{dwi}$=`r round(mean(df_dwi %>% filter(grepl("Age", Pheno)) %>% na.omit() %>% pull(R2)), 3)` $\pm$ `r round(sd(df_dwi %>% filter(grepl("Age", Pheno)) %>% na.omit() %>% pull(R2)), 3)`) and a greater proportion of recipes `r round(100*sum(df_func %>% filter(grepl("Age", Pheno)) %>% na.omit() %>% pull(R2) > 0.2)/length(df_func %>% filter(grepl("Age", Pheno)) %>% na.omit() %>% pull(R2)), 2)`\% might be considered good predictors ($R^{2}>0.2$). On the basis of their independent $R^{2}$ estimates overall, however, connectomes were better predictors of the mood phenotypes than the age phenotypes (`r str_split(str_split(report_statistics(t.test(df_func %>% filter(grepl("Age", Pheno)) %>% na.omit() %>% pull(R2), df_func %>% filter(!grepl("Age", Pheno)) %>% na.omit() %>% pull(R2))), "], ")[[1]], ";")[[2]][[1]]`). First, the learned connectome model was, on average, better at predicting the mood phenotypes than it was at predicting brain age, and did so across a largely diverging set of attributes. In effect, this indicated that temporal persistence is not merely a function of accelerated aging, but reflects latent processes which are orthogonal to the brain's natural course of maturation. Second, that structural connectomes more consistently and accurately predicted brain age on average than did functional connectomes helped to substantiate the intuition that structural connectivity plays a comparatively greater role in determining age-related changes in cognition~\cite{Kaiser2020}. Hence, any comparative interpretation in the ability of structural connectomes, over and above functional connectomes, to predict chronic depression in the target domain would imply that any depressive attributes of structural connectomes---severity or persistence---could implicitly explain variance in depression persistence by virtue of their corresponding data modality alone.

::: {.center data-latex=""}
\begin{figure}
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio=true,angle=270]{../figures/prediction_performance_overview-5.pdf}
\caption{(Source Domain) \label{fig:prediction_performance_overview}\scriptsize{The above violin plots depict distributions of predictive $R^2$ (i.e. the dark jitter points within each violin) that represent the association between each behavioral phenotype of interest (shown in the adjacent legend) and connectome features (functional: red, structural: blue) as estimated in the source domain.}}
\end{figure}
\setlength{\belowcaptionskip}{-10pt}
:::

### Select connectome feature spaces with top-performing predictions per phenotype
#### Functional
##### Connectome attribute-sensitivity
```{r func_trees_rum, fig.width = 16, fig.height=7, fig.align="center", message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
df_func_rum_persistence <- df_func %>% filter(Pheno=="Rumination_Persistence") %>% na.omit()
df_func_rum_severity <- df_func %>% filter(Pheno=="Rumination_Severity") %>% na.omit()
df_func_dep_persistence <- df_func %>% filter(Pheno=="Depression_Persistence") %>% na.omit()
df_func_dep_severity <- df_func %>% filter(Pheno=="Depression_Severity") %>% na.omit()

func_metas <- c("network", "hpass", "smooth", "res", "model", "extract")
func_factors <- c("network", "smooth", "hpass", "extract", "model", "res")
imp_names_func <- c("NetworkDefinition", "SmoothingTolerance", "FrequencyBandwidth", "ExtractionMethod", "ConnectivityEstimator", "NodeGranularity")

# Rumination Persistence
tree_fit_res <- cv_decision_tree_func(df_func_rum_persistence, "R2")
tree_fit_func_rum_persistence <- tree_fit_res[[1]]
df <- tree_fit_res[[2]]
predict_func_rum_persistence <- max(unique(predict(tree_fit_func_rum_persistence, df)))
imp_R2_rum_persistence_func <- vi(tree_fit_func_rum_persistence, method="firm", scale=TRUE)
names(imp_R2_rum_persistence_func) <- c("grid", "Importance")
imp_R2_rum_persistence_func$grid <- imp_names_func
imp_R2_rum_persistence_func$outcome <- "Rumination_Persistence"

# Rumination Severity
tree_fit_res <- cv_decision_tree_func(df_func_rum_severity, "R2")
tree_fit_func_rum_severity <- tree_fit_res[[1]]
df <- tree_fit_res[[2]]
predict_func_rum_severity <- max(unique(predict(tree_fit_func_rum_severity, df)))
imp_R2_rum_severity_func <- vi(tree_fit_func_rum_severity, method="firm", scale=TRUE)
names(imp_R2_rum_severity_func) <- c("grid", "Importance")
imp_R2_rum_severity_func$grid <- imp_names_func
imp_R2_rum_severity_func$outcome <- "Rumination_Severity"

# Depression Persistence
tree_fit_res <- cv_decision_tree_func(df_func_dep_persistence, "R2")
tree_fit_func_dep_persistence <- tree_fit_res[[1]]
df <- tree_fit_res[[2]]
predict_func_dep_persistence <- max(unique(predict(tree_fit_func_dep_persistence, df)))
imp_R2_dep_persistence_func <- vi(tree_fit_func_dep_persistence, method="firm", scale=TRUE)
names(imp_R2_dep_persistence_func) <- c("grid", "Importance")
imp_R2_dep_persistence_func$grid <- imp_names_func
imp_R2_dep_persistence_func$outcome <- "Depression_Persistence"

# Depression Severity
tree_fit_res <- cv_decision_tree_func(df_func_dep_severity, "R2")
tree_fit_func_dep_severity <- tree_fit_res[[1]]
df <- tree_fit_res[[2]]
predict_func_dep_severity <- max(unique(predict(tree_fit_func_dep_severity, df)))
imp_R2_dep_severity_func <- vi(tree_fit_func_dep_severity, method="firm", scale=TRUE)
names(imp_R2_dep_severity_func) <- c("grid", "Importance")
imp_R2_dep_severity_func$grid <- imp_names_func
imp_R2_dep_severity_func$outcome <- "Depression_Severity"
```

```{r sensitivity_func, fig.width = 20, fig.height=20, fig.align="center", message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
imp_func_all <- rbind(imp_R2_rum_persistence_func, imp_R2_rum_severity_func, imp_R2_dep_persistence_func, imp_R2_dep_severity_func) %>%
    convert_as_factor(grid) %>% mutate_if(is.character,as.factor)

func_mean_imp <- as.data.frame(as.matrix(rowMeans(with( imp_func_all, tapply(Importance, list(grid,outcome), mean)))))
colnames(func_mean_imp) <- "imp"
func_mean_imp$vars <- rownames(func_mean_imp)
rownames(func_mean_imp) <- NULL
func_mean_imp <- func_mean_imp %>% as_tibble()
func_mean_imp <- func_mean_imp[, c(2,1)]
func_mean_imp$imp <- 1000*func_mean_imp$imp
func_mean_imp$vars <- gsub(" ", "", func_mean_imp$vars, fixed = TRUE)
func_mean_imp <- rbind(func_mean_imp, c("Phenotype", 1000))
func_mean_imp$imp <- as.numeric(func_mean_imp$imp)

p_func_all <- ggplot(imp_func_all, aes(x=grid, weight=Importance, fill=outcome)) + geom_bar(width=0.25, alpha=0.75) + ggtitle("\nFunctional Connectome Hyperparameter Sensitivity") + xlab("Hyperparameter") + ylab("Variable Importance (VIP)") + scale_fill_tron(name="Phenotype", alpha = 0.75) + scale_fill_tron(name="Sensitivity_Statistic", alpha = 0.75) + theme(axis.text.y=element_text(size=18, colour="white"), axis.title.y=element_text(size=18, colour="white"), axis.text.x = element_text(angle = 45, size = 16, colour="white", vjust=0.4), plot.background = element_rect(fill="black", colour = 'black'), panel.background = element_rect(fill = "#141414"), panel.border = element_blank(), axis.title.x=element_text(size=18, colour="white", vjust=-0.5), legend.title=element_text(size=16, colour="white"), legend.text=element_text(size=14, colour="white"), legend.key = element_rect(fill = "#0D0D0D"), panel.grid = element_line(colour = "#000000"), axis.ticks = element_line(colour = "#CCCCCC"), legend.background = element_rect(fill = "#141414"), plot.title = element_text(size=28, hjust = 0.5, colour="white"))
p_func_all

knitr::kable(imp_func_all %>% mutate_if(is.numeric, format, digits=4), format = "latex", booktabs = TRUE) %>%
          kable_styling(latex_table_env = "tabular", latex_options = c("striped"), full_width = FALSE, position = "left", protect_latex = TRUE) %>% gsub("\\\\end\\{table\\}\n", "", .) %>% gsub("\n\\\\begin\\{table\\}", "", .) %>% gsub("\n\\\\centering", "", .) %>% gsub("\\_", "-", .) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% save_kable("sensitivity_func_tab.tex")
```

As an initial step to attributing functional connectome features with a rumination persistence phenotype, we performed decision-tree sensitivity analysis whereby we explored the relative importance of each specific attribute of interest for capturing rumination and depression, both their severity and persistence. Using this approach, we found that each phenotype had identifiable affinities that could be ranked on the basis of their influence on predictive $R^{2}$ (Table \ref{tab:sensitivity_func} and the top plot in Figure \ref{fig:sensitivities_bar_plot_pheno}). Among the mood phenotypes investigated, all were consistently sensitive to the choice of smoothing tolerance, followed by frequency bandwidth ($mean(VIP)_{rum-persistence}$=`r imp_func_all %>% filter(grid=='FrequencyBandwidth' & outcome=='Rumination_Persistence') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%; $mean(VIP)_{rum-severity}$=`r imp_func_all %>% filter(grid=='FrequencyBandwidth' & outcome=='Rumination_Severity') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%; $mean(VIP)_{dep-severity}$=`r imp_func_all %>% filter(grid=='FrequencyBandwidth' & outcome=='Depression_Severity') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%; $mean(VIP)_{dep-persistence}$=`r imp_func_all %>% filter(grid=='FrequencyBandwidth' & outcome=='Depression_Persistence') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%), and extraction method ($mean(VIP)_{rum-persistence}$=`r imp_func_all %>% filter(grid=='ExtractionMethod' & outcome=='Rumination_Persistence') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%; $mean(VIP)_{rum-severity}$=`r imp_func_all %>% filter(grid=='ExtractionMethod' & outcome=='Rumination_Severity') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%; $mean(VIP)_{dep-severity}$=`r imp_func_all %>% filter(grid=='ExtractionMethod' & outcome=='Depression_Severity') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%; $mean(VIP)_{dep-persistence}$=`r imp_func_all %>% filter(grid=='ExtractionMethod' & outcome=='Depression_Persistence') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%). Rumination persistence and depression severity were also sensitive to the choice of connectivity estimator ($mean(VIP)_{rum-persistence}$=`r imp_func_all %>% filter(grid=='ConnectivityEstimator' & outcome=='Rumination_Persistence') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%; $mean(VIP)_{dep-severity}$=`r imp_func_all %>% filter(grid=='ConnectivityEstimator' & outcome=='Depression_Severity') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%). Choice of node granularity, however, only exhibited any influence on rumination persistence, and that influence was near-negligible ($mean(VIP)_{rum-persistence}$=`r imp_func_all %>% filter(grid=='NodeGranularity' & outcome=='Rumination_Persistence') %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`\%).

##### Top-performing connectome attributes
```{r gridsearch_func, message=FALSE, warning=FALSE, fig.align="center", fig.width = 16, fig.height=10, include=FALSE, out.width="100%", out.height="100%", echo=FALSE, cache=FALSE, eval=FALSE}
knitr::opts_chunk$set(comment = NA)

out2 <- grid_plot_func(df_func %>% dplyr::select(grid, extract, hpass, model, res, smooth, network, Pheno, R2) %>% mutate_if(is.character,as.factor) %>% dplyr::rename(Phenotype = Pheno) %>% na.omit(), 'R2', func_mean_imp)
out2

if (interactive == TRUE){
    out2$width <- "1400px"
    out2$height <- "600px"
    out2$sizingPolicy$padding <- "0"
    out2$sizingPolicy$viewer$padding <- "0"
    out2$sizingPolicy$browser$padding <- "0"
    out2 <- htmlwidgets::prependContent(out2, htmltools::tags$h1(css))
    out2 <- htmlwidgets::prependContent(out2, htmltools::tags$h1("Functional Connectome Phenotype Optimization"))
    out2 <- htmlwidgets::prependContent(out2, htmltools::tags$h2("(Source Domain)"))
    htmlwidgets::saveWidget(out2, file = paste0(results_dir, "gridsearch_func.html"), selfcontained = TRUE, knitrOptions = list(message=FALSE, warning=FALSE, fig.align="center", echo=FALSE))
    URL <- paste0(results_dir, "gridsearch_func.html")
    out_png <- paste0(results_dir, "../figures/gridsearch_func.png")
    gsub_file(URL, "P(color", "P(R2 Quartile", fixed = TRUE)
    gsub_file(URL, "| color)", "| R2 Quartile", fixed = TRUE)
    webshot2::webshot(URL, delay = 1, file = out_png, vwidth = 1400, vheight = 600, zoom = 4, cliprect = 'viewport', max_concurrent = 12, useragent= 'Mozilla/5.0')
    include_graphics(out_png, dpi=600)
}
```

```{r rank_func_tables, message=FALSE, warning=FALSE, fig.align="center", echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
df_func_rankings <- df_func  %>%
  dplyr::select(grid, network, hpass, smooth, model, res, extract, embedding, Pheno, R2) %>% mutate_if(is.character,as.factor) %>% filter(embedding=='ASE', network=='TN_intersection')

names(df_func_rankings) <- c("Grid", "NetworkDefinition", 'FrequencyBandwidth', "SmoothingTolerance", "ConnectivityEstimator", "NodeGranularity", "ExtractionMethod", "Embedding Method", "Phenotype", "R2")

df_func_rank_dep_severity <- df_func_rankings %>% filter(Phenotype=="Depression_Severity", R2>max(predict_func_dep_severity))
df_func_rank_dep_severity <- df_func_rank_dep_severity %>% filter(SmoothingTolerance == as.character(Mode(df_func_rank_dep_severity$SmoothingTolerance))) %>% filter(FrequencyBandwidth == as.character(Mode(df_func_rank_dep_severity$FrequencyBandwidth))) %>% filter(ExtractionMethod == as.character(Mode(df_func_rank_dep_severity$ExtractionMethod))) %>% filter(ExtractionMethod == as.character(Mode(df_func_rank_dep_severity$ExtractionMethod))) %>% filter(ConnectivityEstimator == as.character(Mode(df_func_rank_dep_severity$ConnectivityEstimator))) %>% filter(NodeGranularity == as.character(Mode(df_func_rank_dep_severity$NodeGranularity)))

df_func_rank_rum_severity <- df_func_rankings %>% filter(Phenotype=="Rumination_Severity", R2>max(predict_func_rum_severity))
df_func_rank_rum_severity <- df_func_rank_rum_severity %>% filter(SmoothingTolerance == as.character(Mode(df_func_rank_rum_severity$SmoothingTolerance))) %>% filter(FrequencyBandwidth == as.character(Mode(df_func_rank_rum_severity$FrequencyBandwidth))) %>% filter(ExtractionMethod == as.character(Mode(df_func_rank_rum_severity$ExtractionMethod)))

df_func_rank_dep_persistence <- df_func_rankings %>% filter(Phenotype=="Depression_Persistence", R2>max(predict_func_dep_persistence))
df_func_rank_dep_persistence <- df_func_rank_dep_persistence %>% filter(SmoothingTolerance == as.character(Mode(df_func_rank_dep_persistence$SmoothingTolerance))) %>% filter(FrequencyBandwidth == as.character(Mode(df_func_rank_dep_persistence$FrequencyBandwidth))) %>% filter(ExtractionMethod == as.character(Mode(df_func_rank_dep_persistence$ExtractionMethod)))

df_func_rank_rum_persistence <- df_func_rankings %>% filter(Phenotype=="Rumination_Persistence", R2>max(predict_func_rum_persistence))
df_func_rank_rum_persistence <- df_func_rank_rum_persistence %>% filter(SmoothingTolerance == as.character(Mode(df_func_rank_rum_persistence$SmoothingTolerance))) %>% filter(FrequencyBandwidth == as.character(Mode(df_func_rank_rum_persistence$FrequencyBandwidth))) %>% filter(ExtractionMethod == as.character(Mode(df_func_rank_rum_persistence$ExtractionMethod))) %>% filter(ConnectivityEstimator == as.character(Mode(df_func_rank_rum_persistence$ConnectivityEstimator)))

all_best_func <- rbind(df_func_rank_dep_severity, df_func_rank_rum_severity, df_func_rank_dep_persistence, df_func_rank_rum_persistence)
```

#### Structural
##### Connectome attribute-sensitivity
```{r dwi_trees_rum, fig.width = 16, fig.height=7, fig.align="center", message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
df_dwi_rum_persistence <- df_dwi %>% filter(Pheno=="Rumination_Persistence") %>% na.omit()
df_dwi_rum_severity <- df_dwi %>% filter(Pheno=="Rumination_Severity") %>% na.omit()
df_dwi_dep_persistence <- df_dwi %>% filter(Pheno=="Depression_Persistence") %>% na.omit()
df_dwi_dep_severity <- df_dwi %>% filter(Pheno=="Depression_Severity") %>% na.omit()

dwi_metas <- c("network", "minlength", "smooth", "res", "model", "extract")
dwi_factors <- c("network", "smooth", "minlength", "extract", "model", "res")
imp_names_dwi <- c("NetworkDefinition", "ExtractionMethod", "MinimumFiberLength", "ConnectivityEstimator", "NodeGranularity", "SmoothingTolerance")

# Rumination Persistence
tree_fit_res <- cv_decision_tree_dwi(df_dwi_rum_persistence, "R2")
tree_fit_dwi_rum_persistence <- tree_fit_res[[1]]
df <- tree_fit_res[[2]]
predict_dwi_rum_persistence <- max(unique(predict(tree_fit_dwi_rum_persistence, df)))
imp_R2_rum_persistence_dwi <- vi(tree_fit_dwi_rum_persistence, method="firm", scale=TRUE)
names(imp_R2_rum_persistence_dwi) <- c("grid", "Importance")
imp_R2_rum_persistence_dwi$grid <- imp_names_dwi
imp_R2_rum_persistence_dwi$outcome <- "Rumination_Persistence"

# Rumination Severity
tree_fit_res <- cv_decision_tree_dwi(df_dwi_rum_severity, "R2")
tree_fit_dwi_rum_severity <- tree_fit_res[[1]]
df <- tree_fit_res[[2]]
predict_dwi_rum_severity <- max(unique(predict(tree_fit_dwi_rum_severity, df)))
imp_R2_rum_severity_dwi <- vi(tree_fit_dwi_rum_severity, method="firm", scale=TRUE)
names(imp_R2_rum_severity_dwi) <- c("grid", "Importance")
imp_R2_rum_severity_dwi$grid <- imp_names_dwi
imp_R2_rum_severity_dwi$outcome <- "Rumination_Severity"

# Depression Persistence
tree_fit_res <- cv_decision_tree_dwi(df_dwi_dep_persistence, "R2")
tree_fit_dwi_dep_persistence <- tree_fit_res[[1]]
df <- tree_fit_res[[2]]
predict_dwi_dep_persistence <- max(unique(predict(tree_fit_dwi_dep_persistence, df)))
imp_R2_dep_persistence_dwi <- vi(tree_fit_dwi_dep_persistence, method="firm", scale=TRUE)
names(imp_R2_dep_persistence_dwi) <- c("grid", "Importance")
imp_R2_dep_persistence_dwi$grid <- imp_names_dwi
imp_R2_dep_persistence_dwi$outcome <- "Depression_Persistence"

# Depression Severity
tree_fit_res <- cv_decision_tree_dwi(df_dwi_dep_severity, "R2")
tree_fit_dwi_dep_severity <- tree_fit_res[[1]]
df <- tree_fit_res[[2]]
predict_dwi_dep_severity <- max(unique(predict(tree_fit_dwi_dep_severity, df)))
imp_R2_dep_severity_dwi <- vi(tree_fit_dwi_dep_severity, method="firm", scale=TRUE)
names(imp_R2_dep_severity_dwi) <- c("grid", "Importance")
imp_R2_dep_severity_dwi$grid <- imp_names_dwi
imp_R2_dep_severity_dwi$outcome <- "Depression_Severity"
```

```{r sensitivity_dwi, fig.width = 20, fig.height=20, fig.align="center", message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
imp_dwi_all <- rbind(imp_R2_rum_persistence_dwi, imp_R2_rum_severity_dwi, imp_R2_dep_persistence_dwi, imp_R2_dep_severity_dwi) %>%
    convert_as_factor(grid)

dwi_mean_imp <- as.data.frame(as.matrix(rowMeans(with( imp_dwi_all, tapply(Importance, list(grid,outcome), mean)))))
colnames(dwi_mean_imp) <- "imp"
dwi_mean_imp$vars <- rownames(dwi_mean_imp)
rownames(dwi_mean_imp) <- NULL
dwi_mean_imp <- dwi_mean_imp %>% as_tibble()
dwi_mean_imp <- dwi_mean_imp[, c(2,1)]
dwi_mean_imp$imp <- 1000*dwi_mean_imp$imp
dwi_mean_imp$vars <- gsub(" ", "", dwi_mean_imp$vars, fixed = TRUE)
dwi_mean_imp <- rbind(dwi_mean_imp, c("Phenotype", 1000))
dwi_mean_imp$imp <- as.numeric(dwi_mean_imp$imp)

p_dwi_all <- ggplot(imp_dwi_all, aes(x=grid, weight=Importance, fill=outcome)) + geom_bar(width=0.25, alpha=0.75) + ggtitle("\nStructural Connectome Hyperparameter Sensitivity") + xlab("Hyperparameter") + ylab("Variable Importance (VIP)") + scale_fill_tron(name="Phenotype", alpha = 0.75) + scale_fill_tron(name="Sensitivity_Statistic", alpha = 0.75) + theme(axis.text.y=element_text(size=18, colour="white"), axis.title.y=element_text(size=18, colour="white"), axis.text.x = element_text(angle = 45, size = 16, colour="white", vjust=0.4), plot.background = element_rect(fill="black", colour = 'black'), panel.background = element_rect(fill = "#141414"), panel.border = element_blank(), axis.title.x=element_text(size=18, colour="white", vjust=-0.5), legend.title=element_text(size=16, colour="white"), legend.text=element_text(size=14, colour="white"), legend.key = element_rect(fill = "#0D0D0D"), panel.grid = element_line(colour = "#000000"), axis.ticks = element_line(colour = "#CCCCCC"), legend.background = element_rect(fill = "#141414"), plot.title = element_text(size=28, hjust = 0.5, colour="white"))
p_dwi_all

knitr::kable(imp_dwi_all %>% mutate_if(is.numeric, format, digits=4), format = "latex", booktabs = TRUE) %>%
          kable_styling(latex_table_env = "tabular", latex_options = c("striped"), full_width = FALSE, position = "left", protect_latex = TRUE) %>% gsub("\\\\end\\{table\\}\n", "", .) %>% gsub("\n\\\\begin\\{table\\}", "", .) %>% gsub("\n\\\\centering", "", .) %>% gsub("\\_", "-", .) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% save_kable("sensitivity_dwi_tab.tex")
```

As was performed for the functional connectomes, we performed decision-tree sensitivity analysis whereby we explored the relative importance of each specific attribute of interest for capturing depression and rumination severity and persistence. Using this approach, we found that each phenotype exhibited identifiable affinities that could be ranked on the basis of their influence on predictive $R^{2}$ (Table \ref{tab:sensitivity_dwi} and the bottom plot in Figure \ref{fig:sensitivities_bar_plot_pheno}). Direction-extraction assumptions (deterministic or probabilistic) for attributing neurodevelopmental stochasticity to edges consistently held maximal importance across all phenotypes. In general, both depression and rumination phenotypes had similar sensitivity profiles, albeit they diverged with respect to minimum fiber-length, which influenced explained variance in rumination severity ($mean(VIP)_{rum-persistence}$=`r imp_dwi_all %>% filter(grid=='MinimumFiberLength' & outcome=="Rumination_Severity") %>% dplyr::select(Importance) %>% summarise_all(list(~(mean(., na.rm = TRUE)))) %>% .$Importance %>% round(2)`) alone. 

##### Top-performing connectome attributes
```{r gridsearch_dwi, message=FALSE, warning=FALSE, fig.align="center", fig.width = 16, fig.height=10, include=FALSE, out.width="100%", out.height="100%", echo=FALSE, cache=FALSE, eval=FALSE}
knitr::opts_chunk$set(comment = NA)

out2 <- grid_plot_dwi(df_dwi %>% dplyr::select(grid, directget, minlength, model, res, tol, network, Pheno, R2) %>% mutate_if(is.character,as.factor) %>% dplyr::rename(Phenotype = Pheno) %>% na.omit(), 'R2', dwi_mean_imp)
out2

if (interactive == TRUE){
    out2$width <- "1400px"
    out2$height <- "600px"
    out2$sizingPolicy$padding <- "0"
    out2$sizingPolicy$viewer$padding <- "0"
    out2$sizingPolicy$browser$padding <- "0"
    out2 <- htmlwidgets::prependContent(out2, htmltools::tags$h1(css))
    out2 <- htmlwidgets::prependContent(out2, htmltools::tags$h1("Structural Connectome Phenotype Optimization"))
    out2 <- htmlwidgets::prependContent(out2, htmltools::tags$h2("(Source Domain)"))
    htmlwidgets::saveWidget(out2, file = paste0(results_dir, "gridsearch_dwi.html"), selfcontained = TRUE, knitrOptions = list(message=FALSE, warning=FALSE, fig.align="center", echo=FALSE))
    URL <- paste0(results_dir, "gridsearch_dwi.html")
    out_png <- paste0(results_dir, "../figures/gridsearch_dwi.png")
    gsub_file(URL, "P(color", "P(R2 Quartile", fixed = TRUE)
    gsub_file(URL, "| color)", "| R2 Quartile", fixed = TRUE)
    webshot2::webshot(URL, delay = 1, file = out_png, vwidth = 1400, vheight = 600, zoom = 4, cliprect = 'viewport', max_concurrent = 12, useragent= 'Mozilla/5.0')
    include_graphics(out_png, dpi=600)
}
```

```{r rank_dwi_tables, echo=FALSE, fig.align="center", message=FALSE, warning=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
df_dwi_rankings <- df_dwi  %>%
  dplyr::select(grid, network, minlength, tol, model, res, directget, embedding, Pheno, R2) %>% mutate_if(is.character,as.factor) %>% filter(embedding=='ASE')

names(df_dwi_rankings) <- c("Grid", "NetworkDefinition", "MinimumFiberLength", "SmoothingTolerance", "ConnectivityEstimator", "NodeGranularity", "ExtractionMethod", "Embedding Method", "Phenotype", "R2")

df_dwi_rank_dep_severity <- df_dwi_rankings %>% filter(Phenotype=="Depression_Severity", R2>max(predict_dwi_dep_severity))
df_dwi_rank_dep_severity <- df_dwi_rank_dep_severity %>% filter(ExtractionMethod == as.character(Mode(df_dwi_rank_dep_severity$ExtractionMethod)))
df_dwi_rank_rum_severity <- df_dwi_rankings %>% filter(Phenotype=="Rumination_Severity", R2>max(predict_dwi_rum_severity))
df_dwi_rank_rum_severity <- df_dwi_rank_rum_severity %>% filter(ExtractionMethod == as.character(Mode(df_dwi_rank_rum_severity$ExtractionMethod))) %>% filter(MinimumFiberLength == as.character(Mode(df_dwi_rank_rum_severity$MinimumFiberLength)))
df_dwi_rank_dep_persistence <- df_dwi_rankings %>% filter(Phenotype=="Depression_Persistence", R2>max(predict_dwi_dep_persistence))
df_dwi_rank_dep_persistence <- df_dwi_rank_dep_persistence %>% filter(ExtractionMethod == as.character(Mode(df_dwi_rank_dep_persistence$ExtractionMethod)))
df_dwi_rank_rum_persistence <- df_dwi_rankings %>% filter(Phenotype=="Rumination_Persistence", R2>max(predict_dwi_rum_persistence))
df_dwi_rank_rum_persistence <- df_dwi_rank_rum_persistence %>% filter(ExtractionMethod == as.character(Mode(df_dwi_rank_rum_persistence$ExtractionMethod)))%>% filter(MinimumFiberLength == as.character(Mode(df_dwi_rank_rum_persistence$MinimumFiberLength)))

all_best_dwi <- rbind(df_dwi_rank_dep_severity, df_dwi_rank_rum_severity, df_dwi_rank_dep_persistence, df_dwi_rank_rum_persistence)
```

When performing gridsearch in the source domain, we made a number of key insights. In the functional connectome case, all phenotypes had an affinity for the triple-network intersection subnetwork. Depression persistence also had the widest spectrum of high-performing recipes that tracked closely with that which was observed for depression severity, which differed only in that it did not include perform well at >0.028 Hz. Rumination persistence performed more poorly at >0.0 8Hz and when using a partial correlation estimator. Finally, rumination severity showed only a vary narrow window of high-performing recipes comprising a covariance estimator, >0.08 Hz frequency bandwidth, signal average, 600 Nodes, and either 6mm FWHM or no smoothing but not 3mm. In the structural connectome case, virtually all phenotypes (with the exception of age) had an affinity for the dorsal language network and either long or short (but not medium fiber lengths), yet depression and rumination persistence showed opposing affinities for deterministic and probabilistic tractography, respectively.

```{r sensitivity_barplot, fig.width = 18.7, fig.height=10, fig.align="center", message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, eval=FALSE}
sensitivity_barplot <- grid_arrange_shared_legend(p_func_all, p_dwi_all, nrow=1, ncol=2, title = "\n\nRelative Sensitivities of Attribute-Assigning Connectome Hyperparameters on TN and LN Multiverse R2\n")
sensitivity_barplot
```

::: {.center data-latex=""}
\begin{figure}
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio=true,angle=270]{../figures/sensitivity_barplot-1.pdf}
\caption{(Source Domain) \label{fig:sensitivities_bar_plot_pheno}\scriptsize{The figure mosaic depicts two stacked bar plots (left: functional, right: structural) of connectome attributes as they contribute to prediction of rumination and depression severity and persistence in the source domain. Here, the x-axes contain manipulated connectome-generating hyperparameters, and the y-axis depicts the relative variable importance (VIP) index as defined by a Classification and Regression Trees (CART) model and whereby each tuning phenotype is indexed by color (red=Depression Persistence, blue=Depression severity, Yellow=Rumination Persistence, Green=Rumination Severity).}}
\end{figure}
\setlength{\belowcaptionskip}{-10pt}
:::

::: {.center data-latex=""}
\begin{table}
\begin{minipage}{\textwidth}
\centering
\adjustbox{width=0.3\textwidth,height=0.3\textheight,keepaspectratio=true}{\subfile{Chapter_IV/results/sensitivity_dwi_tab}}
\subcaption{\label{tab:sensitivity_dwi}\scriptsize{Structural (LN)}}
\vspace{\baselineskip}
\adjustbox{width=0.3\textwidth,height=0.3\textheight,keepaspectratio=true}{\subfile{Chapter_IV/results/sensitivity_func_tab}}
\subcaption{\label{tab:sensitivity_func}\scriptsize{Functional (TN)}}
\end{minipage}
\caption{(Source Domain) \label{tab:sensitivity}These tables summarize the sensitivity of predictive $R^{2}$ to choice of connectome attributes}
\end{table}
\setlength{\belowcaptionskip}{-10pt}
:::

<!-- ::: {.center data-latex=""} -->
<!-- \begin{figure} -->
<!-- \centering -->
<!-- \includegraphics[width=\textheight,height=\textwidth,keepaspectratio=true,angle=270]{../figures/gridsearch_func-1.pdf} -->
<!-- \caption{(Source Domain) \label{fig:gridsearch_func}\scriptsize{The figure depicts an alluvial cobweb plot, which represents the conditional frequencies of the relationships among each functional connectome-generating hyperparameter, listed horizontally along, the x-axis. The vertical height of each "stratum" at each x-axis tick corresponds to the level of each hyperparameter, and the density of the colored flows that intersect with them are proportional to the flow quantity associated with quartiles of discriminability~\cite{ggalluvial}. While difficult to parse directly through visual inspection, these plots are intended less formally as a heuristic device that conveys the non-linearity of choice combinations as they influence the amplitude of connectome discriminability.}} -->
<!-- \end{figure} -->
<!-- \setlength{\belowcaptionskip}{-10pt} -->

<!-- \begin{figure} -->
<!-- \centering -->
<!-- \includegraphics[width=\textheight,height=\textwidth,keepaspectratio=true,angle=270]{../figures/gridsearch_dwi-1.pdf} -->
<!-- \caption{(Source Domain) \label{fig:gridsearch_dwi}\scriptsize{The figure depicts an alluvial cobweb plot, which represents the conditional frequencies of the relationships among each structural connectome-generating hyperparameter, listed horizontally along, the x-axis. The vertical height of each "stratum" at each x-axis tick corresponds to the level of each hyperparameter, and the density of the colored flows that intersect with them are proportional to the flow quantity associated with quartiles of discriminability~\cite{ggalluvial}. While difficult to parse directly through visual inspection, these plots are intended less formally as a heuristic device that conveys the non-linearity of choice combinations as they influence the amplitude of connectome discriminability.}} -->
<!-- \end{figure} -->
<!-- \setlength{\belowcaptionskip}{-10pt} -->
<!-- ::: -->

Based on our sensitivity analyses, we next selected a subset of recipes of functional and structural connectome attributes based on the ability of the corresponding embedded connectomes to explain phenotypically distinct variance in rumination and depression construed as persistence and contemporaneous severity. To perform this selection in an unbiased way, we used the decision-tree cut points learned by minimizing Gini impurity of $R^{2}$ during cross-validation~\cite{Breiman1996} (Functional: depression severity = $R^{2}$>`r predict_func_dep_severity %>% round(3)`, rumination severity = $R^{2}$>`r predict_func_rum_severity %>% round(3)`, depression persistence = $R^{2}$>`r predict_func_dep_persistence %>% round(3)`; Structural: depression severity = $R^{2}$>`r predict_dwi_dep_severity %>% round(3)`, rumination severity = $R^{2}$>`r predict_dwi_rum_severity %>% round(3)`, depression persistence = $R^{2}$>`r predict_dwi_dep_persistence %>% round(3)`), while also controlling for Smoothing Tolerance for functional connectomes and Direction Extraction method for structural connectomes since those attributes were found to be universally important across each of the mood phenotypes. The latter was accomplished by further filtering the selected subsets by the respective the statistical mode of those attributes for each phenotype. 

```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
setwd("../results")
save(df_func, file = "df_func.RData")
save(df_dwi, file = "df_dwi.RData")
```

```{python eval=FALSE,include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
import pandas as pd
import seaborn as sns
from pynets.core.utils import flatten
import os
import ast
import json
import glob
import re
import numpy as np
from collections import Counter
from itertools import groupby
from pathlib import Path
import mplcyberpunk
from pynets.core.utils import load_runconfig
import random
import matplotlib
from matplotlib import pyplot as plt
from nilearn import plotting as niplot
import pkg_resources
from pynets.plotting.plot_gen import create_gb_palette
import nibabel as nib
from matplotlib import colors
from scipy.spatial import distance
from sklearn.preprocessing import StandardScaler
import itertools
from pynets.core.thresholding import normalize
import networkx as nx
from PIL import Image, ImageFont, ImageDraw
from pynets.stats.utils import cleanNullTerms

plt.style.use("cyberpunk")

ch2better_loc = pkg_resources.resource_filename(
    "pynets", "templates/ch2better.nii.gz"
)

working = f"/home/dpys/iccs_all/pruned_atlases"

figures_dir = f"/home/dpys/Documents/Dissertation/Chapter_IV/data/TrainTest_set/figures"

results_dir = f"/home/dpys/Documents/Dissertation/Chapter_IV/data/TrainTest_set/results"

try:
    nib.load(ch2better_loc)
except ImportError as e:
    print(e, f"\nCannot load plotting template. Do you have git-lfs "
             f"installed?")

hardcoded_params = load_runconfig()

try:
    color_theme = random.choice(
        [
            "Purples_d",
            "Blues_d",
            "Greens_d",
            "Oranges_d",
            "Reds_d",
            "YlOrBr_d",
            "YlOrRd_d",
            "OrRd_d",
            "PuRd_d",
            "RdPu_d",
            "BuPu_d",
            "GnBu_d",
            "PuBu_d",
            "YlGnBu_d",
            "PuBuGn_d",
            "BuGn_d",
            "YlGn_d",
        ]
    )

    connectogram = hardcoded_params["plotting"]["connectogram"][0]
    glassbrain = hardcoded_params["plotting"]["glassbrain"][0]
    adjacency = hardcoded_params["plotting"]["adjacency"][0]
    dpi_resolution = hardcoded_params["plotting"]["dpi"][0]
    labeling_atlas = hardcoded_params["plotting"]["labeling_atlas"][0]
except KeyError as e:
    print(e,
          "Plotting configuration not successfully extracted "
          "from runconfig.yaml"
          )

res_map = {'200': '77', '400': '135', '600': '180', '800': '228'}


def replace_lps_with_int(x):
    clean_list = ast.literal_eval(re.sub(' +', ' ', str(x).lstrip().replace('\n', '')).replace('[ ', '[').replace(' ]', ']').replace(' ', ', '))

    if 'rsn-' in str(x):
        return [i.split('_')[0] for i in clean_list]
    else:
        return clean_list
              
def make_lp_dict(df, modality, master_dict, rsn, subdivision, res):
    if rsn not in master_dict.keys():
        master_dict[rsn] = {}
    if subdivision not in master_dict[rsn].keys():
        master_dict[rsn][subdivision] = {}
    if res not in master_dict[rsn][subdivision].keys():
        master_dict[rsn][subdivision][res] = {}
    if subdivision == 'union':
        rsn_abbr = 'triple'
    elif subdivision == 'intersection':
        rsn_abbr = 'kmeans'
    elif subdivision == 'dorsal':
        rsn_abbr = rsn

    lps = dict(sorted(dict(Counter(list(flatten([list([int(j) for j in i]) for i in list(df.loc[(df.network == rsn_abbr) & (df.res == str(res))]['lp_importance'].values)])))).items(), key=lambda item: item[1], reverse=True))
    for lp in list(lps.keys()):
        master_dict[rsn][subdivision][res][lp] = {}
        master_dict[rsn][subdivision][res][lp]['occurrence'] = lps[lp]
        master_dict[rsn][subdivision][res][lp]['score'] = np.nanmean(np.array(df.loc[(df['network']==rsn_abbr) & (df['res'].astype('str')==str(res)) & (df['lp_importance'].apply(str).str.contains(str(lp)))]['Score'].values))
    return master_dict


def load_best_lps(results_file):
    if not os.path.isfile(results_file):
        raise FileNotFoundError(f"File {results_file} not found!")
    else:
        df = pd.read_csv(results_file)
        df.res = df.res.astype('str')
        df['res'] = df['res'].str.replace('77', '200')
        df['res'] = df['res'].str.replace('135', '400')
        df['res'] = df['res'].str.replace('180', '600')
        df['res'] = df['res'].str.replace('228', '800')
        df['lp_importance'] = df['lp_importance'].apply(lambda x: replace_lps_with_int(x))
        
        master_dict = {}
        if modality == 'func':
            master_dict = make_lp_dict(df, modality, master_dict, 'triple', 'intersection', '400')
            master_dict = make_lp_dict(df, modality, master_dict, 'triple', 'intersection', '600')
            master_dict = make_lp_dict(df, modality, master_dict, 'triple', 'union', '800')
        else:
            master_dict = make_lp_dict(df, modality, master_dict, 'triple', 'intersection', '400')
            master_dict = make_lp_dict(df, modality, master_dict, 'triple', 'union', '200')
            master_dict = make_lp_dict(df, modality, master_dict, 'language', 'dorsal', '400')
    return master_dict, df


def make_node_dict_from_parcellation(parcellation, vox_size='2mm'):
    from pynets.core.nodemaker import get_names_and_coords_of_parcels, \
        parcel_naming
    from pynets.core.utils import save_coords_and_labels_to_json
    dir_path = str(Path(parcellation).parent)
    coords, _, _, label_intensities = get_names_and_coords_of_parcels(parcellation)
    labels = parcel_naming(coords, vox_size)
    node_file = save_coords_and_labels_to_json(coords, labels, dir_path, network='all_nodes', indices=label_intensities)
    return node_file
    

def CountFrequency(my_list): 
    freq = {} 
    for item in my_list: 
        if (item in freq): 
            freq[item] += 1
        else: 
            freq[item] = 1
    return freq
    
    
def grab_coords_labels(node_file):
    with open(node_file, 'r+') as f:
        node_dict = json.load(f)
    indices = [i['index'] for i in
               node_dict]
    coords = [i['coord'] for i in
              node_dict]
    if isinstance(node_dict[0]['label'], str):
        labels = [
            ast.literal_eval(
                re.search('({.+})',
                          i['label']).group(0))[
                'BrainnetomeAtlasFan2016'] for i in
            node_dict]
    else:
        labels = [
            list(i['label'])[0][
                'BrainnetomeAtlasFan2016'] for i in
            node_dict]
    return indices, coords, labels


def drop_badixs_from_parcellation(uatlas, bad_idxs):
    import os
    import nibabel as nib
    import numpy as np
    from nipype.utils.filemanip import fname_presuffix
    from pynets.core.nodemaker import enforce_hem_distinct_consecutive_labels

    parcellation_img = nib.load(uatlas)

    bad_idxs = sorted(list(set(bad_idxs)), reverse=True)

    parlist_img_data = parcellation_img.get_fdata()
    for val in bad_idxs:
        print(f"Removing: {str(val)}...")
        parlist_img_data[np.where(parlist_img_data == val)] = 0

    parcellation = fname_presuffix(
        uatlas, suffix="_pruned_predict",
        newpath=os.path.dirname(uatlas))
    nib.save(
        nib.Nifti1Image(parlist_img_data,
                        affine=parcellation_img.affine),
        parcellation)

    print(f"{len(np.unique(parlist_img_data))} parcels remaining")
    parcellation = enforce_hem_distinct_consecutive_labels(parcellation)[0]
    return parcellation
    
phenotypes = ['Rumination_Persistence', 'Depression_Persistence']

dfs_vip = []
parcellation_dict = {}
views = ["x", "z"]
for modality in ['func', 'dwi']:
    source_dir_path = f"/home/dpys/Documents/Dissertation/Chapter_IV/data/TrainTest_set/data/tuning_set/predictions_{modality}"
    for pheno in phenotypes:
        filename = f"final_df_{modality}_ASE_{pheno}_clean"
        if os.path.isfile(f"{source_dir_path}/{filename}.csv"):
            master_dict, df = load_best_lps(f"{source_dir_path}/{filename}.csv")
            for rsn in ['triple', 'language']:
                if rsn in master_dict.keys():
                    for subdivision in ['union', 'intersection', 'dorsal', 'ventral']:
                        if subdivision in master_dict[rsn].keys():
                            for res in ['200', '400', '600', '800']:
                                if res in master_dict[rsn][subdivision].keys():
                                    if subdivision == 'union':
                                        rsn_abbr = 'triple'
                                        col_map = 'Blues_d'
                                    elif subdivision == 'intersection':
                                        rsn_abbr = 'kmeans'
                                        col_map = 'Purples_d'
                                    elif subdivision == 'dorsal':
                                        rsn_abbr = rsn
                                        col_map = 'Oranges_d'
                               
                                    parcellation = f"{working}/rsn-{rsn_abbr}_res-{res_map[res]}_pruned.nii.gz"
                                                                   
                                    if rsn_abbr not in parcellation_dict.keys():
                                        parcellation_dict[rsn_abbr] = {}
                                    if res not in parcellation_dict[rsn_abbr].keys():
                                        parcellation_dict[rsn_abbr][res] = {}
                                        parcellation_dict[rsn_abbr][res]['bad_indices'] = []
                                        parcellation_dict[rsn_abbr][res]['parcellation'] = parcellation
                                        
                                    node_file = make_node_dict_from_parcellation(parcellation, vox_size='2mm')
                                    
                                    [indices, coords, labels] = grab_coords_labels(node_file)
            
                                    lp_ixs = [str(i) for i in list(master_dict[rsn][subdivision][res].keys()) if str(i) in indices]
                                    good_idxs = [j for j, x in enumerate([True if i in lp_ixs else False for i in indices]) if x]
                                    indices_lps = [indices[i] for i in good_idxs]
                                    coords_lps = [coords[i] for i in good_idxs]
                                    labels_lps = [labels[i] for i in good_idxs]
                                    labels_lps_corrected = []
                                    for i in labels_lps:
                                        if i != 'Unlabeled' and ('_L' in i):
                                            labels_lps_corrected.append(f"{i.split('_')[0]}_{i.split('_')[1]}".replace("_L", "_R"))
                                        elif i != 'Unlabeled' and ('_R' in i):
                                            labels_lps_corrected.append(f"{i.split('_')[0]}_{i.split('_')[1]}".replace("_R", "_L"))
                                        else:
                                            labels_lps_corrected.append('Unlabeled')
                                    labels_lps = labels_lps_corrected
                                    vips = [master_dict[rsn][subdivision][res][int(i)]['score'] for i in indices_lps]
                                    occurrences = [master_dict[rsn][subdivision][res][int(i)]['occurrence'] for i in indices_lps]
                                    
                                    dist = np.array(vips)*np.array(occurrences)
                                    bad_ixs = list(flatten([np.where(dist==x)[0].tolist() for x in dist[np.where(dist<np.percentile(dist, 25))]])) 
                                    parcellation_dict[rsn_abbr][res]['bad_indices'].extend(bad_ixs)
                                    
                                    # Create feature-importance "graph"
                                    df_case = df.loc[(df['network']==rsn_abbr) & (df['res'].astype('str')==str(res))]['lp_importance']
                                    
                                    # Create dataframe to house weighted vips
                                    lp_labels_long = [f"{i}_{l}" for i, l in list(zip(lp_ixs, labels_lps))]
                                    best_lps_dict = dict(sorted(dict(zip(lp_labels_long, dist.tolist())).items(), key=lambda item: item[1], reverse=True))
                                    df_vips = pd.DataFrame({'Best_regions': []})
                                    df_vips['Best_regions'] = df_vips['Best_regions'].astype('object')
                                    df_vips.at[1, 'Best_regions'] = sorted(dict(Counter(['_'.join(i.split('_')[1:]) for i in best_lps_dict.keys() if best_lps_dict[i]>1 and i != 'Unlabeled'])), reverse=True)
                                    df_vips['network'] = rsn_abbr
                                    df_vips['res'] = res
                                    df_vips['modality'] = modality
                                    df_vips['phenotype'] = pheno
                                    dfs_vip.append(df_vips)
                                    
                                    G = nx.Graph(directed=False)
                                    G.add_nodes_from(lp_ixs)
                                    edge_combos = list(itertools.combinations(lp_ixs, 2))
                                    b = []
                                    seen = set()
                                    for t in edge_combos:
                                        s = tuple(sorted(t))
                                        if s not in seen:
                                            seen.add(s)
                                            b.append(t)
              
                                    for source, target in b:
                                        G.add_edge(source, target)
                                        co_occur = 0
                                        for feat_space in list(df_case.values):
                                            if source in feat_space and target in feat_space:
                                                co_occur += 1
                                        G[source][target]["weight"] = co_occur
                                    in_mat = nx.to_numpy_array(G)
                                    if modality == 'dwi':
                                        edge_cmap = 'binary'
                                    else:
                                        edge_cmap = 'Greens'
                                        
                                    in_mat = normalize(in_mat)
                                        
                                    clust_pal = sns.color_palette(col_map, n_colors=len(occurrences))
                                    clust_pal_nodes = colors.to_rgba_array(clust_pal)
                                    
                                    connectome = niplot.plot_connectome(
                                        np.zeros(shape=(1, 1)), [(0, 0, 0)], node_size=0.0001,
                                        black_bg=True, display_mode=''.join(views), annotate=False
                                    )
                                    connectome.add_overlay(ch2better_loc, alpha=0.45, cmap=plt.cm.gray)
                        
                                    [
                                        conn_matrix,
                                        clust_pal_edges,
                                        _,
                                        node_sizes,
                                        edge_sizes,
                                        _,
                                        z_max,
                                        coords_lps,
                                        labels_lps,
                                    ] = create_gb_palette(in_mat, edge_cmap,
                                                          coords_lps, labels_lps,
                                                          prune=False,
                                                          centrality_type=vips,
                                                          max_node_size=50)
            
                                    scaler = StandardScaler()
                                    occurrences_scaled = scaler.fit_transform(np.array([float(i) for i in occurrences]).reshape(-1, 1))
            
                                    clust_pal_nodes = np.vstack([x for _, x in sorted(zip(list(occurrences_scaled[None,:]), list(clust_pal_nodes[None,:])))])
            
            
                                    if modality == 'dwi':
                                        edge_alpha = 0.20
                                        z_max = 1
                                        z_min = 1
                                        edge_thr = "10%"
                                        clust_pal_edges = plt.cm.binary
                                        edge_kwargs = {"alpha": 0.20, "lineStyle": "dashed"}
                                    else:
                                        edge_alpha = 0.50
                                        z_min = min(in_mat[in_mat>0.01])
                                        edge_thr = "90%"
                                        edge_kwargs = {"alpha": edge_alpha, 'zorder': 1}
                                        
                                    connectome.add_graph(
                                        in_mat,
                                        coords_lps,
                                        edge_threshold=edge_thr,
                                        edge_cmap=clust_pal_edges,
                                        edge_vmax=float(z_max),
                                        edge_vmin=float(z_min),
                                        node_size=node_sizes,
                                        node_color=clust_pal_nodes,
                                        edge_kwargs=edge_kwargs,
                                        node_kwargs={'zorder': 1000}
                                    )
                                    
                                    if modality == 'dwi':
                                        for view in views:
                                            mod_lines = []
                                            for line, edge_size in list(
                                                zip(connectome.axes[view].ax.lines, edge_sizes)
                                            ):
                                                line.set_lw(edge_size*0.1)
                                                mod_lines.append(line)
                                            connectome.axes[view].ax.lines = mod_lines
                                            mplcyberpunk.make_lines_glow(connectome.axes[view].ax,
                                                                         n_glow_lines=7, diff_linewidth=0.15,
                                                                         alpha_line=0.15)
                                    else:
                                        for view in views:
                                            mod_lines = []
                                            for line, edge_size in list(
                                                zip(connectome.axes[view].ax.lines, edge_sizes)
                                            ):
                                                line.set_lw(edge_size*0.35)
                                                mod_lines.append(line)
                                            connectome.axes[view].ax.lines = mod_lines
                                         
                                    zorder = 10000
                                    for view in views:
                                        coord_anns = []
                                        for coord, label in list(zip(coords_lps, labels_lps)):
                                            if view == 'x':
                                                coord_ann = (coord[1], coord[2])
                                            if view == 'y':
                                                coord_ann = (coord[0], coord[2])
                                            if view == 'z':
                                                coord_ann = (coord[0], coord[1])
                            
                                            if len(coord_anns) > 0:
                                                dists = []
                                                for c in coord_anns:
                                                    dists.append(distance.euclidean(coord_ann, c))
                                                if any([i < 20 for i in dists]):
                                                    continue
                                            if label == 'Unlabeled':
                                                continue
                                            coord_anns.append(coord_ann)
                                            connectome.axes[view].ax.set_axisbelow(False)
                                            connectome.axes[view].ax.annotate(label,
                                                                              coord_ann,
                                                                              xycoords='data',
                                                                              textcoords='offset points',
                                                                              xytext=(-0.0001, -0.0001),
                                                                              horizontalalignment='center',
                                                                              verticalalignment='top',
                                                                              fontsize='2.7',
                                                                              fontweight='extra bold',
                                                                              zorder=zorder,
                                                                              color='black')
                                            zorder += 10
                            
                                            connectome.axes[view].ax.annotate(label,
                                                                              coord_ann,
                                                                              xycoords='data',
                                                                              textcoords='offset points',
                                                                              xytext=(0, 0),
                                                                              horizontalalignment='center',
                                                                              verticalalignment='top',
                                                                              fontsize='2.65',
                                                                              fontweight='bold',
                                                                              zorder=zorder,
                                                                              color='red')
                                            zorder += 100
                                    out_path_fig_conn = f"/tmp/{rsn}_{res}_{subdivision}_{modality}_{pheno}_vip_connectome.png"
                                    connectome.savefig(out_path_fig_conn, dpi=600)

df_vip_final = pd.concat(dfs_vip)
def f(x):    
   return [y for y in x if 'Unlabeled' not in y]
   
df_vip_final['Best_regions'] = df_vip_final['Best_regions'].apply(f)
df_vip_final.to_csv(f"{results_dir}/all_phenotype_weighted_vips_regions.csv", index=False)

image_dict = {}
for modality in ['func', 'dwi']:
    if modality == 'func':
        best_nets = [{'rumination_persist_phenotype': ('language', '600')}, {'depression_persist_phenotype': ('language', '800')}]
    if modality == 'dwi':
        best_nets = [{'rumination_persist_phenotype': ('intersection', '400')}, {'depression_persist_phenotype': ('intersection', '400')}]
      
    if modality not in image_dict.keys():
        image_dict[modality] = {}
    for pheno in phenotypes:
        out = [i[pheno] for i in best_nets if pheno == list(i.keys())[0]][0]
        best_rsn = out[0]
        best_res = out[1]
        if pheno not in image_dict[modality].keys():
            image_dict[modality][pheno] = {}
        for rsn in ['triple', 'language']:
            if rsn not in image_dict[modality][pheno].keys():
                image_dict[modality][pheno][rsn] = {}
            for subdivision in ['union', 'intersection', 'dorsal']:
                if subdivision not in image_dict[modality][pheno][rsn].keys():
                    image_dict[modality][pheno][rsn][subdivision] = {}
                for res in ['200', '400', '600', '800']:
                    if subdivision not in image_dict[modality][pheno][rsn][subdivision].keys():
                        image_dict[modality][pheno][rsn][subdivision][res] = {}
                    in_file = f"/tmp/{rsn}_{res}_{subdivision}_{modality}_{pheno}_vip_connectome.png"
                    if not os.path.isfile(in_file):
                        continue
                    else:
                        if subdivision == 'dorsal':
                            net = 'language'
                        else:
                            net = subdivision
                        if net == best_rsn and res == best_res:
                            image_dict[modality][pheno][rsn][subdivision][res] = in_file

image_dict = cleanNullTerms(image_dict)

phenotypes = ['rumination_persist_phenotype', 'depression_persist_phenotype']

pheno_map = {'rumination_persist_phenotype': 'Rumination Persistent Phenotype', 'depression_persist_phenotype': 'Depression Persistent Phenotype'}

def get_concat_h(im1, im2):
    dst = Image.new('RGB', (im1.width + im2.width, im1.height))
    dst.paste(im1, (0, 0))
    dst.paste(im2, (im1.width, 0))
    return dst

def get_concat_v(im1, im2):
    dst = Image.new('RGB', (im1.width, im1.height + im2.height))
    dst.paste(im1, (0, 0))
    dst.paste(im2, (0, im1.height))
    return dst
    
def add_margin(pil_img, top, right, bottom, left, color):
    width, height = pil_img.size
    new_width = width + right + left
    new_height = height + top + bottom
    result = Image.new(pil_img.mode, (new_width, new_height), color)
    result.paste(pil_img, (left, top))
    return result

final_imgs = {}
font_path = "/home/dpys/Desktop/misc/LIWC2015-app-1.3.1/org/apache/pdfbox/resources/ttf/Arial-BoldMT.ttf"
fnt_main = ImageFont.truetype(font_path, 72)
fnt_sub = ImageFont.truetype(font_path, 48)
for modality in ['func', 'dwi']:
    rum_pheno_images = []
    dep_pheno_images = []
    for pheno in phenotypes:
        rsn = list(image_dict[modality][pheno].keys())[0]
        subdivision = list(image_dict[modality][pheno][rsn].keys())[0]
        res = list(image_dict[modality][pheno][rsn][subdivision].keys())[0]
        img = Image.open(image_dict[modality][pheno][rsn][subdivision][res])
        draw = ImageDraw.Draw(img)
        draw.text((img.getbbox()[3]/2-100, 0), f"{pheno_map[pheno]}",(255,255,255),font=fnt_main, align='left')
        draw.text((img.getbbox()[3]/2-100, img.getbbox()[3]-100), f"Best Network: {rsn}-{subdivision}, {res} nodes", (192, 192, 192),font=fnt_sub, align='left')
        img = add_margin(img, 15, 5, 15, 5, (0,0,0))
        if 'rum' in pheno:
          rum_pheno_images.append(img)
        if 'dep' in pheno:
          dep_pheno_images.append(img)    
    
    v_concatted_rum = rum_pheno_images[0]
    i = 1
    for h in range(len(rum_pheno_images) - 1):
        v_concatted_rum = get_concat_v(v_concatted_rum, rum_pheno_images[i])
        i += 1
    
    v_concatted_dep = dep_pheno_images[0]
    i = 1
    for h in range(len(dep_pheno_images) - 1):
        v_concatted_dep = get_concat_v(v_concatted_dep, dep_pheno_images[i])
        i += 1
    
    final_concat = add_margin(get_concat_h(v_concatted_rum, v_concatted_dep), 200, 0, 10, 0, (0,0,0))
    draw = ImageDraw.Draw(final_concat)
    if modality == 'func':
        mod = 'Functional'
    else:
        mod = 'Structural'
    draw.text((final_concat.getbbox()[2]/2 - 850, 0), f"{mod}",(218,165,32),font=fnt_main, align='center')

    final_concat = add_margin(final_concat, 200, 0, 0, 0, (0,0,0))

    final_imgs[modality] = final_concat
    
    v_concatted_all_mods = get_concat_v(final_imgs['func'], final_imgs['dwi'])
    
    v_concatted_all_mods.save(f"{figures_dir}/tuning_set_mosaic.png")

# Prune consistently low-importance nodes
for rsn_abbr in ['language', 'kmeans', 'triple']:
    for res in ['200', '400', '600', '800']:
         if res in parcellation_dict[rsn_abbr].keys():
             if 'final_bad_indices' not in parcellation_dict[rsn_abbr][res].keys():
                parcellation_dict[rsn_abbr][res]['final_bad_indices'] = []
             counts = CountFrequency(parcellation_dict[rsn_abbr][res]['bad_indices'])
             for k, v in counts.items():
                 if v > 1:
                     parcellation_dict[rsn_abbr][res]['final_bad_indices'].append(k)
             out_file = drop_badixs_from_parcellation(parcellation_dict[rsn_abbr][res]['parcellation'], parcellation_dict[rsn_abbr][res]['final_bad_indices'])
```

# (Part II) Evaluating Classifiers of Future Depression Risk with Attributed Connectomes and Other Features
## Summarize behavioral data in the target domain
```{r TrainTest_behavioral, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, eval=FALSE}
TrainTest_loc <- paste0(data_dir, 'TrainTest_set/')
df_TrainTest_behavioral <- read.csv(paste(data_dir, "df_depressed_TrainTest_final.csv", sep=''))

df_TrainTest_behavioral <- df_TrainTest_behavioral %>% mutate(participant_id = as.character(participant_id)) %>% as_tibble() %>% filter(usable_mri==1)
df_TrainTest_behavioral$past_depression <- as.factor(tidyr::replace_na(as.character(df_TrainTest_behavioral$past_depression), 0))

df_TrainTest_behavioral_complete <- df_TrainTest_behavioral %>% dplyr::select(total_study_duration, num_visits) %>% na.omit()
df_clust <- as.matrix(cbind(df_TrainTest_behavioral_complete$total_study_duration, df_TrainTest_behavioral_complete$num_visits))

silhouette_score <- function(k, df_clust){
  km <- kmeans(x=df_clust, centers=k, nstart=3)
  ss <- silhouette(km$cluster, dist(df_clust))
  mean(ss[, 3])
}

#for (k in 3:9){
#  print(paste("k:", k, sep=" "))
#  print(silhouette_score(k, df_clust))
#}
set.seed(42)
time_clusts <- kmeans(x=df_clust, centers=7)
centers <- time_clusts$centers[,1]
df_TrainTest_behavioral_complete$time_clusters <- as.factor(time_clusts$cluster)

df_TrainTest_behavioral_complete$time_clusters <- factor(df_TrainTest_behavioral_complete$time_clusters,
levels = c(1, 2, 3, 4, 5, 6, 7),
labels = c(paste(round(time_clusts$centers[,1][1]/30.417, digit=0), "mo / ", round(time_clusts$centers[,2][1], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][2]/30.417, digit=0), "mo / ", round(time_clusts$centers[,2][2], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][3]/30.417, digit=0), "mo / ", round(time_clusts$centers[,2][3], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][4]/30.417, digit=0), "mo / ", round(time_clusts$centers[,2][4], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][5]/30.417, digit=0), "mo / ", round(time_clusts$centers[,2][5], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][6]/30.417, digit=0), "mo / ", round(time_clusts$centers[,2][6], digit=0)[[1]], " visits", sep=""), paste(round(time_clusts$centers[,1][7]/30.417, digit=0), "mo / ", round(time_clusts$centers[,2][7], digit=0)[[1]], " visits", sep="")))
time_clust_labs_TrainTest <- fct_count(df_TrainTest_behavioral_complete$time_clusters)
time_clust_labs_TrainTest$`Longitudinal Study Participation Clusters` <- time_clust_labs_TrainTest$f
time_clust_labs_TrainTest$N <- time_clust_labs_TrainTest$n
time_clust_labs_TrainTest <- time_clust_labs_TrainTest %>% dplyr::select(-"f", -"n")

time_clusts$cluster <- df_TrainTest_behavioral_complete$time_clusters

out <- fviz_cluster(time_clusts, data = df_TrainTest_behavioral_complete %>% dplyr::select(total_study_duration, num_visits), repel=TRUE, xlab="Duration of Study Participation", ylab="Number of Study Visits", ggtheme=theme_void(), main = "Longitudinal Study Visit-Duration Clusters", geom = c("point"), palette = pal_tron(alpha=0.75)(7), stand=FALSE) + theme(plot.title = element_text(hjust = 0.5, colour="white"), axis.text=element_text(size=18, colour="white"), axis.title.y=element_text(size=18, angle = 90, colour="white"), axis.title.x=element_text(size=18, colour="white"), legend.title=element_text(size=16, colour="white"), legend.text=element_text(size=14, colour="white"), plot.background = element_rect(fill = "black"), panel.background = element_rect(fill = "black"), legend.key = element_rect(fill = "black"))
out

df_TrainTest_behavioral$sex <- ordered(as.factor(df_TrainTest_behavioral$sex),
levels = c(0, 1),
labels = c("Male", "Female"))
gender_labs <- fct_count(df_TrainTest_behavioral$sex)

df_TrainTest_behavioral$dataset <- as.factor(df_TrainTest_behavioral$dataset)
levels(df_TrainTest_behavioral$dataset) <- c("SWU", "NKI")
df_TrainTest_behavioral$dataset <- as.factor(tidyr::replace_na(as.character(df_TrainTest_behavioral$dataset), 'NKI'))
dataset_labs <- fct_count(df_TrainTest_behavioral$dataset)

df_TrainTest_behavioral$race <- as.factor(as.character(df_TrainTest_behavioral$race))
df_TrainTest_behavioral$ethnicity <- as.factor(as.character(df_TrainTest_behavioral$ethnicity))
df_TrainTest_behavioral$language <- as.factor(as.character(df_TrainTest_behavioral$language))
df_TrainTest_behavioral$num_visits <- as.factor(as.character(df_TrainTest_behavioral$num_visits))

sample_summary3 <- df_TrainTest_behavioral %>%
  summarize(
    `Total N` = length(participant_id),
    `Mean Age` = paste(
      round(mean(age, na.rm = T), 1), " (SD = ",
      round(sd(age, na.rm = T), 1),
      ")", sep = ""
    ),
    `Gender` = paste(levels(gender_labs$f)[1], ': ', gender_labs$n[1], ' ', levels(gender_labs$f)[2], ': ', gender_labs$n[2], sep = ""),
    `Datasets` = paste(levels(dataset_labs$f)[1], ': ', dataset_labs$n[1], ' ', levels(dataset_labs$f)[2], ': ', dataset_labs$n[2], sep = ""),
    `Language` = paste('English: ', sum(as.numeric(as.character(language))==1), ' Chinese: ', sum(as.numeric(as.character(language))==6), sep = ""),
    `Race` = paste('Caucasian: ', sum(as.numeric(as.character(race))==2), ' Asian/Pacific: ', sum(as.numeric(as.character(race))==5), ' Other: ', sum(as.numeric(as.character(df_TrainTest_behavioral %>% select(race) %>% filter(race==1 | race==3 | race==4) %>% pull(.)))), sep = ""),
    `Mean Number of Visits` = paste(
      round(mean(as.numeric(as.character(num_visits)), na.rm=T), 1), " (SD = ",
      round(sd(as.numeric(as.character(num_visits)), na.rm=T), 1),
      ")", sep = ""
    )
)

knitr::kable(sample_summary3 %>% mutate_if(is.numeric, format, digits=4), format = "latex", booktabs = TRUE) %>%
          kable_styling(latex_table_env = "tabular", latex_options = c("striped"), full_width = FALSE, position = "left", protect_latex = TRUE) %>% gsub("\\\\end\\{table\\}\n", "", .) %>% gsub("\n\\\\begin\\{table\\}", "", .) %>% gsub("\n\\\\centering", "", .) %>% gsub("\\_", "-", .) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% save_kable("TrainTest_sample_demographic_descriptives.tex")

df_TrainTest_behavioral$Behavioral_disability <- as.factor(as.character(df_TrainTest_behavioral$Behavioral_disability %>% round(0)))
df_TrainTest_behavioral$comorbid <- as.factor(as.character(df_TrainTest_behavioral$comorbid))
levels(df_TrainTest_behavioral$Behavioral_disability) <- c("No Disability", "Disability")
levels(df_TrainTest_behavioral$comorbid) <- c("No Comorbidity", "Comorbidity")
disability_labs <- fct_count(df_TrainTest_behavioral$Behavioral_disability)
comorbid_labs <- fct_count(df_TrainTest_behavioral$comorbid)

df_TrainTest_behavioral$antidepressants <- as.factor(tidyr::replace_na(as.character(df_TrainTest_behavioral$antidepressants), 0))
df_TrainTest_behavioral$past_depression <- as.factor(tidyr::replace_na(as.character(df_TrainTest_behavioral$past_depression), 0))

df_TrainTest_behavioral$MDE_conversion <- as.factor(as.character(df_TrainTest_behavioral$MDE_conversion))
df_TrainTest_behavioral$MDE_chronic <- as.factor(as.character(df_TrainTest_behavioral$MDE_chronic))
df_TrainTest_behavioral$MDE_pre <- as.factor(as.character(df_TrainTest_behavioral$MDE_pre))
df_TrainTest_behavioral$MDE_post <- as.factor(as.character(df_TrainTest_behavioral$MDE_post))

sample_summary4 <- df_TrainTest_behavioral %>% 
  summarize(
    `RRS Brooding baseline (Rescaled 0-100)` = paste(
      round(mean(Behavioral_brooding_severity, na.rm = T), 3), " (SD = ",
      round(sd(Behavioral_brooding_severity, na.rm = T), 3), ")", sep = ""
    ),
    `Disabled` = paste(levels(disability_labs$f)[1], ': ', disability_labs$n[1], ' ', levels(disability_labs$f)[2], ': ', disability_labs$n[2], sep = ""),
    `Emotion Utilization (0-100)` = paste(
      round(mean(Behavioral_emotion_utilization, na.rm = T), 3), " (SD = ",
      round(sd(Behavioral_emotion_utilization, na.rm = T), 3), ")", sep = ""
    ),
    `Emotion Appraisal (Rescaled 0-100)` = paste(
      round(mean(Behavioral_emotional_appraisal, na.rm = T), 3), " (SD = ",
      round(sd(Behavioral_emotional_appraisal, na.rm = T), 3), ")", sep = ""
    ),
    `Social Intelligence (Rescaled 0-100)` = paste(
      round(mean(Behavioral_social_ability_sum, na.rm = T), 3), " (SD = ",
      round(sd(Behavioral_social_ability_sum, na.rm = T), 3), ")", sep = ""
    ),
    `Emotion Control (Rescaled 0-100)` = paste(
      round(mean(Behavioral_emotional_control, na.rm = T), 3), " (SD = ",
      round(sd(Behavioral_emotional_control, na.rm = T), 3), ")", sep = ""
    ),
    `Trait Anxiety Severity` = paste(
      round(mean(Behavioral_Trait_anxiety, na.rm = T), 3), " (SD = ",
      round(sd(Behavioral_Trait_anxiety, na.rm = T), 3), ")", sep = ""
    ),
    `State Anxiety Severity` = paste(
      round(mean(Behavioral_State_anxiety, na.rm = T), 3), " (SD = ",
      round(sd(Behavioral_State_anxiety, na.rm = T), 3), ")", sep = ""
    ),
    `Perceptual IQ (Rescaled 0-100)` = paste(
      round(mean(Behavioral_perceptual_IQ, na.rm = T), 3), " (SD = ",
      round(sd(Behavioral_perceptual_IQ, na.rm = T), 3), ")", sep = ""
    ),
    `Life Satisfaction (Rescaled 0-100)` = paste(
      round(mean(Behavioral_Life_satisfaction, na.rm = T), 3), " (SD = ",
      round(sd(Behavioral_Life_satisfaction, na.rm = T), 3), ")", sep = ""
    )
)

additional_past_deps = sum(as.numeric(as.character(df_TrainTest_behavioral$past_depression)) + as.numeric(as.character(df_TrainTest_behavioral$some_dep))) - sum(abs(as.numeric(as.character(df_TrainTest_behavioral$past_depression)) - as.numeric(as.character(df_TrainTest_behavioral$some_dep))))
chronic_rate = sum(as.numeric(as.character(df_TrainTest_behavioral$MDE_chronic)))/(additional_past_deps + sum(as.numeric(as.character(df_TrainTest_behavioral$some_dep))) + + sum(as.numeric(as.character(df_TrainTest_behavioral$MDE_pre))))
conversion_rate = sum(as.numeric(as.character(df_TrainTest_behavioral$MDE_conversion)))/length(df_TrainTest_behavioral %>% filter((MDE_chronic==0) & (MDE_pre==0)) %>% pull(.))

df_TrainTest_behavioral$episodic <- as.numeric((df_TrainTest_behavioral$MDE_chronic == 0) & (df_TrainTest_behavioral$MDE_conversion == 0) & ((df_TrainTest_behavioral$MDE_pre == 1) | (df_TrainTest_behavioral$MDE_post == 1) | (is.na(df_TrainTest_behavioral$MDE_pre) == T) | (is.na(df_TrainTest_behavioral$MDE_post) == T)))

df_TrainTest_behavioral$healthy <- as.numeric((df_TrainTest_behavioral$some_dep == 0) & (df_TrainTest_behavioral$episodic == 0) & (df_TrainTest_behavioral$MDE_chronic == 0) & (df_TrainTest_behavioral$MDE_conversion == 0))

df_TrainTest_behavioral$depression_outcome <-
as.factor(1*as.numeric(as.character(df_TrainTest_behavioral$healthy)) +
2*as.numeric(df_TrainTest_behavioral$healthy==FALSE)*as.numeric(as.character(df_TrainTest_behavioral$MDE_conversion)) + 3*as.numeric(df_TrainTest_behavioral$healthy==FALSE)*as.numeric(as.character(df_TrainTest_behavioral$MDE_chronic)))

df_TrainTest_behavioral$depression_outcome <- ordered(as.factor(df_TrainTest_behavioral$depression_outcome),
levels = c(1, 2, 3),
labels = c("Healthy", "Depression Conversion", "Chronic Depression"))
depression_outcome_labs <- fct_count(df_TrainTest_behavioral$depression_outcome)

total_subs <- length(df_TrainTest_behavioral$participant_id)
deps <- sum(sum(df_TrainTest_behavioral$episodic, na.rm=T), sum(as.numeric(as.character(df_TrainTest_behavioral$MDE_chronic)), na.rm=T), sum(as.numeric(as.character(df_TrainTest_behavioral %>% filter(episodic!=1, MDE_chronic!=1) %>% pull(past_depression))=="Past Depression"), na.rm=T))

current_deps <- sum(df_TrainTest_behavioral$episodic, na.rm=T)

df_TrainTest_behavioral <- df_TrainTest_behavioral %>% drop_na(antidepressants)
df_TrainTest_behavioral$antidepressants <- ordered(as.factor(df_TrainTest_behavioral$antidepressants),
levels = c(0, 1),
labels = c("No Antidepressants", "Antidepressants"))
antidepressants_labs <- fct_count(df_TrainTest_behavioral$antidepressants)

df_TrainTest_behavioral <- df_TrainTest_behavioral %>% drop_na(past_depression)
df_TrainTest_behavioral$past_depression <- ordered(as.factor(df_TrainTest_behavioral$past_depression),
levels = c(0, 1),
labels = c("No Past Depression", "Past Depression"))
past_depression_labs <- fct_count(df_TrainTest_behavioral$past_depression)

clinical_characteristics_TrainTest <- df_TrainTest_behavioral %>% 
  summarize(
    `Depressed` = paste('Current Depression: ', current_deps, ' (', round(100*(current_deps/total_subs), 1),'%)', sep = ""),
    `Chronicly Depressed` = paste(levels(depression_outcome_labs$f)[3], ': ', depression_outcome_labs$n[3], ' (', round(100*chronic_rate, 1),'%)', sep = ""),
    `Depression-Converted` = paste(levels(depression_outcome_labs$f)[2], ': ', depression_outcome_labs$n[2], ' (', round(100*conversion_rate, 1),'%)', sep = ""),
    `Healthy` = paste(levels(depression_outcome_labs$f)[1], ': ', depression_outcome_labs$n[1], ' (', round(100*depression_outcome_labs$n[1]/total_subs, 1),'%)', sep = ""),
    `Past Depression` = paste(levels(past_depression_labs$f)[2], ': ', past_depression_labs$n[2], ' (', round(100*past_depression_labs$n[2]/total_subs, 1),'%)', sep = ""),
    `Comorbidity` = paste(levels(comorbid_labs$f)[2], ': ', comorbid_labs$n[2], ' (', round(100*comorbid_labs$n[2]/total_subs, 1),'%)', sep = ""),
    `Antidepressants` = paste(levels(antidepressants_labs$f)[2], ': ', antidepressants_labs$n[2], ' (', round(100*antidepressants_labs$n[2]/total_subs, 1),'%)', sep = "")
)

clinical_characteristics_TrainTest_t <- transpose(clinical_characteristics_TrainTest)
names(clinical_characteristics_TrainTest_t) <- paste0("Diagnostic Subsamples (Cumulative N=", total_subs,")")

knitr::kable(clinical_characteristics_TrainTest_t %>% mutate_if(is.numeric, format, digits=4), format = "latex", booktabs = TRUE) %>%
          kable_styling(latex_table_env = "tabular", latex_options = c("striped"), full_width = FALSE, position = "left", protect_latex = TRUE) %>% gsub("\\\\end\\{table\\}\n", "", .) %>% gsub("\n\\\\begin\\{table\\}", "", .) %>% gsub("\n\\\\centering", "", .) %>% gsub("\\_", "-", .) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% save_kable("TrainTest_sample_clinical_characteristics.tex")
```

As summarized in Table \ref{tab:TrainTest_sample_demographic_descriptives}, the data analyzed in the target domain consisted of N = `r sample_summary3 %>% pull("Total N")` participants which, as in the source domain, were recruited across two continents but spanned just two aggregated data sets (SWU = `r str_split(sample_summary3$Datasets, ' ', n=4)[[1]][2]`, NKI = `r str_split(sample_summary3$Datasets, ' ', n=4)[[1]][4]`). The majority of participants included in the target domain sample were, as in the souce domain, young adults, but ages varied widely across the 18-65 range, with a mean age of `r sample_summary3 %>% pull("Mean Age")`, with balanced gender. All participants in the sample were examined for at least two and at most four visits, all of which were spaced evenly one year apart. In terms of psychopathology, `r round(100*past_depression_labs$n[2]/total_subs, 1)`% had a prior history of depression, `r round(100*antidepressants_labs$n[2]/total_subs, 1)`% reported stable use of antidepressant medication throughout their study participation, and `r round(100*comorbid_labs$n[2]/total_subs, 1)`% were found to have comorbidity with at least one other psychological disorder (Table \ref{tab:TrainTest_sample_clinical_characteristics}). To protect against these random effects, they were deconfounded from all subsequent linear regression models, along with age, gender, race, language, respective study site, race, and total duration until follow-up. This involved residualizing the input features by subtracting the contributions of their confounding variables~\cite{Chyzhyk2018,Rao2017}. When considering history of past depression in addition to currently significant depressive symptoms, the base rate of chronic depression (`r round(100*chronic_rate, 1)`%) in the present sample closely approximated the estimated 20% population rate of chronicity typically cited in depression literature~\cite{Vos2004}. To ensure that outcome variables were representative of population epidemiology, we randomly subsampled additional healthy subjects from the public datasets with usable neuroimaging data to yield base rates that reflected the latest estimates of 1-year depression conversion rate (`r round(100*conversion_rate, 1)`%)~\cite{Ettman2020} whereby N=`r depression_outcome_labs$n[2]` were not depressed at baseline but converted to depression at least one year later.

::: {.center data-latex=""}
\begin{sidewaystable}
\begin{minipage}{\textwidth}
\centering
\adjustbox{width=\textwidth,height=\textheight,keepaspectratio=true}{\subfile{Chapter_IV/results/TrainTest_sample_demographic_descriptives}}
\subcaption{\label{tab:TrainTest_sample_demographic_descriptives}\scriptsize{Demographic}}
\vspace{\baselineskip}
\adjustbox{width=0.25\textwidth,height=0.25\textheight,keepaspectratio=true}{\subfile{Chapter_IV/results/TrainTest_sample_clinical_characteristics}}
\subcaption{\label{tab:TrainTest_sample_clinical_characteristics}\scriptsize{Clinical}}
\end{minipage}
\caption{(Target Domain) \label{tab:TrainTest_sample_characteristics}\scriptsize{These tables summarize the demographic (top) and clinical (bottom) characteristics of the data evaluated in the target-domain (N=393). The clinical characteristics reported include the diagnostic subcategory of clinical depression (if available), along with associated base rates. The table also includes an inventory of relevant secondary clinical variables such as depression history, comorbidity, and antidepressant usage, which were used as nuisance confounds when training machine-learning classifiers.}}
\end{sidewaystable}
\setlength{\belowcaptionskip}{-10pt}
:::

## Feature Benchmarking
```{bash eval=FALSE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
# FUNC
## ASE
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'func' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'inter' 'language' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid'

## Betweenness
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'func' -session_label 1 -et 'betweenness' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'inter' 'language' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid'

### Dummy
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'func' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'inter' 'language' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid' -dr

### Desikan
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'func' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'DesikanKlein' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid'

# DWI
## ASE
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'dwi' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'language' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid'

### Dummy
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'dwi' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'inter' 'language' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid' -dr

### Desikan
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'dwi' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'DesikanKlein' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid'

## Multimodal
### Beh-Func
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'dwi' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'inter' 'language' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid' -sp 'Behavioral' 'func' -stack

### Beh-dwi
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'dwi' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'inter' 'language' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid' -sp 'Behavioral' 'dwi' -stack

### func-dwi
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'dwi' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'inter' 'language' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid' -sp 'func' 'dwi' -stack

### func-dwi-beh
singularity exec --cleanenv -B /scratch2/04171/dpisner:/working /scratch2/04171/dpisner/dpys_pynets_latest-2021-10-18-24d104118874_MNI152.img /opt/conda/lib/python3.6/site-packages/pynets-1.1.2-py3.6.egg/pynets/cli/pynets_predict.py -basedir '/working/validation_set/outputs' -modality 'dwi' -session_label 1 -et 'ASE' -tv 'MDE_conversion' -n_boots 1000 -temp 'any' -pheno '/working/validation_set/outputs/df_depressed_TrainTest_final.csv' -nets 'inter' 'language' -conf 'dep_1' 'race_1.0' 'race_2.0' 'race_3.0' 'race_5.0' 'ethnicity_0.0' 'ethnicity_1.0' 'ethnicity_2.0' 'language_1.0' 'language_2.0' 'language_4.0' 'language_6.0' 'dataset' 'comorbid' 'past_depression', 'antidepressants' 'num_visits' 'total_study_duration' 'sex' 'age' -dc 'Behavioral_emotion_utilization' 'Behavioral_social_ability_sum' 'Behavioral_disability' 'Behavioral_emotional_appraisal' 'Behavioral_emotional_control' 'Behavioral_Trait_anxiety' 'Behavioral_State_anxiety' 'Behavioral_perceptual_IQ' 'Behavioral_brooding_severity' 'Behavioral_Life_satisfaction' 'some_dep' 'subclinical' 'MDE_pre' 'MDE_post' 'usable_mri' -search 'grid' -sp 'func' 'dwi' 'Behavioral' -stack
```

```{python eval=FALSE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
import pandas as pd
import seaborn as sns
from pynets.core.utils import flatten
import os
import ast
import numpy as np
import json
from sklearn.preprocessing import MinMaxScaler
    
def conform_tup_order(g):
    idx=[4,0,1,2,3,5]
    a = np.array(ast.literal_eval(g))
    return tuple(a[idx])

## Prepare dataframes
source_file_path = '/home/dpys/Documents/Dissertation/Chapter_IV/data/TrainTest_set'

def preparare_grid_dfs(fname, source_file_path, metaparams):
    if not os.path.isfile(f"{source_file_path}/{fname}.csv"):
        raise FileNotFoundError(f"File {source_file_path}/{fname}.csv not found!")
    frame = pd.read_csv(f"{source_file_path}/{fname}.csv", index_col=False)
    if "Unnamed: 0" in frame.columns:
        frame.drop(frame.filter(regex="Unnamed: 0"), axis=1, inplace=True)

    df_grid = frame.dropna(axis=1, how='all')
    df_grid['grid'] = df_grid['grid'].str.replace('77', '200')
    df_grid['grid'] = df_grid['grid'].str.replace('135', '400')
    df_grid['grid'] = df_grid['grid'].str.replace('180', '600')
    df_grid['grid'] = df_grid['grid'].str.replace('228', '800')
    
    df_best_est = df_grid.copy()
        
    #df_grid = df_grid[['grid', 'lp_importance', 'Score', 'Error']]
    df_grid = df_grid[['grid', 'Score', 'Error']]
    
    if 'mvpa' not in fname and 'Behavioral' not in fname and 'multimodal' not in fname and 'simulated' not in metaparams:
        try:
            df_grid[metaparams] = pd.DataFrame([eval(i) for i in df_grid['grid'].tolist()], index=df_grid.index)
        except:
            df_grid[metaparams[1:]] = pd.DataFrame([eval(i) for i in df_grid['grid'].tolist()], index=df_grid.index)
        df_grid['grid'] = df_grid['grid'].apply(conform_tup_order)
        
        df_grid['network'] = df_grid['network'].map({'inter': 'TN_intersection', 'union': 'TN_union', 'triple': 'TN_union', 'language': 'LN_dorsal', 'language': 'LN_dorsal'})
    #df_grid.lp_importance = df_grid.lp_importance.values[0].replace('\n','').replace(' ',', ')

    df_grid.Score = df_grid.Score.apply(lambda x: [float(i) for i in str(x.replace('\n', '').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ', ').replace(', ]', ']').replace('[ ', '[').replace('  ', ' ').replace(',,,', ',').replace(',,', ',').replace('[','').replace(']','')).split(', ')])

    df_grid.Error = df_grid.Error.apply(lambda x: [float(i) for i in str(x.replace('\n', '').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ', ').replace(', ]', ']').replace('[ ', '[').replace('  ', ' ').replace(',,,', ',').replace(',,', ',').replace('[','').replace(']','')).split(', ')])

    df_grid = pd.concat([df_grid.drop(columns=['Score', 'Error']), pd.DataFrame(df_grid.Score.values.tolist())], axis=1)

    loss = []
    bias = []
    variance = []
    for i in range(len(df_best_est['best_estimator'])):
        est = df_best_est['best_estimator'][i]
        est_list = ast.literal_eval(est.replace('\n', '').replace('    ', ' ').replace('   ', ' ').replace('  ', ' ').replace(' ', ', ').replace(', ]', ']').replace('[ ', '[').replace('  ', ' ').replace(',,,', ',').replace(',,', ','))
        est_list_unique = list(set(est_list))
        
        loss_tmp = []
        bias_tmp = []
        variance_tmp = []
        for j in est_list_unique:
            loss_tmp.append(float(j.split("AvgExpLoss=")[1].split('_')[0]))
            bias_tmp.append(float(j.split("AvgBias=")[1].split('_')[0]))
            variance_tmp.append(float(j.split("AvgVar=")[1].split('_')[0]))
        
        df_grid.at[i, 'avg_loss'] = np.nanmean(loss_tmp)
        df_grid.at[i, 'avg_bias'] = np.nanmean(bias_tmp)
        df_grid.at[i, 'avg_var'] = np.nanmean(variance_tmp)
        
    df_grid.to_csv(f"{source_file_path}/{fname}_scores.csv", index=False)
    print(f"Final File: {source_file_path}/{fname}_scores.csv")

    return

multimodal_files = ['df_summary_MDE_conversion_multimodal_stacking_func_dwi_with_nuisance', 
'df_summary_MDE_conversion_multimodal_stacking_dwi_beh_with_nuisance', 
'df_summary_MDE_conversion_multimodal_stacking_func_dwi_beh_with_nuisance', 
'df_summary_MDE_chronic_multimodal_stacking_func_dwi_with_nuisance', 
'df_summary_MDE_conversion_multimodal_stacking_func_beh_with_nuisance', 
'df_summary_MDE_chronic_multimodal_stacking_dwi_beh_with_nuisance', 
'df_summary_MDE_chronic_multimodal_stacking_func_beh_with_nuisance', 
'df_summary_MDE_chronic_multimodal_stacking_func_dwi_beh_with_nuisance', 
'df_summary_MDE_conversion_multimodal_voting_dwi_beh_with_nuisance', 
'df_summary_MDE_conversion_multimodal_voting_func_dwi_with_nuisance', 
'df_summary_MDE_conversion_multimodal_voting_func_dwi_beh_with_nuisance', 
'df_summary_MDE_conversion_multimodal_voting_func_beh_with_nuisance', 
'df_summary_MDE_chronic_multimodal_voting_func_dwi_with_nuisance', 
'df_summary_MDE_chronic_multimodal_voting_dwi_beh_with_nuisance', 
'df_summary_MDE_chronic_multimodal_voting_func_beh_with_nuisance', 
'df_summary_MDE_chronic_multimodal_voting_func_dwi_beh_with_nuisance']

func_files = [
'final_predictions_modality-func_rsn-DesikanKlein_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid',
'final_predictions_modality-func_rsn-DesikanKlein_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid',
'final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid',
'final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid',
'final_predictions_modality-func_rsn-inter_language_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid_dummy',
'final_predictions_modality-func_rsn-inter_language_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid_dummy']

dwi_files = ['final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid_dummy',
'final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid_dummy',
'final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid',
'final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid',
'final_predictions_modality-dwi_rsn-DesikanKlein_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid',
'final_predictions_modality-dwi_rsn-DesikanKlein_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid']

mvpa_files = ['df_summary_MDE_conversion_func_mvpa_with_nuisance',
'df_summary_MDE_chronic_func_mvpa_with_nuisance',
'df_summary_MDE_chronic_dwi_mvpa_with_nuisance',
'df_summary_MDE_chronic_dwi_mvpa_nosubgraph_with_nuisance',
'df_summary_MDE_conversion_dwi_mvpa_with_nuisance',
'df_summary_MDE_conversion_dwi_mvpa_nosubgraph_with_nuisance']

simulated_files = ['df_summary_MDE_chronic_dwi_RDPG', 'df_summary_MDE_chronic_func_RDPG', 'df_summary_MDE_conversion_dwi_RDPG', 'df_summary_MDE_conversion_func_RDPG', 'df_summary_MDE_chronic_dwi_ErdosRenyi_deep', 'df_summary_MDE_chronic_func_ErdosRenyi_deep', 'df_summary_MDE_conversion_dwi_ErdosRenyi_deep', 'df_summary_MDE_conversion_func_ErdosRenyi_deep', 'df_summary_MDE_chronic_dwi_small', 'df_summary_MDE_chronic_func_small', 'df_summary_MDE_conversion_dwi_small', 'df_summary_MDE_conversion_func_small', 'df_summary_MDE_chronic_dwi_barabasi', 'df_summary_MDE_chronic_func_barabasi', 'df_summary_MDE_conversion_dwi_barabasi', 'df_summary_MDE_conversion_func_barabasi']

behavioral_files = ['df_summary_MDE_chronic_Behavioral_percentiles_with_nuisance', 'df_summary_MDE_conversion_Behavioral_percentiles_with_nuisance']

for pheno in ['chronic', 'conversion']:
    for file_ in [i for i in func_files if pheno in i]:
        preparare_grid_dfs(file_, f"{source_file_path}", ['extract', 'hpass', 'model', 'res', 'network', 'smooth']) 

for pheno in ['chronic', 'conversion']:
    for file_ in [i for i in dwi_files if pheno in i]:
        preparare_grid_dfs(file_, f"{source_file_path}", ['directget', 'minlength', 'model', 'res', 'network', 'tol']) 

for pheno in ['chronic', 'conversion']:
    for file_ in [i for i in  behavioral_files if pheno in i]:
        preparare_grid_dfs(file_, f"{source_file_path}", [])
  
for pheno in ['chronic', 'conversion']:
    for file_ in [i for i in  mvpa_files if pheno in i]:
        preparare_grid_dfs(file_, f"{source_file_path}", [])
        
for pheno in ['chronic', 'conversion']:
    for file_ in [i for i in  multimodal_files if pheno in i]:
        preparare_grid_dfs(file_, f"{source_file_path}", [])

for pheno in ['chronic', 'conversion']:
    for file_ in [i for i in  simulated_files if pheno in i]:
        preparare_grid_dfs(file_, f"{source_file_path}", ['simulated'])
```

```{r}
corrected_dependent_ttest <- function(x, y, n_training_folds=10, n_test_folds=10, alternative = "two.sided", conf.level=0.95) {
  
  n <- length(y)
  
  differences <- vector()
  for (i in seq(1:n)){
      differences[i] <- x[i] - y[i]
  }           
  df <- n - 1
  stderr <- sqrt(1 / n + n_test_folds / n_training_folds) * sd(differences)
  t_stat <- 1 / n * sum(differences) / stderr
  
  if (alternative == "less") {
  	p <- pt(t_stat, df)
  	cint <- c(-Inf, t_stat + qt(conf.level, df))
  } else if (alternative == "greater") {
	  p <- pt(t_stat, df, lower.tail = FALSE)
	  cint <- c(t_stat - qt(conf.level, df), Inf)
  } else {
	  p <- 2 * pt(-abs(t_stat), df)
	  alpha <- 1 - conf.level
    cint <- qt(1 - alpha/2, df)
	  cint <- t_stat + c(-cint, cint)
  }
  
  return(list(t_stat = t_stat, df = df, conf.int = cint, p = p))
}

make_modality_boot_df <- function(df_chronic, df_conversion, grid_cols, Feature_Space=NULL, x_compare=NULL, y_compare=NULL, connectome=TRUE) {
    df_chronic$Response <- 'Chronic'
    df_chronic$Response <- as.factor(df_chronic$Response)
    df_conversion$Response <- 'Conversion'
    df_conversion$Response <- as.factor(df_conversion$Response)
    
    df_out <- bind_rows(df_chronic, df_conversion) %>% dplyr::select(-all_of(matches(grid_cols)))
    
    if (is.null(x_compare)==TRUE) {
          if (connectome == TRUE) {
              out <- df_out %>% dplyr::select(-"Phenotype") %>% split(f = as.factor(.$Response))
          } else {
              out <- cbind(data.frame(sapply(df_out[,1:1000], as.numeric)), df_out %>% dplyr::select(Response)) %>% split(f = as.factor(.$Response))
          }
          
          df_chronic <- as.data.frame(t(out$Chronic %>% dplyr::select(-"Response")))
          if (connectome == FALSE) {
              df_chronic <- df_chronic %>% mutate_all(as.numeric)
              names(df_chronic) <- 'AUC'
          }
          df_chronic <- df_chronic[!(row.names(df_chronic) %in% c('Response', 'Modality')),] %>% as.data.frame()
          rownames(df_chronic) <- NULL
          df_chronic[1:length(names(df_chronic))] <- sapply(df_chronic[1:length(names(df_chronic))],as.numeric)
          df_chronic <- df_chronic %>% as.tibble() %>% mutate(across(where(is.numeric), ~na_if(., 0.5))) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC)
          df_chronic$boot <- seq(1, 1000)
          df_chronic$Response <- 'Chronic'

          df_conversion <- as.data.frame(t(out$Conversion %>% dplyr::select(-"Response")))
          if (connectome == FALSE) {
              df_conversion <- df_conversion %>% mutate_all(as.numeric)
              names(df_conversion) <- 'AUC'
          }
          df_conversion <- df_conversion[!(row.names(df_conversion) %in% c('Response', 'Modality')), ] %>% as.data.frame()
          rownames(df_conversion) <-  NULL
          df_conversion[1:length(names(df_conversion))] <- sapply(df_conversion[1:length(names(df_conversion))],as.numeric)
          df_conversion <- df_conversion %>% as.tibble() %>% mutate(across(where(is.numeric), ~na_if(., 0.5))) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC)
          df_conversion$boot <- seq(1, 1000)
          df_conversion$Response <- 'Conversion'

          dat <- as.data.frame(bind_rows(df_chronic, df_conversion)) %>% na.omit()
          dat$Feature_Space <- Feature_Space
    } else {
          if (connectome == TRUE) {
              out <- df_out %>% filter(grepl(!!x_compare, Phenotype)) %>% dplyr::select(-"Phenotype") %>% split(f = as.factor(.$Response))
          } else {
              out <- cbind(data.frame(sapply(df_out[,1:1000], as.numeric)), df_out %>% filter(grepl(!!x_compare, Phenotype)) %>% dplyr::select(Response)) %>% split(f = as.factor(.$Response))
          }

          df_chronic <- as.data.frame(t(out$Chronic %>% dplyr::select(-"Response")))
          if (connectome == FALSE) {
              df_chronic <- df_chronic %>% mutate_all(as.numeric)
              names(df_chronic) <- 'AUC'
          }
          df_chronic <- df_chronic[!(row.names(df_chronic) %in% c('Response', 'Modality')), ] %>% as.data.frame()
          rownames(df_chronic) <- NULL
          df_chronic <- df_chronic %>% dplyr::select(-all_of(matches(grid_cols)), -matches("Modality"), -matches("Phenotype"), -matches("Response"))
          df_chronic[1:length(names(df_chronic))] <- sapply(df_chronic[1:length(names(df_chronic))],as.numeric)
          df_chronic <- as.data.frame(df_chronic) %>% as.tibble() %>% mutate(across(where(is.numeric), ~na_if(., 0.5))) %>% mutate(AUC= rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC)
          df_chronic$boot <- seq(1, 1000)
          df_chronic$Response <- 'Chronic'

          df_conversion <- as.data.frame(t(out$Conversion %>% dplyr::select(-"Response")))
          if (connectome == FALSE) {
              df_conversion <- df_conversion %>% mutate_all(as.numeric)
              names(df_conversion) <- 'AUC'
          }
          df_conversion <- df_conversion[!(row.names(df_conversion) %in% c('Response', 'Modality')), ] %>% as.data.frame()
          rownames(df_conversion) <-  NULL
          df_conversion <- df_conversion %>% dplyr::select(-all_of(matches(grid_cols)), -matches("Modality"), -matches("Phenotype"), -matches("Response"))
          df_conversion[1:length(names(df_conversion))] <- sapply(df_conversion[1:length(names(df_conversion))],as.numeric)
          df_conversion <- as.data.frame(df_conversion) %>% as.tibble() %>% mutate(across(where(is.numeric), ~na_if(., 0.5))) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC)
          df_conversion$boot <- seq(1, 1000)
          df_conversion$Response <- 'Conversion'
          df_1 <- bind_rows(df_chronic, df_conversion)
          rownames(df_1) <-  NULL
          df_1$Feature_Space <- x_compare

          if (connectome == TRUE) {
              out <- df_out %>% filter(grepl(!!y_compare, Phenotype)) %>% dplyr::select(-"Phenotype") %>% split(f = as.factor(.$Response))
          } else {
              out <- cbind(data.frame(sapply(df_out[,1:1000], as.numeric)), df_out %>% filter(grepl(!!y_compare, Phenotype)) %>% dplyr::select(Response)) %>% split(f = as.factor(.$Response))
          }

          df_chronic <- as.data.frame(t(out$Chronic %>% dplyr::select(-"Response")))
          if (connectome == FALSE) {
              df_chronic <- df_chronic %>% mutate_all(as.numeric)
              names(df_chronic) <- 'AUC'
          }
          df_chronic <- df_chronic[!(row.names(df_chronic) %in% c('Response', 'Modality')), ] %>% as.data.frame()
          rownames(df_chronic) <- NULL
          df_chronic <- df_chronic %>% dplyr::select(-all_of(matches(grid_cols)), -matches("Modality"), -matches("Phenotype"), -matches("Response"))
          df_chronic[1:length(names(df_chronic))] <- sapply(df_chronic[1:length(names(df_chronic))],as.numeric)
          df_chronic <- as.data.frame(df_chronic) %>% as.tibble() %>% mutate(across(where(is.numeric), ~na_if(., 0.5))) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC)
          df_chronic$boot <- seq(1, 1000)
          df_chronic$Response <- 'Chronic'

          df_conversion <- as.data.frame(t(out$Conversion %>% dplyr::select(-"Response")))
          if (connectome == FALSE) {
              df_conversion <- df_conversion %>% mutate_all(as.numeric)
              names(df_conversion) <- 'AUC'
          }
          df_conversion <- df_conversion[!(row.names(df_conversion) %in% c('Response', 'Modality')), ] %>% as.data.frame()
          rownames(df_conversion) <-  NULL
          df_conversion <- df_conversion %>% dplyr::select(-all_of(matches(grid_cols)), -matches("Modality"), -matches("Phenotype"), -matches("Response"))
          df_conversion[1:length(names(df_conversion))] <- sapply(df_conversion[1:length(names(df_conversion))],as.numeric)
          df_conversion <- as.data.frame(df_conversion) %>% as.tibble() %>% mutate(across(where(is.numeric), ~na_if(., 0.5))) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC)
          df_conversion$boot <- seq(1, 1000)
          df_conversion$Response <- 'Conversion'
          
          df_2 <- bind_rows(df_chronic, df_conversion)
          rownames(df_2) <-  NULL
          df_2$Feature_Space <- y_compare

          dat <- as.data.frame(bind_rows(df_1, df_2)) %>% na.omit()
    }

    return(dat)
}

clean_pairs <- function(dat, Y='AUC', min_thr=0.50, subsample=100, facet=NULL){
    '%ni%' <- Negate('%in%')
    
    dat_raw <- dat %>% mutate_if(is.character,as.factor) %>% dplyr::select_if(~ !is.factor(.x) | sum(tabulate(.x) > 1) > 1) %>% filter(AUC > !!min_thr)

    x <- which(names(dat_raw) == 'Feature_Space')
    y <- which(names(dat_raw) == Y)

    x_levels <- as.vector(unique(dat_raw %>% dplyr::select(names(dat_raw)[x]))[[1]])
    combs <- combn(levels(as.factor(x_levels)), 2, simplify = FALSE)

    gb_cols <- names(dat_raw)[which(names(dat_raw) %ni% c("AUC", "boot", "Feature_Space"))]
    datt <- dat_raw %>% group_by(across(all_of(!!gb_cols)), Feature_Space) %>% filter(AUC > !!min_thr)

    df_list <- datt %>% group_by(across(all_of(!!gb_cols))) %>% group_split()
    
    valid_boots <- list()
    for (i in 1:length(df_list))
    {
        df_tmp <- outlierKD(df_list[[i]] %>% na.omit(), AUC) %>% na.omit()
        df_tmp_split <- df_tmp %>% group_split(Feature_Space)
        boots <- list()
        for (j in 1:length(df_tmp_split)){
            boots[[j]] <- df_tmp_split[[j]] %>% pull(boot)
        }
        good_boots <- Reduce(intersect, boots)
        valid_boots[[i]] <- good_boots
        gc()
    }        
    
    usable_boots <- Reduce(intersect, valid_boots)
    
    dat_new <- datt %>% filter(boot %in% usable_boots)
    dat_chronic <- dat_new %>% filter(Response=='Chronic') %>% as.tibble()
    dat_conversion <- dat_new %>% filter(Response=='Conversion') %>% as.tibble()
    
    if (('Modality' %in% facet) & ('Response' %in% facet)) {
        dat_chronic_dwi <- dat_chronic %>% filter(Modality=='Structural') %>% as.tibble() %>% arrange_(~ desc(AUC)) %>%
      group_by(Feature_Space) %>%
      do(head(., n = subsample*4)) %>% arrange(., boot) %>% ungroup()
        dat_conversion_dwi <- dat_conversion %>% filter(Modality=='Structural') %>% as.tibble()  %>% arrange_(~ desc(AUC)) %>%
      group_by(Feature_Space) %>%
      do(head(., n = subsample*4)) %>% arrange(., boot) %>% ungroup()
        dat_chronic_func <- dat_chronic %>% filter(Modality=='Functional') %>% as.tibble() %>% arrange_(~ desc(AUC)) %>%
      group_by(Feature_Space) %>%
      do(head(., n = subsample*4)) %>% arrange(., boot) %>% ungroup()
        dat_conversion_func <- dat_conversion %>% filter(Modality=='Functional') %>% as.tibble() %>% arrange_(~ desc(AUC)) %>%
      group_by(Feature_Space) %>%
      do(head(., n = subsample*4)) %>% arrange(., boot) %>% ungroup()
      dat_new <- bind_rows(dat_chronic_dwi, dat_conversion_dwi, dat_chronic_func, dat_conversion_func)
      
    } else if (('Modality' %in% facet) & ('Modality' %in% names(dat_new))) {
      dat_new_dwi <- dat_new %>% filter(Modality=='Structural') %>% as.tibble() %>% arrange_(~ desc(AUC)) %>%
      group_by(Feature_Space) %>%
      do(head(., n = subsample*2)) %>% arrange(., boot) %>% ungroup()

      dat_new_func <- dat_new %>% filter(Modality=='Functional') %>% as.tibble() %>% arrange_(~ desc(AUC)) %>%
      group_by(Feature_Space) %>%
      do(head(., n = subsample*2)) %>% arrange(., boot) %>% ungroup()
      dat_new <- bind_rows(dat_new_dwi, dat_new_func)
      
    } else if ('Functional' %in% levels(dat_chronic$Feature_Space)) {
      dat_new <- bind_rows(dat_chronic, dat_conversion) %>% as.tibble() %>%
      group_by(Response, Feature_Space) %>%
      do(head(., n = subsample)) %>% arrange(., boot) %>% ungroup()
      
    } else if ('Response' %in% facet) {
      dat_chronic <- dat_chronic %>% as.tibble() %>% arrange_(~ desc(AUC)) %>%
      group_by(Feature_Space) %>%
      do(head(., n = subsample*2)) %>% arrange(., boot) %>% ungroup()
      
      dat_conversion <- dat_conversion %>% as.tibble()  %>% arrange_(~ desc(AUC)) %>%
      group_by(Feature_Space) %>%
      do(head(., n = subsample*2)) %>% arrange(., boot) %>% ungroup()
      dat_new <- bind_rows(dat_chronic, dat_conversion) %>% as.tibble()
    } else {
      dat_new <- dat_new %>% as.tibble() %>% arrange_(~ desc(AUC)) %>%
      group_by(Feature_Space) %>%
      do(head(., n = subsample)) %>% arrange(., boot) %>% ungroup()
    }
    
    dat_new$boot <- as.factor(dat_new$boot)
    dat_new <- dat_new[order(dat_new$boot),]
    
    return(dat_new)
} 

paired_subcompare <- function(dat, x_levels, Y, facet, conf.level, alternative){
      if (('Modality' %in% facet) & ('Response' %in% facet)) {
        dat_chronic <- dat %>% filter(Response=='Chronic') %>% as.tibble()

        dat_conversion <- dat %>% filter(Response=='Conversion') %>% as.tibble()

        dat_conversion_func <- subset(dat_conversion, Modality == "Functional")
        dat_conversion_func <- subset(dat_conversion_func, duplicated(boot) | duplicated(boot, fromLast=TRUE))
        
        dat_conversion_dwi <- subset(dat_conversion, Modality == "Structural")
        dat_conversion_dwi <- subset(dat_conversion_dwi, duplicated(boot) | duplicated(boot, fromLast=TRUE))
        
        dat_chronic_func <- subset(dat_chronic, Modality == "Functional")
        dat_chronic_func <- subset(dat_chronic_func, duplicated(boot) | duplicated(boot, fromLast=TRUE))
                    
        dat_chronic_dwi <- subset(dat_chronic, Modality == "Structural")
        dat_chronic_dwi <- subset(dat_chronic_dwi, duplicated(boot) | duplicated(boot, fromLast=TRUE))
                    
        ttest_chronic_func <- corrected_dependent_ttest(dat_chronic_func %>% filter(Feature_Space==x_levels[1]) %>% pull(!!Y), dat_chronic_func %>% filter(Feature_Space==x_levels[2]) %>% pull(!!Y), n_training_folds=10, n_test_folds=10, alternative = alternative, conf.level = conf.level)
        
        ttest_chronic_dwi <- corrected_dependent_ttest(dat_chronic_dwi %>% filter(Feature_Space==x_levels[1]) %>% pull(!!Y), dat_chronic_dwi %>% filter(Feature_Space==x_levels[2]) %>% pull(!!Y), n_training_folds=10, n_test_folds=10, alternative = alternative, conf.level = conf.level)
    
        ttest_conversion_func <- corrected_dependent_ttest(dat_conversion_func %>% filter(Feature_Space==x_levels[1]) %>% pull(!!Y), dat_conversion_func %>% filter(Feature_Space==x_levels[2]) %>% pull(!!Y), n_training_folds=10, n_test_folds=10, alternative = alternative, conf.level = conf.level)
        
        ttest_conversion_dwi <- corrected_dependent_ttest(dat_conversion_dwi %>% filter(Feature_Space==x_levels[1]) %>% pull(!!Y), dat_conversion_dwi %>% filter(Feature_Space==x_levels[2]) %>% pull(!!Y), n_training_folds=10, n_test_folds=10, alternative = alternative, conf.level = conf.level) 
        
        return (list(ttest_chronic_func, ttest_chronic_dwi, ttest_conversion_func, ttest_conversion_dwi))
    } else if ('Response' %in% facet) {
        dat_chronic <- dat %>% filter(Response=='Chronic') %>% as.tibble()

        dat_conversion <- dat %>% filter(Response=='Conversion') %>% as.tibble()

        ttest_chronic <- corrected_dependent_ttest(dat_chronic %>% filter(Feature_Space==x_levels[1]) %>% pull(!!Y), dat_chronic %>% filter(Feature_Space==x_levels[2]) %>% pull(!!Y), n_training_folds=10, n_test_folds=10, alternative = alternative, conf.level = conf.level)
    
        ttest_conversion <- corrected_dependent_ttest(dat_conversion %>% filter(Feature_Space==x_levels[1]) %>% pull(!!Y), dat_conversion %>% filter(Feature_Space==x_levels[2]) %>% pull(!!Y), n_training_folds=10, n_test_folds=10, alternative = alternative, conf.level = conf.level)
        
        return (list(ttest_chronic, ttest_conversion))
    } else if ('Modality' %in% facet) {
        dat_dwi <- dat %>% filter(Modality=='Structural') %>% as.tibble()

        dat_func <- dat %>% filter(Modality=='Functional') %>% as.tibble()

        ttest_dwi <- corrected_dependent_ttest(dat_dwi %>% filter(Feature_Space==x_levels[1]) %>% pull(!!Y), dat_dwi %>% filter(Feature_Space==x_levels[2]) %>% pull(!!Y), n_training_folds=10, n_test_folds=10, alternative = alternative, conf.level = conf.level)
    
        ttest_func <- corrected_dependent_ttest(dat_func %>% filter(Feature_Space==x_levels[1]) %>% pull(!!Y), dat_func %>% filter(Feature_Space==x_levels[2]) %>% pull(!!Y), n_training_folds=10, n_test_folds=10, alternative = alternative, conf.level = conf.level)
        
        return (list(ttest_func, ttest_dwi))
    } else {
        ttest <- corrected_dependent_ttest(dat %>% filter(Feature_Space==x_levels[1]) %>% pull(!!Y), dat %>% filter(Feature_Space==x_levels[2]) %>% pull(!!Y), n_training_folds=10, n_test_folds=10, alternative = alternative, conf.level = conf.level)
            
        return (list(ttest))
    }
}

paired_compare <- function(dat, METHOD, TAG="", facet=NULL, Y="AUC", 
                           alternative="two.sided", conf.level=0.95) {

    x <- which(names(dat) == 'Feature_Space')
    y <- which(names(dat) == Y)
    
    plt <- violin_boxplot(dat, x, y, "t.test", TRUE, METHOD, facet) + 
      labs(tag = TAG, colour = "white")

    x_levels <- as.vector(unique(dat %>% dplyr::select(names(dat)[x]))[[1]])
    
    if (length(x_levels) == 2){
        return(c(list(plt), paired_subcompare(dat, x_levels, Y, facet, 
                                              conf.level, alternative)))
    } else {
        combs <- combn(levels(as.factor(x_levels)), 2, simplify = FALSE)
        ttest_list <- list(plt)
        for (comb in combs){
          x_levels <- comb
          ttest_list <- c(ttest_list, 
                          c(gsub("\n\n", " ", 
                                 strcat(comb)), 
                            paired_subcompare(dat, comb, Y, 
                                              facet, conf.level, alternative)))
        }
        return(ttest_list)
    }
}

load_func_TrainTest <- function(df, all_best_func_tune) {

    df <- df %>% mutate_if(is.character,as.factor)
    
    df$hpass <- as.factor(df$hpass)
    df <- mutate(df, hpass = revalue(hpass, c("0" = "0.0 Hz", "0.028" = '0.028 Hz', "0.08" = '0.08 Hz')))
    
    df$model <- as.factor(df$model)
    df <- mutate(df, model = revalue(model, c("corr" = "Correlation", "cov" = "Covariance", "partcorr" = "Partial Correlation")))

    df$smooth <- as.factor(df$smooth)
    df <- mutate(df, smooth = revalue(smooth, c("0" = "0mm", "3" = "3mm", "6" = "6mm")))
    
    df$network <- as.factor(df$network)
    df$extract <- as.factor(df$extract)
    df$res <- as.factor(df$res)
    
    all_best_func_tune$FrequencyBandwidth <- as.factor(all_best_func_tune$FrequencyBandwidth)
    all_best_func_tune$ConnectivityEstimator <- as.factor(all_best_func_tune$ConnectivityEstimator)
    all_best_func_tune$SmoothingTolerance <- as.factor(all_best_func_tune$SmoothingTolerance)
    all_best_func_tune$NetworkDefinition <- as.factor(all_best_func_tune$NetworkDefinition)
    all_best_func_tune$ExtractionMethod <- as.factor(all_best_func_tune$ExtractionMethod)
    all_best_func_tune$NodeGranularity <- as.factor(all_best_func_tune$NodeGranularity)
    all_best_func_tune$Phenotype <- as.factor(all_best_func_tune$Phenotype)
    
    df <- clean_grid_col(df)
    names(df)[1:7] <- c("grid", "ExtractionMethod", "FrequencyBandwidth", "ConnectivityEstimator", "NodeGranularity", "NetworkDefinition", "SmoothingTolerance")
    df <- df %>% dplyr::select(-grid, -contains(".1"))
    df_val <- df %>% left_join(., all_best_func_tune, on=c("ExtractionMethod", "FrequencyBandwidth", "ConnectivityEstimator", "NodeGranularity", "NetworkDefinition", "SmoothingTolerance"))
    df_val$Phenotype <- as.factor(tidyr::replace_na(as.character(df_val$Phenotype), 'Random'))
    df_val$Modality <- 'Functional'
    df_quality <- df_val %>% dplyr::select(avg_loss, avg_bias, avg_var)

 return (list(df_val %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), df_quality))
}

load_dwi_TrainTest <- function(df, all_best_dwi_tune) {

    df <- df %>% mutate_if(is.character,as.factor)
    
    df$minlength <- as.factor(df$minlength)
    df <- mutate(df, minlength = revalue(minlength, c("0" = "Short", "10" = "Medium", "30" = "Long")))
    
    df$model <- as.factor(df$model)
    df <- mutate(df, model = revalue(model, c("csa" = "CSA", "sfm" = "SFM")))
    
    df$tol <- as.factor(df$tol)
    df <- mutate(df, tol = revalue(tol, c("5" = "5mm", "10" = "10mm")))

    df$directget <- as.factor(df$directget)
    df <- mutate(df, directget = revalue(directget, c("det" = "Deterministic", "prob" = "Probabilistic")))

    df$res <- as.factor(df$res)
    
    all_best_dwi_tune$MinimumFiberLength <- as.factor(all_best_dwi_tune$MinimumFiberLength)
    all_best_dwi_tune$ConnectivityEstimator <- as.factor(all_best_dwi_tune$ConnectivityEstimator)
    all_best_dwi_tune$SmoothingTolerance <- as.factor(all_best_dwi_tune$SmoothingTolerance)
    all_best_dwi_tune$NetworkDefinition <- as.factor(all_best_dwi_tune$NetworkDefinition)
    all_best_dwi_tune$ExtractionMethod <- as.factor(all_best_dwi_tune$ExtractionMethod)
    all_best_dwi_tune$NodeGranularity <- as.factor(all_best_dwi_tune$NodeGranularity)
    
    all_best_dwi_tune <- mutate(all_best_dwi_tune, MinimumFiberLength = revalue(MinimumFiberLength, c("Long" = "Medium")))
    
    df <- clean_grid_col(df)
    names(df)[1:7] <- c("grid", "ExtractionMethod", "MinimumFiberLength", "ConnectivityEstimator", "NodeGranularity", "NetworkDefinition", "SmoothingTolerance")
    df <- df %>% dplyr::select(-grid, -ends_with(".1"))
    df_val <- df %>% left_join(., all_best_dwi_tune, on=c("ExtractionMethod", "MinimumFiberLength", "ConnectivityEstimator", "NodeGranularity", "NetworkDefinition", "SmoothingTolerance"))
    df_val$Phenotype <- as.factor(tidyr::replace_na(as.character(df_val$Phenotype), 'Random'))
    df_val$Modality <- 'Structural'
    df_quality <- df_val %>% dplyr::select(avg_loss, avg_bias, avg_var)
        
 return (list(df_val %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), df_quality))
}
```

```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
# Functional
setwd(data_dir)
names(all_best_func) <- gsub(".", " ", names(all_best_func), fixed = TRUE)
all_best_func_tune_ASE <- all_best_func %>% filter(`Embedding Method`=='ASE') %>% dplyr::select(-`Embedding Method`, -R2, -Grid)

df_func_chronic <- read.csv(paste(TrainTest_loc, "final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)

df_func_conversion <- read.csv(paste(TrainTest_loc, "final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)

df_func_chronic_desikan <- read.csv(paste(TrainTest_loc, "final_predictions_modality-func_rsn-DesikanKlein_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)
df_func_conversion_desikan <- read.csv(paste(TrainTest_loc, "final_predictions_modality-func_rsn-DesikanKlein_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)

df_func_chronic_dummy <- read.csv(paste(TrainTest_loc, "final_predictions_modality-func_rsn-inter_language_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid_dummy_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)
df_func_conversion_dummy <- read.csv(paste(TrainTest_loc, "final_predictions_modality-func_rsn-inter_language_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid_dummy_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)

df_func_chronic <- load_func_TrainTest(df_func_chronic, all_best_func_tune_ASE)
df_func_chronic_quality <- df_func_chronic[[2]]
df_func_chronic <- df_func_chronic[[1]]
df_func_conversion <- load_func_TrainTest(df_func_conversion, all_best_func_tune_ASE)
df_func_conversion_quality <- df_func_conversion[[2]]
df_func_conversion <- df_func_conversion[[1]]

df_func_chronic_desikan <- load_func_TrainTest(df_func_chronic_desikan, all_best_func_tune_ASE)
df_func_chronic_desikan_quality <- df_func_chronic_desikan[[2]]
df_func_chronic_desikan <- df_func_chronic_desikan[[1]]
df_func_conversion_desikan <- load_func_TrainTest(df_func_conversion_desikan, all_best_func_tune_ASE)
df_func_conversion_desikan_quality <- df_func_conversion_desikan[[2]]
df_func_conversion_desikan <- df_func_conversion_desikan[[1]]

df_func_chronic_dummy <- load_func_TrainTest(df_func_chronic_dummy, all_best_func_tune_ASE)
df_func_chronic_dummy_quality <- df_func_chronic_dummy[[2]]
df_func_chronic_dummy <- df_func_chronic_dummy[[1]]
df_func_conversion_dummy <- load_func_TrainTest(df_func_conversion_dummy, all_best_func_tune_ASE)
df_func_conversion_dummy_quality <- df_func_conversion_dummy[[2]]
df_func_conversion_dummy <- df_func_conversion_dummy[[1]]

# Structural
setwd(data_dir)
names(all_best_dwi) <- gsub(".", " ", names(all_best_dwi), fixed = TRUE)
all_best_dwi_tune_ASE <- all_best_dwi %>% filter(`Embedding Method`=='ASE') %>% dplyr::select(-`Embedding Method`, -R2, -Grid)

df_dwi_chronic <- read.csv(paste(TrainTest_loc, "final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)

df_dwi_conversion <- read.csv(paste(TrainTest_loc, "final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)

df_dwi_chronic_desikan <- read.csv(paste(TrainTest_loc, "final_predictions_modality-dwi_rsn-DesikanKlein_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)
df_dwi_conversion_desikan <- read.csv(paste(TrainTest_loc, "final_predictions_modality-dwi_rsn-DesikanKlein_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)

df_dwi_chronic_dummy <- read.csv(paste(TrainTest_loc, "final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid_dummy_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)
df_dwi_conversion_dummy <- read.csv(paste(TrainTest_loc, "final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid_dummy_scores.csv", sep='')) %>% dplyr::rename(., network = atlas)

df_dwi_chronic <- load_dwi_TrainTest(df_dwi_chronic, all_best_dwi_tune_ASE)
df_dwi_chronic_quality <- df_dwi_chronic[[2]]
df_dwi_chronic <- df_dwi_chronic[[1]]
df_dwi_conversion <- load_dwi_TrainTest(df_dwi_conversion, all_best_dwi_tune_ASE)
df_dwi_conversion_quality <- df_dwi_conversion[[2]]
df_dwi_conversion <- df_dwi_conversion[[1]]

df_dwi_chronic_desikan <- load_dwi_TrainTest(df_dwi_chronic_desikan, all_best_dwi_tune_ASE)
df_dwi_chronic_desikan_quality <- df_dwi_chronic_desikan[[2]]
df_dwi_chronic_desikan <- df_dwi_chronic_desikan[[1]]
df_dwi_conversion_desikan <- load_dwi_TrainTest(df_dwi_conversion_desikan, all_best_dwi_tune_ASE)
df_dwi_conversion_desikan_quality <- df_dwi_conversion_desikan[[2]]
df_dwi_conversion_desikan <- df_dwi_conversion_desikan[[1]]

df_dwi_chronic_dummy <- load_dwi_TrainTest(df_dwi_chronic_dummy, all_best_dwi_tune_ASE)
df_dwi_chronic_dummy_quality <- df_dwi_chronic_dummy[[2]]
df_dwi_chronic_dummy <- df_dwi_chronic_dummy[[1]]
df_dwi_conversion_dummy <- load_dwi_TrainTest(df_dwi_conversion_dummy, all_best_dwi_tune_ASE)
df_dwi_conversion_dummy_quality <- df_dwi_conversion_dummy[[2]]
df_dwi_conversion_dummy <- df_dwi_conversion_dummy[[1]]

# Behavioral
setwd(data_dir)
df_behavioral_chronic_scores <- read.csv(paste(TrainTest_loc, "df_summary_MDE_chronic_Behavioral_percentiles_with_nuisance_scores.csv", sep='')) %>% dplyr::select(-grid)
df_behavioral_chronic_quality <- df_behavioral_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_behavioral_chronic_scores <- df_behavioral_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

df_behavioral_conversion_scores <- read.csv(paste(TrainTest_loc, "df_summary_MDE_conversion_Behavioral_percentiles_with_nuisance_scores.csv", sep='')) %>% dplyr::select(-grid)
df_behavioral_conversion_quality <- df_behavioral_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_behavioral_conversion_scores <- df_behavioral_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

# MVPA
setwd(data_dir)
df_func_mvpa_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_func_mvpa_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_mvpa_chronic_quality <- df_func_mvpa_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_mvpa_chronic_scores <- df_func_mvpa_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_func_mvpa_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_func_mvpa_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_mvpa_conversion_quality <- df_func_mvpa_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_mvpa_conversion_scores <- df_func_mvpa_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

df_dwi_mvpa_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_dwi_mvpa_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_mvpa_chronic_quality <- df_dwi_mvpa_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_mvpa_chronic_scores <- df_dwi_mvpa_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_dwi_mvpa_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_dwi_mvpa_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_mvpa_conversion_quality <- df_dwi_mvpa_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_mvpa_conversion_scores <- df_dwi_mvpa_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

# Simulated
setwd(data_dir)
df_func_rdpg_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_func_RDPG_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_rdpg_chronic_quality <- df_func_rdpg_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_rdpg_chronic_scores <- df_func_rdpg_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_func_rdpg_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_func_RDPG_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_rdpg_conversion_quality <- df_func_rdpg_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_rdpg_conversion_scores <- df_func_rdpg_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

df_dwi_rdpg_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_dwi_RDPG_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_rdpg_chronic_quality <- df_dwi_rdpg_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_rdpg_chronic_scores <- df_dwi_rdpg_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_dwi_rdpg_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_dwi_RDPG_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_rdpg_conversion_quality <- df_dwi_rdpg_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_rdpg_conversion_scores <- df_dwi_rdpg_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

# Simulated Erdos Renyi
setwd(data_dir)
df_func_ErdosRenyi_deep_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_func_ErdosRenyi_deep_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_ErdosRenyi_deep_chronic_quality <- df_func_ErdosRenyi_deep_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_ErdosRenyi_deep_chronic_scores <- df_func_ErdosRenyi_deep_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_func_ErdosRenyi_deep_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_func_ErdosRenyi_deep_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_ErdosRenyi_deep_conversion_quality <- df_func_ErdosRenyi_deep_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_ErdosRenyi_deep_conversion_scores <- df_func_ErdosRenyi_deep_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

df_dwi_ErdosRenyi_deep_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_dwi_ErdosRenyi_deep_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_ErdosRenyi_deep_chronic_quality <- df_dwi_ErdosRenyi_deep_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_ErdosRenyi_deep_chronic_scores <- df_dwi_ErdosRenyi_deep_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_dwi_ErdosRenyi_deep_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_dwi_ErdosRenyi_deep_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_ErdosRenyi_deep_conversion_quality <- df_dwi_ErdosRenyi_deep_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_ErdosRenyi_deep_conversion_scores <- df_dwi_ErdosRenyi_deep_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

# Simulated Barabasi
setwd(data_dir)
df_func_barabasi_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_func_barabasi_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_barabasi_chronic_quality <- df_func_barabasi_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_barabasi_chronic_scores <- df_func_barabasi_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_func_barabasi_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_func_barabasi_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_barabasi_conversion_quality <- df_func_barabasi_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_barabasi_conversion_scores <- df_func_barabasi_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

df_dwi_barabasi_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_dwi_barabasi_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_barabasi_chronic_quality <- df_dwi_barabasi_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_barabasi_chronic_scores <- df_dwi_barabasi_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_dwi_barabasi_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_dwi_barabasi_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_barabasi_conversion_quality <- df_dwi_barabasi_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_barabasi_conversion_scores <- df_dwi_barabasi_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

# Simulated Erdos Renyi
setwd(data_dir)
df_func_small_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_func_small_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_small_chronic_quality <- df_func_small_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_small_chronic_scores <- df_func_small_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_func_small_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_func_small_scores.csv', sep='')) %>% dplyr::select(-grid)
df_func_small_conversion_quality <- df_func_small_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_func_small_conversion_scores <- df_func_small_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

df_dwi_small_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_dwi_small_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_small_chronic_quality <- df_dwi_small_chronic_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_small_chronic_scores <- df_dwi_small_chronic_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)
df_dwi_small_conversion_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_conversion_dwi_small_scores.csv', sep='')) %>% dplyr::select(-grid)
df_dwi_small_conversion_quality <- df_dwi_small_conversion_scores %>% dplyr::select(avg_loss, avg_bias, avg_var)
df_dwi_small_conversion_scores <- df_dwi_small_conversion_scores %>% dplyr::select(-avg_loss, -avg_bias, -avg_var)

# Stacked
setwd(data_dir)
df_stacked_func_dwi_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_multimodal_stacking_func_dwi_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_stacked_dwi_beh_chronic_scores <- read.csv(paste(TrainTest_loc, 'df_summary_MDE_chronic_multimodal_stacking_dwi_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_stacked_func_beh_chronic_scores <- read.csv(paste(TrainTest_loc,                                                    'df_summary_MDE_chronic_multimodal_stacking_func_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_stacked_func_dwi_beh_chronic_scores <- read.csv(paste(TrainTest_loc,                                              'df_summary_MDE_chronic_multimodal_stacking_func_dwi_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_voting_func_dwi_chronic_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_chronic_multimodal_voting_func_dwi_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_voting_dwi_beh_chronic_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_chronic_multimodal_voting_dwi_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_voting_func_beh_chronic_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_chronic_multimodal_voting_func_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_voting_func_dwi_beh_chronic_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_chronic_multimodal_voting_func_dwi_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_stacked_func_dwi_conversion_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_conversion_multimodal_stacking_func_dwi_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_stacked_dwi_beh_conversion_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_conversion_multimodal_stacking_dwi_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_stacked_func_dwi_beh_conversion_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_conversion_multimodal_stacking_func_dwi_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_stacked_func_beh_conversion_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_conversion_multimodal_stacking_func_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_voting_dwi_beh_conversion_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_conversion_multimodal_voting_dwi_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_voting_func_dwi_conversion_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_conversion_multimodal_voting_func_dwi_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_voting_func_dwi_beh_conversion_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_conversion_multimodal_voting_func_dwi_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)
df_voting_func_beh_conversion_scores <- read.csv(paste(TrainTest_loc,
'df_summary_MDE_conversion_multimodal_voting_func_beh_with_nuisance_scores.csv', sep='')) %>% dplyr::select(-grid)

func_grid_cols <- c("ExtractionMethod", "FrequencyBandwidth", "ConnectivityEstimator", "NodeGranularity", "NetworkDefinition", "SmoothingTolerance")
dwi_grid_cols <- c("ExtractionMethod", "MinimumFiberLength", "ConnectivityEstimator", "NodeGranularity", "NetworkDefinition", "SmoothingTolerance")
```

### As compared to randomly encoding brain network attributes, does encoding attributes associated with particular behavioral phenotypes improve connectome-based classification of depression prognosis?
```{r pheno_vs_random, message=FALSE, warning=FALSE, fig.width = 7, fig.height=4, fig.align="center", fig.show="hide", echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
out_func  <- make_modality_boot_df(df_func_chronic, df_func_conversion, func_grid_cols, Feature_Space=NULL, x_compare="Random", y_compare='Depression|Rumination', connectome=TRUE)
out_dwi  <- make_modality_boot_df(df_dwi_chronic, df_dwi_conversion, dwi_grid_cols, Feature_Space=NULL, x_compare="Random", y_compare='Depression|Rumination', connectome=TRUE)
out_func$Modality <- 'Functional'
out_dwi$Modality <- 'Structural'
dat_pheno_vs_random <- data.frame(bind_rows(out_func, out_dwi)) %>% mutate_if(is.character, as.factor) %>% mutate(., boot = as.factor(boot))
levels(dat_pheno_vs_random$Feature_Space) <- c("Phenotypically Attributed", "Randomly Attributed")

dat_pheno_vs_random <- data.frame(bind_rows(out_func, out_dwi))

out_pheno_vs_random <- paired_compare(clean_pairs(dat_pheno_vs_random, facet = 'Response'), "Random vs.Phenotypically-Targeted Attributed Connectome Features", "A", 'Response', alternative="less", conf.level = 0.975)
out_pheno_vs_random

out_pheno_vs_random[[1]]
```

To evaluate whether encoding *any* phenotypically-meaningful attributes in general---depression or rumination measures of severity or persistence---to connectomes benefitted classification performance, we next compared performance achieved using the four core phenotype-derived connectome recipes (for rumination vs. depression---both their severity vs. persistence) to that achieved using randomly-derived connectome recipes. See plot A of Figure \ref{fig:all_comparison_freq} for a paired boxplot visualization of the comparisons. The results showed that in the case of classifying chronic depression, AUC was modestly higher when attributing connectomes with phenotypic information ($mean(AUC)$=`r round(mean(dat_pheno_vs_random %>% filter(Response=="Chronic", Feature_Space=='Depression|Rumination') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_pheno_vs_random %>% filter(Response=="Chronic", Feature_Space=='Depression|Rumination') %>% pull(AUC), na.rm=TRUE), 3)`) as compared to random information ($mean(AUC)$=`r round(mean(dat_pheno_vs_random %>% filter(Response=="Chronic", Feature_Space=='Random') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_pheno_vs_random %>% filter(Response=="Chronic", Feature_Space=='Random') %>% pull(AUC), na.rm=TRUE), 3)`)(paired t(`r as.integer(out_pheno_vs_random[[2]]$df)`) = `r out_pheno_vs_random[[2]]$t_stat %>% round(2)`, 95% CI [`r out_pheno_vs_random[[2]]$conf.int[1] %>% round(3)`, `r out_pheno_vs_random[[2]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_pheno_vs_random[[2]]$p*2, digits = 3, prefix = NULL)`). This effect was not observed for classifying depression conversion, however (paired t(`r as.integer(out_pheno_vs_random[[3]]$df)`) = `r out_pheno_vs_random[[3]]$t_stat %>% round(2)`, 95% CI [`r out_pheno_vs_random[[3]]$conf.int[1] %>% round(3)`, `r out_pheno_vs_random[[3]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_pheno_vs_random[[3]]$p, digits = 3, prefix = NULL)`). Given the small size of this effect, however, we next explored whether performance might benefit by using connectome features attributed with more *specific* phenotypic information.

### As compared to encoding contemporaneous brain network attributes of mood severity, does encoding developmentally persistent brain network attributes of mood persistence improve connectome-based classification of depression prognosis?
```{r persistence_vs_severity, message=FALSE, warning=FALSE, fig.width = 20, fig.height=20, fig.align="center", fig.show="hide", echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}

out_func  <- make_modality_boot_df(df_func_chronic, df_func_conversion, func_grid_cols, Feature_Space=NULL, x_compare='Severity', y_compare='Persistence', connectome=TRUE)
out_func$Modality <- 'Functional'
  
out_dwi  <- make_modality_boot_df(df_dwi_chronic, df_dwi_conversion, dwi_grid_cols, Feature_Space=NULL, x_compare='Severity', y_compare='Persistence', connectome=TRUE)
out_dwi$Modality <- 'Structural'

dat_persistence_vs_severity <- data.frame(bind_rows(out_func, out_dwi))
out_severity_vs_persistence <- paired_compare(clean_pairs(dat_persistence_vs_severity, subsample=30, facet=c('Response', 'Modality')), "Symptom Severity vs. Persistence of Phenotypically Attributed Connectome Features", "B", c('Response', 'Modality'), conf.level = 0.9875)
out_severity_vs_persistence
```

We next explored whether performance benefitted by using connectome features encoded with the developmental attributes learned in the souce domain. When controlling for multimodal interactions and applying a Bonferroni adjusted alpha level of .0125 per test (.05/4), we observed that functional connectome features attributed with contemporaneous attributes significantly improved classification of depression conversion and chronicity ($mean(AUC)$=`r round(mean(dat_persistence_vs_severity %>% filter(Feature_Space=="Severity", Modality=='Functional') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_persistence_vs_severity %>% filter(Feature_Space=="Severity", Modality=='Functional') %>% pull(AUC), na.rm=TRUE), 3)`) as compared to that of mood persistence attributes ($mean(AUC)$=`r round(mean(dat_persistence_vs_severity %>% filter(Feature_Space=="Persistence", Modality=='Functional') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_persistence_vs_severity %>% filter(Feature_Space=="Persistence", Modality=='Functional') %>% pull(AUC), na.rm=TRUE), 3)`)(Chronic: paired t(`r as.integer(out_severity_vs_persistence[[2]]$df)`) = `r out_severity_vs_persistence[[2]]$t_stat %>% round(2)`, 95% CI [`r out_severity_vs_persistence[[2]]$conf.int[1] %>% round(3)`, `r out_severity_vs_persistence[[2]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_severity_vs_persistence[[2]]$p, digits = 3, prefix = NULL)`; Conversion: paired t(`r as.integer(out_severity_vs_persistence[[3]]$df)`) = `r out_severity_vs_persistence[[3]]$t_stat %>% round(2)`, 95% CI [`r out_severity_vs_persistence[[3]]$conf.int[1] %>% round(3)`, `r out_severity_vs_persistence[[3]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_severity_vs_persistence[[3]]$p, digits = 3, prefix = NULL)`). Similarly, structural connectome features attributed with contemporaneous mood attributes also significantly improved classification of depression conversion ($mean(AUC)$=`r round(mean(dat_persistence_vs_severity %>% filter(Feature_Space=="Severity", Modality=='Structural', Response=='Conversion') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_persistence_vs_severity %>% filter(Feature_Space=="Severity", Modality=='Structural', Response=='Conversion') %>% pull(AUC), na.rm=TRUE), 3)`) as compared to that of persistence attributes ($mean(AUC)$=`r round(mean(dat_persistence_vs_severity %>% filter(Feature_Space=="Persistence", Modality=='Structural', Response=='Conversion') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_persistence_vs_severity %>% filter(Feature_Space=="Persistence", Modality=='Structural', Response=='Conversion') %>% pull(AUC), na.rm=TRUE), 3)`) (paired t(`r as.integer(out_severity_vs_persistence[[5]]$df)`) = `r out_severity_vs_persistence[[5]]$t_stat %>% round(2)`, 95% CI [`r out_severity_vs_persistence[[5]]$conf.int[1] %>% round(3)`, `r out_severity_vs_persistence[[5]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_severity_vs_persistence[[5]]$p, digits = 3, prefix = NULL)`). In contrast to functional connectome features, however, this difference was reversed in the case of chronic depression, where mood persistence attributes also significantly improved classification of depression conversion ($mean(AUC)$=`r round(mean(dat_persistence_vs_severity %>% filter(Feature_Space=="Severity", Modality=='Structural', Response=='Chronic') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_persistence_vs_severity %>% filter(Feature_Space=="Severity", Modality=='Structural', Response=='Chronic') %>% pull(AUC), na.rm=TRUE), 3)`) as compared to that of mood severity attributes ($mean(AUC)$=`r round(mean(dat_persistence_vs_severity %>% filter(Feature_Space=="Persistence", Modality=='Structural', Response=='Chronic') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_persistence_vs_severity %>% filter(Feature_Space=="Persistence", Modality=='Structural', Response=='Chronic') %>% pull(AUC), na.rm=TRUE), 3)`)(paired t(`r as.integer(out_severity_vs_persistence[[4]]$df)`) = `r out_severity_vs_persistence[[4]]$t_stat %>% round(2)`, 95% CI [`r out_severity_vs_persistence[[4]]$conf.int[1] %>% round(3)`, `r out_severity_vs_persistence[[4]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_severity_vs_persistence[[4]]$p, digits = 3, prefix = NULL)`). See plot B of Figure \ref{fig:all_comparison_freq} for paired boxplot visualization of the comparisons for each depression outcome type and interaction across data modalities.

### As compared to encoding brain network attributes of depression directly, does encoding attributes of rumination improve connectome-based classification of depression prognosis?
```{r rum_vs_dep, message=FALSE, warning=FALSE, fig.width = 20, fig.height=20, fig.align="center", fig.show="hide", echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
out_func  <- make_modality_boot_df(df_func_chronic, df_func_conversion, func_grid_cols, Feature_Space=NULL, x_compare='Rumination', y_compare='Depression', connectome=TRUE)
out_func$Modality <- "Functional"

out_dwi  <- make_modality_boot_df(df_dwi_chronic, df_dwi_conversion, dwi_grid_cols, Feature_Space=NULL, x_compare='Rumination', y_compare='Depression', connectome=TRUE)
out_dwi$Modality <- "Structural"

dat_rum_vs_dep_func <- data.frame(bind_rows(out_func, out_dwi))

out_rum_vs_dep_func <- paired_compare(clean_pairs(dat_rum_vs_dep_func, facet=c('Response', 'Modality')), "Rumination vs. Depression Phenotypically Attributed Connectome Features", "C", c('Response', 'Modality'), conf.level = 0.9875)
out_rum_vs_dep_func
```

After learning that developmental specificity interacted with connectome modality (i.e., severity outperformed persistence in all cases except for when predicting chronic depression using the structural modality), we next compared classification performance when encoding connectome features with rumination attributes versus depression attributes. Since, as we discovered earlier, attributing connectomes with any phenotypic information as compared to random information did not improve predictions above chance when classifying depression conversion risk, yet subsequent analysis showed a strong temporal affinity of depression conversion to contemporaneous temporal attributes of severity, we here assessed only depression severity vs. rumination severity rather than allow for its persistence specifier. In the case of classifying chronic depression, however, we proceeded to evaluate differences in predictive performance as conferred by rumination vs. depression irrespective of temporal specifier. Again controlling for multimodal interactions and applying a Bonferroni adjusted alpha level of .0125 per test (.05/4), our results generally showed that the choice of connectome attributes optimized for depression vs. rumination phenotypes was associated with meaningful differences in AUC in most cases, though the direction of this relationship varied depending on the response variable and the data modality. See plot C of Figure \ref{fig:all_comparison_freq} for paired boxplot visualization of the comparisons for each depression outcome type. When classifying chronic depression using functional connectomes, we did not observe any significant difference in AUC when attributing the connectomes with rumination attributes as compared to depression attributes (paired t(`r as.integer(out_rum_vs_dep_func[[2]]$df)`) = `r out_rum_vs_dep_func[[2]]$t_stat %>% round(2)`, 95% CI [`r out_rum_vs_dep_func[[2]]$conf.int[1] %>% round(3)`, `r out_rum_vs_dep_func[[2]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_rum_vs_dep_func[[2]]$p, digits = 3, prefix = NULL)`). When classifying depression conversion using functional connectomes, however, we did find a significant gain in AUC when attributing the connectomes with rumination attributes ($mean(AUC)$=`r round(mean(dat_rum_vs_dep_func %>% filter(Response=="Conversion", grepl('Rumination', Feature_Space), Modality=='Functional') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_rum_vs_dep_func %>% filter(Response=="Conversion", grepl('Rumination', Feature_Space), Modality=='Functional') %>% pull(AUC), na.rm=TRUE), 3)`) as compared to depression attributes ($mean(AUC)$=`r round(mean(dat_rum_vs_dep_func %>% filter(Response=="Conversion", grepl('Depression', Feature_Space), Modality=='Functional') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_rum_vs_dep_func %>% filter(Response=="Conversion", grepl('Depression', Feature_Space), Modality=='Functional') %>% pull(AUC), na.rm=TRUE), 3)`) (paired t(`r as.integer(out_rum_vs_dep_func[[3]]$df)`) = `r out_rum_vs_dep_func[[3]]$t_stat %>% round(2)`, 95% CI [`r out_rum_vs_dep_func[[3]]$conf.int[1] %>% round(3)`, `r out_rum_vs_dep_func[[3]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_rum_vs_dep_func[[3]]$p, digits = 3, prefix = NULL)`). 
When classifying chronic depression using structural connectomes, we found a significant gain in AUC when attributing the connectomes with rumination attributes ($mean(AUC)$=`r round(mean(dat_rum_vs_dep_func %>% filter(Response=="Chronic", grepl('Rumination', Feature_Space), Modality=='Structural') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_rum_vs_dep_func %>% filter(Response=="Chronic", grepl('Rumination', Feature_Space), Modality=='Structural') %>% pull(AUC), na.rm=TRUE), 3)`) as compared to depression attributes ($mean(AUC)$=`r round(mean(dat_rum_vs_dep_func %>% filter(Response=="Chronic", grepl('Depression', Feature_Space), Modality=='Structural') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_rum_vs_dep_func %>% filter(Response=="Chronic", grepl('Depression', Feature_Space), Modality=='Structural') %>% pull(AUC), na.rm=TRUE), 3)`)(paired t(`r as.integer(out_rum_vs_dep_func[[4]]$df)`) = `r out_rum_vs_dep_func[[4]]$t_stat %>% round(2)`, 95% CI [`r out_rum_vs_dep_func[[4]]$conf.int[1] %>% round(3)`, `r out_rum_vs_dep_func[[4]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_rum_vs_dep_func[[4]]$p, digits = 3, prefix = NULL)`). When classifying depression conversion using structural connectomes, however, we also found a significant gain in AUC, but in the opposite direction---attributing the connectomes with depression attributes ($mean(AUC)$=`r round(mean(dat_rum_vs_dep_func %>% filter(Response=="Conversion", grepl('Depression', Feature_Space), Modality=='Structural') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_rum_vs_dep_func %>% filter(Response=="Conversion", grepl('Depression', Feature_Space), Modality=='Structural') %>% pull(AUC), na.rm=TRUE), 3)`) rather than rumination attributes ($mean(AUC)$=`r round(mean(dat_rum_vs_dep_func %>% filter(Response=="Conversion", grepl('Rumination', Feature_Space), Modality=='Structural') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_rum_vs_dep_func %>% filter(Response=="Conversion", grepl('Rumination', Feature_Space), Modality=='Structural') %>% pull(AUC), na.rm=TRUE), 3)`) conferred the greatest gains in performance (paired t(`r as.integer(out_rum_vs_dep_func[[5]]$df)`) = `r out_rum_vs_dep_func[[5]]$t_stat %>% round(2)`, 95% CI [`r out_rum_vs_dep_func[[5]]$conf.int[1] %>% round(3)`, `r out_rum_vs_dep_func[[5]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_rum_vs_dep_func[[5]]$p, digits = 3, prefix = NULL)`). 

```{r}
df_func_chronic <- as.data.frame(setDT(df_func_chronic)[which.max(df_func_chronic %>% dplyr::select(starts_with("X")) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC) %>% as.matrix()), Phenotype:="Best_Space"])
df_func_conversion <- as.data.frame(setDT(df_func_conversion)[which.max(df_func_conversion %>% dplyr::select(starts_with("X")) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC) %>% as.matrix()), Phenotype:="Best_Space"])
df_dwi_chronic <- as.data.frame(setDT(df_dwi_chronic)[which.max(df_dwi_chronic %>% dplyr::select(starts_with("X")) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC) %>% as.matrix()), Phenotype:="Best_Space"])
df_dwi_conversion <- as.data.frame(setDT(df_dwi_conversion)[which.max(df_dwi_conversion %>% dplyr::select(starts_with("X")) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC) %>% as.matrix()), Phenotype:="Best_Space"])

df_func_chronic_desikan <- as.data.frame(setDT(df_func_chronic_desikan)[which.max(df_func_chronic_desikan %>% dplyr::select(starts_with("X")) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC) %>% as.matrix()), Phenotype:="Best_Space"])
df_func_conversion_desikan <- as.data.frame(setDT(df_func_conversion_desikan)[which.max(df_func_conversion_desikan %>% dplyr::select(starts_with("X")) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC) %>% as.matrix()), Phenotype:="Best_Space"])
df_dwi_chronic_desikan <- as.data.frame(setDT(df_dwi_chronic_desikan)[which.max(df_dwi_chronic_desikan %>% dplyr::select(starts_with("X")) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC) %>% as.matrix()), Phenotype:="Best_Space"])
df_dwi_conversion_desikan <- as.data.frame(setDT(df_dwi_conversion_desikan)[which.max(df_dwi_conversion_desikan %>% dplyr::select(starts_with("X")) %>% mutate(AUC = rowMeans(., na.rm = TRUE)) %>% dplyr::select(AUC) %>% as.matrix()), Phenotype:="Best_Space"])
save.image(paste(root.dir, "/../AllCache_Appendix_Chapter-IV.RData", sep = ''))
```

### Do synthetic (i.e. randomly-rewired) connectomes perform comparably to "observed" connectomes for classification of depression prognosis?
```{python eval=FALSE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
import pandas as pd
import re
import glob
import ast
import scipy.sparse as sp
import pynets.core.thresholding
import numpy as np
import json
from pynets.core.thresholding import normalize
from pynets.stats.prediction import bootstrapped_nested_cv, preprocess_x_y, MakeDF
from graspologic.embed import AdjacencySpectralEmbed
from graspologic.simulations import er_np, sbm, rdpg
import graph_tool.all as gt
import networkx as nx

in_path = '/home/dpys/Documents/Dissertation/Chapter_IV/data/TrainTest_set/df_depressed_TrainTest_final.pkl'

df_raw = pd.read_pickle(in_path)

nuisance_cols = ['num_visits', 'sex', 'age', 'race_1.0', 'race_2.0', 'race_3.0', 'race_5.0', 'ethnicity_0.0', 'ethnicity_1.0', 'ethnicity_2.0', 'language_1.0', 'language_2.0', 'language_4.0', 'language_6.0', 'dataset', 'antidepressants', 'comorbid', 'past_depression', 'total_study_duration']

def gen_g(in_mat, random=False, model='er'):
    wt = np.random.normal
    wtargs = dict(loc=0, scale=1)
    G = nx.from_numpy_array(in_mat)
    N=int(np.sum(np.ones(in_mat.shape[0])))
    edges=len(G.edges())
    if random is False:
        PROB = np.sum(in_mat>0)/np.sum(np.ones(in_mat.shape))
        print(f"{N} nodes")
        print(f"{edges} edges")
        print(f"{PROB} probability")
        
        if model == 'er':
            G1 = er_np(n=N, p=PROB, wt=wt, wtargs=wtargs)
            
        if model == 'small':
            a = np.abs(list(nx.average_neighbor_degree(G, weight='weight').values()))
            K = int(np.mean(a[(np.nonzero(a)) and np.where(a < N)]))
            if not K > 0 and not K < 60:
                K=2
            G1 = nx.to_numpy_array(nx.watts_strogatz_graph(n=N, k=K, p=PROB, seed=42), weight='weight')
        if model == 'barabasi':
            a = np.abs(list(nx.average_neighbor_degree(G, weight='weight').values()))
            K = int(np.mean(a[(np.nonzero(a)) and np.where(a < N)]))
            if not K > 0 and not K < 60:
                K=2
            G1 = nx.to_numpy_array(nx.barabasi_albert_graph(n=N, m=K, seed=42), weight='weight')
    else:
        G1 = rdpg(in_mat, loops=False)

    return G1


# plot_conn_mat(conn_matrix, labels, out_path_fig, cmap=plt.get_cmap('RdBu_r'), dpi_resolution=600)
# 
# plot_conn_mat(adj, list(graph_dict[pheno][modality]['roi_dict'].values()), f"{results_dir}/anomoly_connectome_nbs_{pheno}_{modality}.png", cmap=plt.get_cmap('coolwarm'), dpi_resolution=600)
#     
def grab_coords_labels(node_file):
    with open(node_file, 'r+') as f:
        node_dict = json.load(f)
    indices = [i['index'] for i in
               node_dict]
    coords = [i['coord'] for i in
              node_dict]
    if isinstance(node_dict[0]['label'], str):
        labels = [
            ast.literal_eval(
                re.search('({.+})',
                          i['label']).group(0))[
                'BrainnetomeAtlasFan2016'] for i in
            node_dict]
    else:
        labels = [
            list(i['label'])[0][
                'BrainnetomeAtlasFan2016'] for i in
            node_dict]
    return indices, coords, labels
  

def make_graph_dict(df_raw, graph_dict={}, phenos=['conversion', 'chronic'], modalities=['dwi', 'func'], gtype='deep', model='small'):
    df_subs = []
    for pheno in phenos:
        graph_dict[pheno] = {}
        for modality in modalities:
            node_set = glob.glob(f"/home/dpys/Documents/best_graphs/{pheno}/{modality}/*.json")
            usable_subs = list(set([i.split('sub-')[1].split('.json')[0] for i in node_set]))
            graph_set = glob.glob(f"/home/dpys/Documents/best_graphs/{pheno}/{modality}/*.npy")
            graph_set = [i for i in graph_set if i.split('sub-')[1].split('_')[0] in usable_subs]
            graph_dict[pheno][modality] = {}
            mask = df_raw['participant_id'].isin(list(set(usable_subs)))
            df_masked = df_raw[mask].drop_duplicates(subset='participant_id', keep="first")
            df_frames = []
            for sub in list(set(usable_subs)):
                node_file = [i for i in node_set if sub in i][0]
                graph_list = [np.load(i) for i in graph_set if sub in i]
                if modality == 'dwi' and len(graph_list) > 1:
                    in_mat = np.array(np.array(graph_list)).max(axis=0)
                else:
                    in_mat = graph_list[0]
                #print(np.sum(in_mat))
                in_mat = normalize(in_mat)
                [indices, coords, labels] = grab_coords_labels(node_file)
                if len(indices) != np.shape(in_mat)[0]:
                    print(f"nodes not equal to indices for {sub}")
                    continue
                if np.sum(in_mat>0)/np.sum(np.ones(in_mat.shape)) == 0:
                    continue
                
                if sub in df_masked.participant_id.values:
                    try:
                        if gtype == 'deep':
                            DATA=AdjacencySpectralEmbed(n_components=1).fit_transform(gen_g(in_mat, model=model)).reshape(1, -1)
                        elif gtype == 'rand':
                            DATA=AdjacencySpectralEmbed(n_components=1).fit_transform(gen_g(in_mat, random=True)).reshape(1, -1)
                        else:
                            DATA=AdjacencySpectralEmbed(n_components=1).fit_transform(in_mat).reshape(1, -1)
                        df_flat = pd.DataFrame(data=DATA,
                              columns=[f"{modality}_{i}" for i in labels],
                              index=[sub])
                              
                        df_flat.columns = [j + f'_{i}' if df_flat.columns.duplicated()[i] else j for i,j in enumerate(df_flat.columns)]
                        
                    except:
                        df_flat = pd.DataFrame(pd.Series(np.array([np.nan]*len([f"{modality}_{i}" for i in labels])), name=sub), index=[sub], columns=[f"{modality}_{i}" for i in labels])
                        continue
                    if df_flat.index[0] not in [i.index[0] for i in df_frames]:
                        df_frames.append(df_flat)
                    
            df_all = pd.concat(df_frames, axis=0)
            df_all = df_all.apply(lambda x: np.where(np.abs(x) < 0.000001, 0, x))
            df_all = df_all.T.loc[(df_all == 0).sum() < (
                float(0.50)) * df_all.shape[0]].T
            df_all = df_all[~(df_all.T < 0.000001).all()]
            df_all = df_all.dropna(axis=1, thresh=80)
            df_all = df_all.reset_index()
            df_all = df_all.rename(columns={'index': 'participant_id'})
            df_all = df_masked.merge(df_all, on='participant_id')
            graph_dict[pheno][modality] = df_all
    return graph_dict

graph_dict = make_graph_dict(df_raw, gtype='deep', model='barabasi')

phenos=['conversion', 'chronic']
modalities=['dwi', 'func']
for modality in modalities:                
    for target_var in ['MDE_conversion', 'MDE_chronic']:
        df = graph_dict[target_var.split('_')[1]][modality]
        X = df.drop(columns=['participant_id', 'MDE_conversion', 'MDE_chronic'])
        X = X.loc[:, ~X.columns.str.startswith('Beh')]
        y = df[target_var]
    
        [
                                grand_mean_best_estimator,
                                grand_mean_best_score,
                                grand_mean_best_error,
                                mega_feat_imp_dict,
                                grand_mean_y_predicted,
                                final_est
                            ] = bootstrapped_nested_cv(X, y, nuisance_cols, n_boots=1000, stack=False, dummy_run=False, search_method='grid', n_jobs=-1)

        print(grand_mean_best_score)
        print(grand_mean_best_error)
        mdf = MakeDF()
        mdf.inputs.grand_mean_best_estimator = grand_mean_best_estimator
        mdf.inputs.grand_mean_best_score = grand_mean_best_score
        mdf.inputs.grand_mean_y_predicted = grand_mean_y_predicted
        mdf.inputs.grand_mean_best_error = grand_mean_best_error
        mdf.inputs.mega_feat_imp_dict = mega_feat_imp_dict
        mdf.inputs.target_var = target_var
        mdf.inputs.modality = modality
        mdf.inputs.embedding_type = 'barabasi'
        mdf.inputs.grid_param = '[\'with_nuisance\']'
    
        outs = mdf.run()
```

```{r observed_vs_simulated, message=FALSE, warning=FALSE, fig.width = 20, fig.height=15, fig.align="center", fig.show="hide", echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
out_func1  <- make_modality_boot_df(df_func_chronic %>% filter(grepl('Best_Space', Phenotype)), df_func_conversion %>% filter(grepl('Best_Space', Phenotype)), func_grid_cols, Feature_Space='\nAttributed\nObserved\n', x_compare=NULL, y_compare =NULL)
out_dwi1  <- make_modality_boot_df(df_dwi_chronic %>% filter(grepl('Best_Space', Phenotype)), df_dwi_conversion %>% filter(grepl('Best_Space', Phenotype)), dwi_grid_cols, Feature_Space='\nAttributed\nObserved\n', x_compare=NULL, y_compare=NULL)
out_func1$Modality <- "Functional"
out_dwi1$Modality <- "Structural"

df_func_rdpg_chronic_scores$Phenotype <- "RDPG"
df_func_rdpg_conversion_scores$Phenotype <- "RDPG"
df_dwi_rdpg_chronic_scores$Phenotype <- "RDPG"
df_dwi_rdpg_conversion_scores$Phenotype <- "RDPG"

out_func2  <- make_modality_boot_df(df_func_rdpg_chronic_scores , df_func_rdpg_conversion_scores, func_grid_cols, Feature_Space='\nAttributed\nRDPG\nSimulated\n', x_compare=NULL, y_compare =NULL)
out_dwi2  <- make_modality_boot_df(df_dwi_rdpg_chronic_scores, df_dwi_rdpg_conversion_scores, dwi_grid_cols, Feature_Space='\nAttributed\nRDPG\nSimulated\n', x_compare=NULL, y_compare=NULL)
out_func2$Modality <- "Functional"
out_dwi2$Modality <- "Structural"

df_func_ErdosRenyi_deep_chronic_scores$Phenotype <- "ErdosRenyi"
df_func_ErdosRenyi_deep_conversion_scores$Phenotype <- "ErdosRenyi"
df_dwi_ErdosRenyi_deep_chronic_scores$Phenotype <- "ErdosRenyi"
df_dwi_ErdosRenyi_deep_conversion_scores$Phenotype <- "ErdosRenyi"

out_func3  <- make_modality_boot_df(df_func_ErdosRenyi_deep_chronic_scores , df_func_ErdosRenyi_deep_conversion_scores, func_grid_cols, Feature_Space='\nAttributed\nErdos-Renyi\nSimulated\n', x_compare=NULL, y_compare =NULL)
out_dwi3  <- make_modality_boot_df(df_dwi_ErdosRenyi_deep_chronic_scores, df_dwi_ErdosRenyi_deep_conversion_scores, dwi_grid_cols, Feature_Space='\nAttributed\nErdos-Renyi\nSimulated\n', x_compare=NULL, y_compare=NULL)
out_func3$Modality <- "Functional"
out_dwi3$Modality <- "Structural"

df_func_barabasi_chronic_scores$Phenotype <- "BarabasiAlbert"
df_func_barabasi_conversion_scores$Phenotype <- "BarabasiAlbert"
df_dwi_barabasi_chronic_scores$Phenotype <- "BarabasiAlbert"
df_dwi_barabasi_conversion_scores$Phenotype <- "BarabasiAlbert"

out_func4  <- make_modality_boot_df(df_func_barabasi_chronic_scores , df_func_barabasi_conversion_scores, func_grid_cols, Feature_Space='\nAttributed\nBarabasi-Albert\nSimulated\n', x_compare=NULL, y_compare =NULL)
out_dwi4  <- make_modality_boot_df(df_dwi_barabasi_chronic_scores, df_dwi_barabasi_conversion_scores, dwi_grid_cols, Feature_Space='\nAttributed\nBarabasi-Albert\nSimulated\n', x_compare=NULL, y_compare=NULL)
out_func4$Modality <- "Functional"
out_dwi4$Modality <- "Structural"

df_func_small_chronic_scores$Phenotype <- "WattsStrogatz"
df_func_small_conversion_scores$Phenotype <- "WattsStrogatz"
df_dwi_small_chronic_scores$Phenotype <- "WattsStrogatz"
df_dwi_small_conversion_scores$Phenotype <- "WattsStrogatz"

out_func5  <- make_modality_boot_df(df_func_small_chronic_scores , df_func_small_conversion_scores, func_grid_cols, Feature_Space='\nAttributed\nWatts-Strogatz\nSimulated\n', x_compare=NULL, y_compare =NULL)
out_dwi5  <- make_modality_boot_df(df_dwi_small_chronic_scores, df_dwi_small_conversion_scores, dwi_grid_cols, Feature_Space='\nAttributed\nWatts-Strogatz\nSimulated\n', x_compare=NULL, y_compare=NULL)
out_func5$Modality <- "Functional"
out_dwi5$Modality <- "Structural"

dat_connectome_vs_sim <- data.frame(bind_rows(out_func1, out_func1, out_func2, out_func3, out_func4, out_func5, out_dwi1, out_dwi1, out_dwi2, out_dwi3, out_dwi4, out_dwi5))
out_connectome_vs_sim <- paired_compare(clean_pairs(dat_connectome_vs_sim, facet=c("Response", "Modality")), "\nSimulated Connectome Features vs. Attributed Connectome Features", "D", facet=c("Response", "Modality"), conf.level = 0.995)
out_connectome_vs_sim
```

We next sought to determine the extent to which the most predictive, learned attributes of the connectome features could be a byproduct purely of a "best-fit" learning process rather than biologically "real" brain network properties. To evaluate this, we created a series of synthetic connectomes by randomly rewiring that of each subject for the same node granularity and edge density. In particular we relied on (1) a Random Dot-Product Graph (RDPG)~\cite{Young2007}, in which the probability of an edge existing between pairs of vertices is determined by the dot product of their associated latent position vectors which are randomly sampled from a prespecified distribution (here, $Normal(0, 1)$); (2) an Erdos-Renyi graph~\cite{Erdos1959}---a special case of RDPG, in which all edges are assumed independent and equally likely; (3) a Watts-Strogatz graph~\cite{Watts1998}---a special case of Erdos-Renyi, that more realistically accounts for triadic closures and local clustering; and finally (4) a Barabasi-Albert graph---a scale-free improvement upon Erdos-Renyi and Watts-Strogatz (which do not not exhibit power laws) that incorporates growth and preferential attachment to more closely approximate the hub-emergence processes of real-world networks, including brain networks. Based on paired comparisons of cross-validated bootstrapped classification performance of chronic depression, AUC was significantly higher for the "observed", non-simulated connectome features ($mean(AUC)$=`r round(mean(dat_connectome_vs_sim %>% filter(Feature_Space=='\nAttributed\nObserved\n') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_connectome_vs_sim %>% filter(Feature_Space=='\nAttributed\nObserved\n') %>% pull(AUC), na.rm=TRUE), 3)`) than for all simulated connectome features ($mean(AUC)$=`r round(mean(dat_connectome_vs_sim %>% filter(Feature_Space!='\nAttributed\nObserved\n') %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_connectome_vs_sim %>% filter(Feature_Space!='\nAttributed\nObserved\n') %>% pull(AUC), na.rm=TRUE), 3)`f)(Functional ~ RDPG: paired t(`r as.integer(out_connectome_vs_sim[[38]]$df)`) = `r out_connectome_vs_sim[[38]]$t_stat %>% round(2)`, 95% CI [`r out_connectome_vs_sim[[38]]$conf.int[1] %>% round(3)`, `r out_connectome_vs_sim[[38]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_connectome_vs_sim[[38]]$p, digits = 3, prefix = NULL)`, Erdos-Renyi: paired t(`r as.integer(out_connectome_vs_sim[[23]]$df)`) = `r out_connectome_vs_sim[[23]]$t_stat %>% round(2)`, 95% CI [`r out_connectome_vs_sim[[23]]$conf.int[1] %>% round(3)`, `r out_connectome_vs_sim[[23]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_connectome_vs_sim[[23]]$p, digits = 3, prefix = NULL)`, Watts-Strogatz: paired t(`r as.integer(out_connectome_vs_sim[[43]]$df)`) = `r out_connectome_vs_sim[[43]]$t_stat %>% round(2)`, 95% CI [`r out_connectome_vs_sim[[43]]$conf.int[1] %>% round(3)`, `r out_connectome_vs_sim[[43]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_connectome_vs_sim[[43]]$p, digits = 3, prefix = NULL)`, Barabasi-Albert: paired t(`r as.integer(out_connectome_vs_sim[[8]]$df)`) = `r out_connectome_vs_sim[[8]]$t_stat %>% round(2)`, 95% CI [`r out_connectome_vs_sim[[8]]$conf.int[1] %>% round(3)`, `r out_connectome_vs_sim[[8]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_connectome_vs_sim[[8]]$p, digits = 3, prefix = NULL)`, Structural ~ RDPG: paired t(`r as.integer(out_connectome_vs_sim[[39]]$df)`) = `r out_connectome_vs_sim[[39]]$t_stat %>% round(2)`, 95% CI [`r out_connectome_vs_sim[[39]]$conf.int[1] %>% round(3)`, `r out_connectome_vs_sim[[39]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_connectome_vs_sim[[39]]$p, digits = 3, prefix = NULL)`, Erdos-Renyi: paired t(`r as.integer(out_connectome_vs_sim[[25]]$df)`) = `r out_connectome_vs_sim[[25]]$t_stat %>% round(2)`, 95% CI [`r out_connectome_vs_sim[[25]]$conf.int[1] %>% round(3)`, `r out_connectome_vs_sim[[25]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_connectome_vs_sim[[25]]$p, digits = 3, prefix = NULL)`, Watts-Strogatz: paired t(`r as.integer(out_connectome_vs_sim[[44]]$df)`) = `r out_connectome_vs_sim[[44]]$t_stat %>% round(2)`, 95% CI [`r out_connectome_vs_sim[[44]]$conf.int[1] %>% round(3)`, `r out_connectome_vs_sim[[44]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_connectome_vs_sim[[44]]$p, digits = 3, prefix = NULL)`, Barabasi-Albert: paired t(`r as.integer(out_connectome_vs_sim[[9]]$df)`) = `r out_connectome_vs_sim[[9]]$t_stat %>% round(2)`, 95% CI [`r out_connectome_vs_sim[[9]]$conf.int[1] %>% round(3)`, `r out_connectome_vs_sim[[9]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_connectome_vs_sim[[9]]$p, digits = 3, prefix = NULL)`). Interestingly, the observed connectomes were outperformed by Erdos-Renyi in the case of classifying depression conversion, for which the learning process for the observed connectomes had not been tailored. This is not an uncommon type of finding when studying neurobiologically implausible generative models like Erdos-Renyi when their parameters are fit according to informative metadata, simply due to the added complexity that results~\cite{Betzel2017}. See plot D of Figure \ref{fig:all_comparison_freq} for paired boxplot visualization of the comparisons for each depression outcome type.

### As compared to unimodal predictions, does "stacking" combinations of multiple attributed connectome classifiers, optimized for each data modality (i.e. structural, functional, and behavioral) improve prognostic classification?
```{python eval=FALSE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
import glob
import os
from pynets.stats.embeddings import build_masetome, build_asetomes
from pynets.stats.netstats import collect_pandas_df_make
#from pynets.stats.netmotifs import motif_matching, multigraph_matching
from joblib import Parallel, delayed
from pynets.stats.utils import node_files_search
import re
import pandas as pd
from pynets.core import utils
from itertools import groupby
import re
import shutil
import numpy as np
from pathlib import Path
from collections import Counter

working_dir = f"/working/TrainTest_set/outputs"


def get_embeddings_multi(sub, sesh, working_dir, response):
    from pynets.stats.embeddings import _ase_embed

    try:
        if response == 'MDE_chronic':
            rsn_func = 'rsn-inter_res-180'
            rsn_dwi = 'rsn-language_res-135'
            dwis = [_ase_embed(np.load(i), rsn_dwi.split('-')[1].split('_')[0], i, rsn_dwi.split('_')[1].split('-')[1], n_components=1, prune=0, norm=3) for i in glob.glob(f"{working_dir}/pynets/{sub}/ses-{sesh}/dwi/{rsn_dwi}/graphs/rawgraph_*model-sfm*directget-prob*minlength-0_tol-10.npy")]
            funcs = [_ase_embed(np.load(i), rsn_func.split('-')[1].split('_')[0], i, rsn_func.split('_')[1].split('-')[1], n_components=1, prune=3, norm=3) for i in glob.glob(f"{working_dir}/pynets/{sub}/ses-{sesh}/func/{rsn_func}/graphs/rawgraph_*_model-corr*hpass-0.08Hz*extract-median.npy") if ('smooth' not in i)]
        elif response == 'MDE_conversion':
            rsn_func = 'rsn-inter_res-135'
            rsn_dwi = 'rsn-language_res-135'
            dwis = [_ase_embed(np.load(i), rsn_dwi.split('-')[1].split('_')[0], i, rsn_dwi.split('_')[1].split('-')[1], n_components=1, prune=0, norm=3) for i in glob.glob(f"{working_dir}/pynets/{sub}/ses-{sesh}/dwi/{rsn_dwi}/embeddings/gradient-ASE_{rsn_dwi}*model-sfm*directget-det*minlength-0_tol-5.npy")]
            funcs = [_ase_embed(np.load(i), rsn_func.split('-')[1].split('_')[0], i, rsn_func.split('_')[1].split('-')[1], n_components=1, prune=3, norm=3) for i in glob.glob(f"{working_dir}/pynets/{sub}/ses-{sesh}/func/{rsn_func}/embeddings/gradient-ASE_{rsn_func}*_model-cov*smooth-3*hpass-0Hz*extract-median.npy")]
    except:
        print("Embedding failed!")
        return

    if len(dwis) == 0 or len(funcs) == 0:
        if len(funcs) == 0:
            print("Failed funcs...")
        if len(dwis) == 0:
            print("Failed dwis...")
        return

    namer_dir = f"{working_dir}/pynets/{sub}/ses-{sesh}/graphs_multilayer"
    os.makedirs(namer_dir + '/mplx_graphs', exist_ok=True)
    os.makedirs(namer_dir + '/mplx_embeddings', exist_ok=True)
    os.makedirs(namer_dir + '/mplx_graphs/mplx_embeddings', exist_ok=True)

    node_files_func = glob.glob(f"/working/TrainTest_set/outputs/pynets/{sub}/"
                           f"ses-{sesh}/func/{rsn_func}/nodes/*.json")

    node_files_dwi = glob.glob(f"/working/TrainTest_set/outputs/pynets/{sub}/"
                           f"ses-{sesh}/dwi/{rsn_dwi}/nodes/*.json")

    if len(node_files_func) == 0 or len(node_files_dwi) == 0:
        print("Failed node_files...")
        return

    dwi_frames = []
    for dwi_path in dwis:
        try:
            ixs_corr_dwi, node_dict_revised = node_files_search(node_files_dwi,
                                                            np.load(dwi_path).shape[0])
            labels_dwi = [node_dict_revised[i]['label']['BrainnetomeAtlasFan2016'] for i in node_dict_revised]

        except:
            print(dwi_path)
            print("Failed dwi_path...")
            continue

        df_dwi = pd.DataFrame(data=np.load(dwi_path).reshape(1, -1),
                              columns=[f"dwi_{i}" for i in labels_dwi],
                              index=[sub])
        df_dwi = df_dwi.groupby(by=df_dwi.columns, axis=1).mean()
        dwi_frames.append(df_dwi)

    if len(dwi_frames) == 0:
        print("Failed dwi frames...")
        return

    df_dwi_all = pd.concat(dwi_frames, axis=0)
    df_dwi_all = df_dwi_all.apply(lambda x: np.where(np.abs(x) < 0.000001, 0, x))
    df_dwi_all = df_dwi_all.T.loc[(df_dwi_all == 0).sum() < (
        float(0.50)) * df_dwi_all.shape[0]].T
    df_dwi_all = df_dwi_all[~(df_dwi_all.T < 0.000001).all()]
    df_dwi_mean = pd.DataFrame(df_dwi_all.mean(axis=0)).T

    func_frames = []
    for func_path in funcs:
        try:

            ixs_corr_func, node_dict_revised = node_files_search(
                node_files_func,
                np.load(func_path).shape[0])
            labels_func = [
                node_dict_revised[i]['label']['BrainnetomeAtlasFan2016'] for i
                in node_dict_revised]
        except:
            print("Failed func path...")
            continue

        df_func = pd.DataFrame(data=np.load(func_path).reshape(1, -1),
                              columns=[f"func_{i}" for i in labels_func],
                              index=[sub])

        # df_func = pd.read_csv(func_path)
        # df_func.columns = [f"func_{i}" for i in labels_func]
        df_func = df_func.groupby(by=df_func.columns, axis=1).mean()
        func_frames.append(df_func)

    if len(func_frames) == 0:
        print("Failed func frames...")
        return
    df_func_all = pd.concat(func_frames, axis=0)
    df_func_all = df_func_all.apply(lambda x: np.where(np.abs(x) < 0.000001, 0, x))
    df_func_all = df_func_all.T.loc[(df_func_all == 0).sum() < (
        float(0.50)) * df_func_all.shape[0]].T
    df_func_all = df_func_all[~(df_func_all.T < 0.000001).all()]
    df_func_mean = pd.DataFrame(df_func_all.mean(axis=0)).T


    df = pd.concat([df_dwi_mean, df_func_mean], axis=1).astype('float32')
    df = df.reset_index(drop=True)
    df_new = pd.DataFrame(data=df.values,
                           columns=list(df.columns),
                           index=[sub])

    df_new.to_csv(f"{namer_dir}/mplx_graphs/mplx_embeddings/unmatched_multimodal_{response}.csv")
    print(f"SUCCESS! {namer_dir}/mplx_graphs/mplx_embeddings/unmatched_multimodal_{response}.csv")
    return


subs = [os.path.basename(i) for i in glob.glob(f"{working_dir}/pynets/sub*")]
Parallel(n_jobs=-1)(delayed(get_embeddings_multi)(sub, 1, working_dir, "MDE_chronic") for sub in subs)
Parallel(n_jobs=-1)(delayed(get_embeddings_multi)(sub, 1, working_dir, "MDE_conversion") for sub in subs)

## Stacking
import numpy as np
import glob
import os
import pandas as pd
from pynets.stats.prediction import bootstrapped_nested_cv, preprocess_x_y, MakeDF
from pynets.stats.utils import node_files_search


for target_var in ['MDE_conversion', 'MDE_chronic']:

    mase_mats = []
    for i in glob.glob(f"/working/TrainTest_set/outputs/pynets/*/ses-1/graphs_multilayer/mplx_graphs/mplx_embeddings/unmatched_multimodal_{target_var}.csv"):
        mase_mats.append(pd.read_csv(i).rename(columns={'Unnamed: 0': 'participant_id'}))

    # mase_mats = []
    # for i in glob.glob('/working/TrainTest_set/outputs/pynets/*/ses-1/graphs_multilayer/mplx_graphs/mplx_embeddings/gradient-MASE_graphs_multilayer_all_nodes*.csv'):
    #     mase_mats.append(pd.read_csv(i).rename(columns={'Unnamed: 0': 'participant_id'}))

    all_mats = pd.concat(mase_mats, axis=0)

    df_final = all_mats.dropna(thresh=all_mats.shape[1]*0.85,how='all',axis=1)

    df_final = df_final.dropna(thresh=len(df_final.columns)*0.20,how='all',axis=0)

    id_vec = df_final['participant_id'].values
    df_final = df_final.drop(columns='participant_id')

    df_final = df_final.apply(lambda x: np.where(np.abs(x) < 0.000001, 0, x))
    df_final = df_final.T.loc[(df_final == 0).sum() < (
        float(0.75)) * df_final.shape[0]].T
    df_final = df_final[~(df_final.T < 0.000001).all()]

    all_cols = list(set(['_'.join(i.split('_')[0:3]) for i in df_final.columns if (i.startswith('func_') or i.startswith('dwi_')) and ('Unlabeled' not in i)]))
    dfs_rois = []
    for roi in all_cols:
        dfs_rois.append(pd.DataFrame(df_final.filter(regex=roi).mean(axis=1), columns=[roi]))

    df_final = pd.concat(dfs_rois, axis=1)

    # scaler = StandardScaler()
    # df_final = pd.DataFrame(scaler.fit_transform(df_final), columns=df_final.columns)
    #
    # variance_threshold = VarianceThreshold(threshold=0.95)
    # variance_threshold.fit(df_final)

    # good_var_cols = df_final.columns[variance_threshold.get_support(indices=True)]
    # low_var_cols = [i for i in df_final.columns if i not in list(good_var_cols)]
    # if len(low_var_cols) > 0:
    #     print(f"Dropping {low_var_cols} for low variance...")
    # df_final = df_final[good_var_cols]

    df_final = df_final.reset_index(drop=True)
    df_final['participant_id'] = id_vec
    df_final.participant_id = [i.replace('sub-', '') for i in
                               df_final.participant_id.values]

    # Subset only those participants which have usable data
    df = pd.read_pickle('/working/TrainTest_set/outputs/df_depressed_TrainTest_final.pkl')
    df = df.merge(df_final, on='participant_id', how='inner')
    df.columns = [str(j) for j in df.columns]
    df = df.drop_duplicates(subset='participant_id')
    # df = df.drop(columns=['func_Unlabeled', 'dwi_Unlabeled'])

    stack_mods_list = [['func', 'dwi', 'Beh']]
    # stack_mods_list = [['func', 'dwi', 'Beh'], ['func', 'dwi'], ['dwi', 'Beh'], ['func', 'Beh']]
```

```{r stacking_comparisons, message=FALSE, warning=FALSE, fig.width = 20, fig.height=20, fig.align="center", fig.show="hide", echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
# Optimized Connectome
out_func1 <- make_modality_boot_df(df_func_chronic %>% filter(grepl('Best_Space', Phenotype)), df_func_conversion %>% filter(grepl('Best_Space', Phenotype)), func_grid_cols, Feature_Space='FUNC', x_compare=NULL, y_compare=NULL)
out_func1$Modality <- 'Unimodal'
out_dwi1  <- make_modality_boot_df(df_dwi_chronic %>% filter(grepl('Best_Space', Phenotype)), df_dwi_conversion %>% filter(grepl('Best_Space', Phenotype)), dwi_grid_cols, Feature_Space='DWI', x_compare=NULL, y_compare=NULL)
out_dwi1$Modality <- 'Unimodal'

# Behavioral
df_behavioral_chronic_scores <- df_behavioral_chronic_scores %>% dplyr::select(-ends_with(".1"))
df_behavioral_chronic_scores$Phenotype <- "chronic"
df_behavioral_chronic_scores$Modality <- 'Unimodal'
df_behavioral_conversion_scores <- df_behavioral_conversion_scores %>% dplyr::select(-ends_with(".1"))
df_behavioral_conversion_scores$Phenotype <- "conversion"
df_behavioral_conversion_scores$Modality <- 'Unimodal'
out_behavioral  <- make_modality_boot_df(df_behavioral_chronic_scores, df_behavioral_conversion_scores, func_grid_cols, Feature_Space='BEH', x_compare=NULL, y_compare=NULL, connectome=FALSE)

# Stacked Connectome
df_stacked_func_dwi_chronic_scores <- df_stacked_func_dwi_chronic_scores %>% dplyr::select(-ends_with(".1"))
df_stacked_dwi_beh_chronic_scores <- df_stacked_dwi_beh_chronic_scores %>% dplyr::select(-ends_with(".1"))
df_stacked_func_beh_chronic_scores <- df_stacked_func_beh_chronic_scores %>% dplyr::select(-ends_with(".1"))
df_stacked_func_dwi_beh_chronic_scores <- df_stacked_func_dwi_beh_chronic_scores %>% dplyr::select(-ends_with(".1"))
df_voting_func_dwi_chronic_scores <- df_voting_func_dwi_chronic_scores %>% dplyr::select(-ends_with(".1"))
df_voting_dwi_beh_chronic_scores <- df_voting_dwi_beh_chronic_scores %>% dplyr::select(-ends_with(".1"))
df_voting_func_beh_chronic_scores <- df_voting_func_beh_chronic_scores %>% dplyr::select(-ends_with(".1"))
df_voting_func_dwi_beh_chronic_scores <- df_voting_func_dwi_beh_chronic_scores %>% dplyr::select(-ends_with(".1"))

df_stacked_func_dwi_chronic_scores$Phenotype <- "chronic"
df_stacked_dwi_beh_chronic_scores$Phenotype <- "chronic"
df_stacked_func_dwi_beh_chronic_scores$Phenotype <- "chronic"
df_stacked_func_beh_chronic_scores$Phenotype <- "chronic"
df_stacked_func_dwi_chronic_scores$Modality <- "Stacking"
df_stacked_dwi_beh_chronic_scores$Modality <- "Stacking"
df_stacked_func_dwi_beh_chronic_scores$Modality <- "Stacking"
df_stacked_func_beh_chronic_scores$Modality <- "Stacking"

df_voting_dwi_beh_chronic_scores$Phenotype <- "chronic"
df_voting_func_dwi_chronic_scores$Phenotype <- "chronic"
df_voting_func_dwi_beh_chronic_scores$Phenotype <- "chronic"
df_voting_func_beh_chronic_scores$Phenotype <- "chronic"
df_voting_dwi_beh_chronic_scores$Modality <- "Voting"
df_voting_func_dwi_chronic_scores$Modality <- "Voting"
df_voting_func_dwi_beh_chronic_scores$Modality <- "Voting"
df_voting_func_beh_chronic_scores$Modality <- "Voting"

df_stacked_func_dwi_conversion_scores <- df_stacked_func_dwi_conversion_scores %>% dplyr::select(-ends_with(".1"))
df_stacked_dwi_beh_conversion_scores <- df_stacked_dwi_beh_conversion_scores %>% dplyr::select(-ends_with(".1"))
df_stacked_func_dwi_beh_conversion_scores <- df_stacked_func_dwi_beh_conversion_scores %>% dplyr::select(-ends_with(".1"))
df_stacked_func_beh_conversion_scores <- df_stacked_func_beh_conversion_scores %>% dplyr::select(-ends_with(".1"))
df_voting_dwi_beh_conversion_scores <- df_voting_dwi_beh_conversion_scores %>% dplyr::select(-ends_with(".1"))
df_voting_func_dwi_conversion_scores <- df_voting_func_dwi_conversion_scores %>% dplyr::select(-ends_with(".1"))
df_voting_func_dwi_beh_conversion_scores <- df_voting_func_dwi_beh_conversion_scores %>% dplyr::select(-ends_with(".1"))
df_voting_func_beh_conversion_scores <- df_voting_func_beh_conversion_scores %>% dplyr::select(-ends_with(".1"))
df_stacked_func_dwi_conversion_scores$Phenotype <- "Conversion"
df_stacked_dwi_beh_conversion_scores$Phenotype <- "Conversion"
df_stacked_func_dwi_beh_conversion_scores$Phenotype <- "Conversion"
df_stacked_func_beh_conversion_scores$Phenotype <- "Conversion"
df_stacked_func_dwi_conversion_scores$Modality <- "Stacking"
df_stacked_dwi_beh_conversion_scores$Modality <- "Stacking"
df_stacked_func_dwi_beh_conversion_scores$Modality <- "Stacking"
df_stacked_func_beh_conversion_scores$Modality <- "Stacking"
df_voting_dwi_beh_conversion_scores$Phenotype <- "Conversion"
df_voting_func_dwi_conversion_scores$Phenotype <- "Conversion"
df_voting_func_dwi_beh_conversion_scores$Phenotype <- "Conversion"
df_voting_func_beh_conversion_scores$Phenotype <- "Conversion"
df_voting_dwi_beh_conversion_scores$Modality <- "Voting"
df_voting_func_dwi_conversion_scores$Modality <- "Voting"
df_voting_func_dwi_beh_conversion_scores$Modality <- "Voting"
df_voting_func_beh_conversion_scores$Modality <- "Voting"

# Stacking
out_stacking_func_dwi <- make_modality_boot_df(bind_rows(df_stacked_func_dwi_chronic_scores, df_stacked_func_dwi_chronic_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), bind_rows(df_stacked_func_dwi_conversion_scores, df_stacked_func_dwi_conversion_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), func_grid_cols, Feature_Space='FUNC\nDWI', x_compare=NULL, y_compare=NULL, connectome=TRUE)

out_stacking_dwi_beh <- make_modality_boot_df(bind_rows(df_stacked_dwi_beh_chronic_scores, df_stacked_dwi_beh_chronic_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), bind_rows(df_stacked_dwi_beh_conversion_scores, df_stacked_dwi_beh_conversion_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), func_grid_cols, Feature_Space='DWI\nBEH', x_compare=NULL, y_compare=NULL, connectome=TRUE)

out_stacking_func_dwi_beh <- make_modality_boot_df(bind_rows(df_stacked_func_dwi_beh_chronic_scores, df_stacked_func_dwi_beh_chronic_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), bind_rows(df_stacked_func_dwi_beh_conversion_scores, df_stacked_func_dwi_beh_conversion_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), func_grid_cols, Feature_Space='FUNC\nDWI\nBEH', x_compare=NULL, y_compare=NULL, connectome=TRUE)

out_stacking_func_beh <- make_modality_boot_df(bind_rows(df_stacked_func_beh_chronic_scores, df_stacked_func_beh_chronic_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), bind_rows(df_stacked_func_beh_conversion_scores, df_stacked_func_beh_conversion_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), func_grid_cols, Feature_Space='FUNC\nBEH', x_compare=NULL, y_compare=NULL, connectome=TRUE)

dat_stack <- data.frame(bind_rows(out_stacking_func_dwi, out_stacking_dwi_beh, out_stacking_func_dwi_beh, out_stacking_func_beh))
dat_stack$MetaEstimator <- 'Stacking'

# Voting
out_voting_func_dwi <- make_modality_boot_df(bind_rows(df_voting_func_dwi_chronic_scores, df_voting_func_dwi_chronic_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), bind_rows(df_voting_func_dwi_conversion_scores, df_voting_func_dwi_conversion_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), func_grid_cols, Feature_Space='FUNC\nDWI', x_compare=NULL, y_compare=NULL, connectome=TRUE)

out_voting_dwi_beh <- make_modality_boot_df(bind_rows(df_voting_dwi_beh_chronic_scores, df_voting_dwi_beh_chronic_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), bind_rows(df_voting_dwi_beh_conversion_scores, df_voting_dwi_beh_conversion_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), func_grid_cols, Feature_Space='DWI\nBEH', x_compare=NULL, y_compare=NULL, connectome=TRUE)

out_voting_func_dwi_beh <- make_modality_boot_df(bind_rows(df_voting_func_dwi_beh_chronic_scores, df_voting_func_dwi_beh_chronic_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), bind_rows(df_voting_func_dwi_beh_conversion_scores, df_voting_func_dwi_beh_conversion_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), func_grid_cols, Feature_Space='FUNC\nDWI\nBEH', x_compare=NULL, y_compare=NULL, connectome=TRUE)

out_voting_func_beh <- make_modality_boot_df(bind_rows(df_voting_func_beh_chronic_scores, df_voting_func_beh_chronic_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), bind_rows(df_voting_func_beh_conversion_scores, df_voting_func_beh_conversion_scores) %>% dplyr::select(-avg_loss, -avg_bias, -avg_var), func_grid_cols, Feature_Space='FUNC\nBEH', x_compare=NULL, y_compare=NULL, connectome=TRUE)

dat_vote <- data.frame(bind_rows(out_voting_func_dwi, out_voting_dwi_beh, out_voting_func_dwi_beh, out_voting_func_beh))
dat_vote$MetaEstimator <- 'Voting'

dat_multi <- data.frame(bind_rows(out_stacking_func_dwi_beh, out_voting_func_dwi_beh))
dat_multi$Feature_Space <- 'Multimodal'

dat_uni <- data.frame(bind_rows(out_func1, out_dwi1, out_behavioral)) %>% dplyr::select(-Modality)
dat_uni$Feature_Space <- 'Unimodal'
    
dat_all <- data.frame(bind_rows(dat_uni, dat_multi, dat_vote %>% dplyr::select(-Feature_Space) %>% dplyr::rename(., Feature_Space = MetaEstimator)))

dat_multi_vs_uni <- bind_rows(dat_uni, dat_multi)

out_multi_vs_uni <- paired_compare(clean_pairs(dat_multi_vs_uni, facet='Response', subsample = 100), "\nComparing Unimodal Vs. Multimodal Models", "E", 'Response')
out_multi_vs_uni

out_stack <- paired_compare(clean_pairs(dat_stack, facet='Response', subsample = 100), "\nComparison of Stacking Combinations", "F", 'Response', conf.level=0.998)
out_stack
```

Finally, we explored the impact of "stacking" classifiers, whereby random-forest and voting meta-classifiers were trained on the predictions from each of the best-performing base classifiers identified earlier. This approach offered a brief opportunity to study the relative impact of incorporating multiple views of connectome information in tandem versus separately. The benefit of studying them in tandem for the particular kind of classification problem that we are trying to solve is that from a theoretical perspective depression's heterogeneity fundamentally warrants multiple views of data---it is unlikely that there is any unitary feature modality, except perhaps the brain, whose variance can explain homogeneities in the longitudinal trajectory of depressed individuals. Importantly, this does not mean that neuroimaging instrument can capture that variance, however. Nevertheless, combining multiple modalities of neuroimaging data, along with behavioral measures that provide real-world context to it, may help to "tame" the wide heterogeneity of depression, by providing  heterogeneous, yet complementary, information for more robust prediction. Indeed, this is what the results showed. In the case of classifying future depression, we observed that stacking multimodal attributed connectome features improved predictive performance `r oddsfactor(round(mean(dat_all %>% filter(Response=="Chronic", Feature_Space=="Unimodal") %>% pull(AUC), na.rm=TRUE), 3), round(mean(dat_all %>% filter(Response=="Chronic", Feature_Space=="Multimodal" | Feature_Space=="Voting") %>% pull(AUC), na.rm=TRUE), 3))`-fold on average over and above unimodal classification, which could be observed both when chronic depression was the response variable (paired t(`r as.integer(out_multi_vs_uni[[2]]$df)`) = `r out_multi_vs_uni[[2]]$t_stat %>% round(2)`, 95% CI [`r out_multi_vs_uni[[2]]$conf.int[1] %>% round(3)`, `r out_multi_vs_uni[[2]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_multi_vs_uni[[2]]$p, digits = 3, prefix = NULL)`) and when depression conversion was the response variable (paired t(`r as.integer(out_multi_vs_uni[[3]]$df)`) = `r out_multi_vs_uni[[3]]$t_stat %>% round(2)`, 95% CI [`r out_multi_vs_uni[[3]]$conf.int[1] %>% round(3)`, `r out_multi_vs_uni[[3]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_multi_vs_uni[[3]]$p, digits = 3, prefix = NULL)`). See plot E of Figure \ref{fig:all_comparison_freq} for a paired boxplot visualization of comparisons between unimodal and multimodal classification for each depression outcome type.

We next compared each variation of multimodal prediction, while applying a stringent Bonferroni adjusted alpha level of .0016 per test (.05/32). When classifying chronic depression, the best performance was achieved when combining all three feature modalities ($mean(AUC)$=`r round(mean(dat_stack %>% filter(Response=='Chronic', Feature_Space=="FUNC\nDWI\nBEH") %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_stack %>% filter(Response=='Chronic', Feature_Space=="FUNC\nDWI\nBEH") %>% pull(AUC), na.rm=TRUE), 3)`), followed by combining structural and behavioral ($mean(AUC)$=`r round(mean(dat_stack %>% filter(Response=='Chronic', Feature_Space=="DWI\nBEH") %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_stack %>% filter(Response=='Chronic', Feature_Space=="DWI\nBEH") %>% pull(AUC), na.rm=TRUE), 3)`), functional and behavioral ($mean(AUC)$=`r round(mean(dat_stack %>% filter(Response=='Chronic', Feature_Space=="FUNC\nBEH") %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_stack %>% filter(Response=='Chronic', Feature_Space=="FUNC\nBEH") %>% pull(AUC), na.rm=TRUE), 3)`), and functional and structural ($mean(AUC)$=`r round(mean(dat_stack %>% filter(Response=='Chronic', Feature_Space=="FUNC\nDWI") %>% pull(AUC), na.rm=TRUE), 3)` $\pm$ `r round(sd(dat_stack %>% filter(Response=='Chronic', Feature_Space=="FUNC\nDWI") %>% pull(AUC), na.rm=TRUE), 3)`). Each of the pairwise differences across conditions was statistically significant. Each of the pairwise differences across conditions was statistically significant. When classifying depression conversion, however, excluding the functional connectome modality led to significantly worse performance (DWI vs. FUNC: paired t(`r as.integer(out_stack[[4]]$df)`) = `r out_stack[[4]]$t_stat %>% round(2)`, 95% CI [`r out_stack[[4]]$conf.int[1] %>% round(3)`, `r out_stack[[4]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_stack[[4]]$p, digits = 3, prefix = NULL)`), such that the difference in performance when using other combinations of stacked features (whereby functional connectomes were included) resulted in negligible gains in performance. See plot F of Figure \ref{fig:all_comparison_freq} for a paired boxplot visualization of comparisons across stacking combinations for each depression outcome type.

```{r all_comparisons_freq, fig.width = 8, fig.height=9, fig.align="center", message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
grid.newpage()
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
plt1 <- do.call(grid.arrange, list(grobs=list(out_connectome_vs_sim[[1]]), vp=viewport(height=1, width=1), nrow=1, ncol=1, top = grobTree(rectGrob(gp=gpar(fill="black", color = "black", size = 0.2)), textGrob("(A) Frequentist Paired Comparisons of Randomly-Attributed Connectome Feature-Spaces\n", gp=gpar(fontsize=16, col="white", fontface="bold")))))
grid.draw(plt1)
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
grid.draw(plt1)
plt1

grid.newpage()
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
plt2 <- do.call(grid.arrange, list(grobs=list(out_rum_vs_dep_func[[1]], out_severity_vs_persistence[[1]]), vp=viewport(height=1, width=1), nrow=2, ncol=1, top = grobTree(rectGrob(gp=gpar(fill="black", color = "black", size = 0.2)), textGrob("(B) Frequentist Paired Comparisons of Phenotype-Attributed Connectome Feature-Spaces\n", gp=gpar(fontsize=16, col="white", fontface="bold")))))
grid.draw(plt2)
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
grid.draw(plt2)
plt2

grid.newpage()
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
plt3 <- do.call(grid.arrange, list(grobs=list(out_multi_vs_uni[[1]], out_stack[[1]]), vp=viewport(height=1, width=1), nrow=2, ncol=1, top = grobTree(rectGrob(gp=gpar(fill="black", color = "black", size = 0.2)), textGrob("(C) Frequentist Paired Comparisons of Multiply-Attributed Connectome Feature-Spaces\n", gp=gpar(fontsize=16, col="white", fontface="bold")))))
grid.draw(plt3)
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
grid.draw(plt3)
plt3
```

::: {.center data-latex=""}
\begin{figure}
    \centering
    \caption{(Target Domain) \label{fig:all_comparison_freq}\scriptsize{The three figure mosaics presented over the subsequent three pages depict paired comparisons between bootstrapped classifiers, faceted for the two definitions of future depression outcome (chronic and conversion), estimated independently using an AutoML logistic regression framework. Comparing classifiers trained on different connectome feature attributions provided a means of directly evaluating both the quality of the Transfer Learning (TL), and indirectly evaluating each of several key assumptions relevant to the etiology of depression maintenance itself. Across all classifiers investigated, the mean ROC AUC was 0.699 $\pm$ 0.078 with a range of [[0.423, 0.926]]. For each separate plot panel in the mosaic, the x-axis represents discrete latent factors corresponding to one or more connectome attribution schemes of interest learned in the source domain. Each of level of these latent factors (indicated by discrete colors of the point jitter) were determined predictively using the unbiased Gini cutpoints of the decision-tree model trained on multiplicatively-attributed connectomes in the source domain. Each point instance further corresponds to a single bootstrapped resampling of train-test splits performed on the held-out data in the target domain, and used to cross-validate orthogonal classifiers. The y-axis represents classifier performance estimates of these classifiers (in units of ROC AUC) trained on the resampled connectome embedding data. The feathered white lines connecting the points across paired boxplots represent precise bootstrap iteration assignments. Although the two definitions of depression outcome are depicted side-by-side for conceptual reference and brevity, their separation across grey subpanels is intentional and reflect the incomparability of paired AUC performance across each outcome type given that predictions of depression conversion risk involved a healthy class of subjects.}}
\end{figure}
\begin{figure}
    \ContinuedFloat
    \centering
    \begin{subfigure}{\textwidth}
        \caption{\label{fig:pheno_vs_random}\scriptsize{Effect of knowledge-based connectome transfer learning versus random transfer}}
          \includegraphics[width=\textwidth,keepaspectratio=true]{../figures/pheno_vs_random-1.pdf}
    \end{subfigure}
\end{figure}
\begin{figure}
    \ContinuedFloat
    \centering
    \begin{subfigure}{\textwidth}
        \caption{\label{fig:all_comparison_freqA}\scriptsize{Effect of biologically real versus synthetic connectome transfer learning}}
          \includegraphics[width=\textwidth,keepaspectratio=true]{../figures/all_comparisons_freq-2.pdf}
    \end{subfigure}
\end{figure}
\begin{figure}
    \ContinuedFloat
    \centering
    \begin{subfigure}{\textwidth}
       \caption{\label{fig:all_comparison_freqB}\scriptsize{Effect of domain-relevant knowledge-based connectome transfer learning}}
        \includegraphics[width=\textwidth,keepaspectratio=true]{../figures/all_comparisons_freq-4.pdf}
    \end{subfigure}
\end{figure}
\begin{figure}
    \ContinuedFloat
    \centering
    \begin{subfigure}{\textwidth}
       \caption{\label{fig:all_comparison_freqC}\scriptsize{Effect of multimodal connectome transfer learning}}
        \includegraphics[width=\textwidth,keepaspectratio=true]{../figures/all_comparisons_freq-6.pdf}
    \end{subfigure}
\end{figure}
\setlength{\belowcaptionskip}{-10pt}
:::

```{python eval=FALSE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
import pandas as pd
import seaborn as sns
from pynets.core.utils import flatten
import os
import ast
import json
import glob
import re
import numpy as np
from collections import Counter
from itertools import groupby
from pathlib import Path
import mplcyberpunk
from pynets.core.utils import load_runconfig
import random
import matplotlib
from matplotlib import pyplot as plt
from nilearn import plotting as niplot
import pkg_resources
from pynets.plotting.plot_gen import create_gb_palette
import nibabel as nib
from matplotlib import colors
from scipy.spatial import distance
from sklearn.preprocessing import StandardScaler
import itertools
from pynets.core.thresholding import normalize
import networkx as nx
from PIL import Image, ImageFont, ImageDraw
from pynets.stats.utils import cleanNullTerms
from pynets.plotting import plot_graphs
import pandas as pd
from pynets.stats.prediction import bootstrapped_nested_cv, preprocess_x_y, MakeDF
from graspologic.embed import AdjacencySpectralEmbed
from pynets.core import thresholding
from graspologic.match import GraphMatch as GMP
from hyppo.ksample import KSample
from graspologic.embed import ClassicalMDS
from graspologic.plot import heatmap
import warnings
from graspologic.embed import OmnibusEmbed
from graspologic.plot import pairplot

plt.style.use("cyberpunk")

ch2better_loc = pkg_resources.resource_filename(
    "pynets", "templates/ch2better.nii.gz"
)

working = f"/home/dpys/Documents/iccs_all/pruned_atlases"

figures_dir = f"/home/dpys/Documents/Dissertation/../figures"

results_dir = f"/home/dpys/Documents/Dissertation/Chapter_IV/results"

try:
    nib.load(ch2better_loc)
except ImportError as e:
    print(e, f"\nCannot load plotting template. Do you have git-lfs "
             f"installed?")

hardcoded_params = load_runconfig()

try:
    color_theme = random.choice(
        [
            "Purples_d",
            "Blues_d",
            "Greens_d",
            "Oranges_d",
            "Reds_d",
            "YlOrBr_d",
            "YlOrRd_d",
            "OrRd_d",
            "PuRd_d",
            "RdPu_d",
            "BuPu_d",
            "GnBu_d",
            "PuBu_d",
            "YlGnBu_d",
            "PuBuGn_d",
            "BuGn_d",
            "YlGn_d",
        ]
    )

    connectogram = hardcoded_params["plotting"]["connectogram"][0]
    glassbrain = hardcoded_params["plotting"]["glassbrain"][0]
    adjacency = hardcoded_params["plotting"]["adjacency"][0]
    dpi_resolution = hardcoded_params["plotting"]["dpi"][0]
    labeling_atlas = hardcoded_params["plotting"]["labeling_atlas"][0]
except KeyError as e:
    print(e,
          "Plotting configuration not successfully extracted "
          "from runconfig.yaml"
          )

res_map = {'200': '77', '400': '135', '600': '180', '800': '228'}


def plot_conn_mat(conn_matrix, labels, out_path_fig, cmap, binarized=False,
                  dpi_resolution=300):
    """
    Plot a connectivity matrix.

    Parameters
    ----------
    conn_matrix : array
        NxN matrix.
    labels : list
        List of string labels corresponding to ROI nodes.
    out_path_fig : str
        File path to save the connectivity matrix image as a .png figure.
    """
    import warnings
    warnings.filterwarnings("ignore")
    import matplotlib
    matplotlib.use('Agg')
    import mplcyberpunk
    from matplotlib import pyplot as plt
    plt.style.use("cyberpunk")
    from matplotlib import pyplot as plt
    from nilearn.plotting import plot_matrix
    from pynets.core import thresholding
    import matplotlib.ticker as mticker

    conn_matrix_bin = thresholding.binarize(conn_matrix)
    conn_matrix_plt = np.nan_to_num(np.multiply(conn_matrix, conn_matrix_bin))

    try:
        plot_matrix(
            conn_matrix_plt,
            figure=(10, 10),
            labels=labels,
            vmax=np.max(conn_matrix_plt) + 0.01,
            vmin=np.min(conn_matrix_plt) - 0.01,
            reorder="average",
            auto_fit=True,
            grid=False,
            colorbar=True,
            cmap=cmap,
        )
    except RuntimeWarning:
        print("Connectivity matrix too sparse for plotting...")

    if len(labels) > 500:
        tick_interval = 5
    elif len(labels) > 100:
        tick_interval = 4
    elif len(labels) > 50:
        tick_interval = 2
    else:
        tick_interval = 1

    plt.axes().yaxis.set_major_locator(mticker.MultipleLocator(tick_interval))
    plt.axes().xaxis.set_major_locator(mticker.MultipleLocator(tick_interval))
    for param in ['figure.facecolor', 'axes.facecolor', 'savefig.facecolor']:
        plt.rcParams[param] = '#000000'
    mplcyberpunk.add_glow_effects()
    plt.savefig(out_path_fig, dpi=dpi_resolution)
    plt.close()
    return


def conform_tup_order(g):
    idx=[4,0,1,2,3,5]
    a = np.array(ast.literal_eval(g))
    return tuple(a[idx])
    
## Prepare lps dataframes
source_file_path = '/home/dpys/Documents/Dissertation/Chapter_IV'
    
def preparare_grid_dfs(fname, source_file_path, metaparams):
    if not os.path.isfile(f"{source_file_path}/{fname}.csv"):
        raise FileNotFoundError(f"File {source_file_path}/{fname}.csv not found!")
    frame = pd.read_csv(f"{source_file_path}/{fname}.csv", index_col=False)
    if "Unnamed: 0" in frame.columns:
        frame.drop(frame.filter(regex="Unnamed: 0"), axis=1, inplace=True)
    df_grid = frame.dropna(axis=1, how='all')
    df_grid['grid'] = df_grid['grid'].str.replace('77', '200')
    df_grid['grid'] = df_grid['grid'].str.replace('135', '400')
    df_grid['grid'] = df_grid['grid'].str.replace('180', '600')
    df_grid['grid'] = df_grid['grid'].str.replace('228', '800')
    df_grid = df_grid[['grid', 'lp_importance', 'Score', 'Error']]
    
    df_scores = df_grid.T
    df_scores.columns = df_scores.iloc[0]
    
    df_scores = pd.DataFrame(df_scores.iloc[2]).T
    df_scores_new = pd.DataFrame(columns=df_scores.columns)
    for col in df_scores.columns:
        df_scores_new[col] = pd.Series(ast.literal_eval(df_scores[col].values.tolist()[0]))
        
        
    frame = pd.DataFrame(df_grid[['grid', 'lp_importance']])

    frame['Scores'] = df_scores_new.T.mean(axis=1).values
    
    try:
        frame[metaparams] = pd.DataFrame([eval(i) for i in frame['grid'].tolist()], index=frame.index)
    except:
        frame[metaparams[1:]] = pd.DataFrame([eval(i) for i in frame['grid'].tolist()], index=frame.index)
    frame['grid'] = frame['grid'].apply(conform_tup_order)
    frame.to_csv(f"{source_file_path}/{fname}_lps.csv", index=False)
    print(f"Final File: {source_file_path}/{fname}_lps.csv")
    return

func_files = ['final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid',
'final_predictions_modality-func_rsn-inter_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid']

dwi_files = ['final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_chronic_boots-1000_search-grid',
'final_predictions_modality-dwi_rsn-inter_language_gradient-ASE_outcome-MDE_conversion_boots-1000_search-grid']

for file_ in func_files:
    preparare_grid_dfs(file_, f"{source_file_path}/data/TrainTest_set", ['extract', 'hpass', 'model', 'res', 'network', 'smooth'])
    
for file_ in dwi_files:
    preparare_grid_dfs(file_, f"{source_file_path}/data/TrainTest_set", ['directget', 'minlength', 'model', 'res', 'network', 'tol']) 


def replace_lps_with_int(x):
    clean_list = ast.literal_eval(re.sub(' +', ' ', str(x).lstrip().replace('\n', '')).replace('[ ', '[').replace(' ]', ']').replace(' ', ', '))

    if 'rsn-' in str(x):
        return [i.split('_')[1] for i in clean_list]
    else:
        return clean_list
              
def make_lp_dict(df, modality, master_dict, rsn, subdivision, res):
    if rsn not in master_dict.keys():
        master_dict[rsn] = {}
    if subdivision not in master_dict[rsn].keys():
        master_dict[rsn][subdivision] = {}
    if res not in master_dict[rsn][subdivision].keys():
        master_dict[rsn][subdivision][res] = {}
    if subdivision == 'TN_intersection':
        rsn_abbr = 'kmeans'
    elif subdivision == 'LN_dorsal':
        rsn_abbr = 'language'

    lps = dict(sorted(dict(Counter(list(flatten([list([int(j) for j in i]) for i in list(df.loc[(df.network == rsn_abbr) & (df.res == str(res))]['lp_importance'].values)])))).items(), key=lambda item: item[1], reverse=True))
    for lp in list(lps.keys()):
        master_dict[rsn][subdivision][res][lp] = {}
        master_dict[rsn][subdivision][res][lp]['occurrence'] = lps[lp]
        master_dict[rsn][subdivision][res][lp]['score'] = np.nanmean(np.array(df.loc[(df['network']==rsn_abbr) & (df['res'].astype('str')==str(res)) & (df['lp_importance'].apply(str).str.contains(str(lp)))]['Scores'].values))
    return master_dict


def load_best_lps(results_file):
    if not os.path.isfile(results_file):
        raise FileNotFoundError(f"File {results_file} not found!")
    else:
        df = pd.read_csv(results_file)
        df.res = df.res.astype('str')
        df['res'] = df['res'].str.replace('77', '200')
        df['res'] = df['res'].str.replace('135', '400')
        df['res'] = df['res'].str.replace('180', '600')
        df['res'] = df['res'].str.replace('228', '800')
        df['network'] = df['network'].str.replace('inter', 'kmeans')
        df['lp_importance'] = df['lp_importance'].apply(lambda x: replace_lps_with_int(x))
        
        master_dict = {}
        if modality == 'func':
            master_dict = make_lp_dict(df, modality, master_dict, 'kmeans', 'TN_intersection', '600')
        else:
            master_dict = make_lp_dict(df, modality, master_dict, 'language', 'LN_dorsal', '400')
    return master_dict, df


def make_node_dict_from_parcellation(parcellation, vox_size='2mm'):
    from pynets.core.nodemaker import get_names_and_coords_of_parcels, \
        parcel_naming
    from pynets.core.utils import save_coords_and_labels_to_json
    dir_path = str(Path(parcellation).parent)
    coords, _, _, label_intensities = get_names_and_coords_of_parcels(parcellation)
    labels = parcel_naming(coords, vox_size)
    node_file = save_coords_and_labels_to_json(coords, labels, dir_path, network='all_nodes', indices=label_intensities)
    return node_file
    

def CountFrequency(my_list): 
    freq = {} 
    for item in my_list: 
        if (item in freq): 
            freq[item] += 1
        else: 
            freq[item] = 1
    return freq
    
    
def grab_coords_labels(node_file):
    with open(node_file, 'r+') as f:
        node_dict = json.load(f)
    indices = [i['index'] for i in
               node_dict]
    coords = [i['coord'] for i in
              node_dict]
    if isinstance(node_dict[0]['label'], str):
        labels = [
            ast.literal_eval(
                re.search('({.+})',
                          i['label']).group(0))[
                'BrainnetomeAtlasFan2016'] for i in
            node_dict]
    else:
        labels = [
            list(i['label'])[0][
                'BrainnetomeAtlasFan2016'] for i in
            node_dict]
    return indices, coords, labels


def drop_badixs_from_parcellation(uatlas, bad_idxs):
    import os
    import nibabel as nib
    import numpy as np
    from nipype.utils.filemanip import fname_presuffix
    from pynets.core.nodemaker import enforce_hem_distinct_consecutive_labels

    parcellation_img = nib.load(uatlas)

    bad_idxs = sorted(list(set(bad_idxs)), reverse=True)

    parlist_img_data = parcellation_img.get_fdata()
    for val in bad_idxs:
        print(f"Removing: {str(val)}...")
        parlist_img_data[np.where(parlist_img_data == val)] = 0

    parcellation = fname_presuffix(
        uatlas, suffix="_pruned_predict",
        newpath=os.path.dirname(uatlas))
    nib.save(
        nib.Nifti1Image(parlist_img_data,
                        affine=parcellation_img.affine),
        parcellation)

    print(f"{len(np.unique(parlist_img_data))} parcels remaining")
    parcellation = enforce_hem_distinct_consecutive_labels(parcellation)[0]
    return parcellation
    
phenotypes = ['MDE_chronic', 'MDE_conversion']

vip_connectomes = {}
dfs_vip = []
parcellation_dict = {}
views = ["x", "z"]
for modality in ['dwi', 'func']:
    vip_connectomes[modality] = {}
    source_dir_path = f"{source_file_path}/data/TrainTest_set"
    for pheno in phenotypes:
        vip_connectomes[modality][pheno] = {}
        if modality == 'func':
            embed = 'ASE'
        else:
            embed = 'ASE'
        filename = glob.glob(f"{source_dir_path}/final_predictions_modality-{modality}_rsn-*_gradient-{embed}_outcome-{pheno}_boots-1000_search-grid_lps.csv")[0]
        if os.path.isfile(filename):
            master_dict, df = load_best_lps(filename)
            for rsn in ['kmeans', 'language']:
                if rsn in master_dict.keys():
                    for subdivision in ['LN_dorsal', 'TN_intersection']:
                        if subdivision in master_dict[rsn].keys():
                            for res in ['200', '400', '600', '800']:
                                vip_connectomes[modality][pheno][res] = {}
                                if res in master_dict[rsn][subdivision].keys():
                                    if subdivision == 'TN_intersection':
                                        rsn_abbr = 'kmeans'
                                        col_map = 'Purples_d'
                                    elif subdivision == 'LN_dorsal':
                                        rsn_abbr = 'language'
                                        col_map = 'Oranges_d'

                                    parcellation = f"{working}/rsn-{rsn_abbr}_res-{res_map[res]}_pruned_predict.nii.gz"
                                                                   
                                    if rsn_abbr not in parcellation_dict.keys():
                                        parcellation_dict[rsn_abbr] = {}
                                    if res not in parcellation_dict[rsn_abbr].keys():
                                        parcellation_dict[rsn_abbr][res] = {}
                                        parcellation_dict[rsn_abbr][res]['bad_indices'] = []
                                        parcellation_dict[rsn_abbr][res]['parcellation'] = parcellation
                                        
                                    node_file = make_node_dict_from_parcellation(parcellation, vox_size='2mm')
                                    
                                    [indices, coords, labels] = grab_coords_labels(node_file)
            
                                    lp_ixs = [str(i) for i in list(master_dict[rsn][subdivision][res].keys()) if str(i) in indices]
                                    good_idxs = [j for j, x in enumerate([True if i in lp_ixs else False for i in indices]) if x]
                                    indices_lps = [indices[i] for i in good_idxs]
                                    coords_lps = [coords[i] for i in good_idxs]
                                    labels_lps = [labels[i] for i in good_idxs]
                                    # labels_lps_corrected = []
                                    # for i in labels_lps:
                                    #     if i != 'Unlabeled' and ('_L' in i):
                                    #         labels_lps_corrected.append(f"{i.split('_')[0]}_{i.split('_')[1]}".replace("_L", "_R"))
                                    #     elif i != 'Unlabeled' and ('_R' in i):
                                    #         labels_lps_corrected.append(f"{i.split('_')[0]}_{i.split('_')[1]}".replace("_R", "_L"))
                                    #     else:
                                    #         labels_lps_corrected.append('Unlabeled')
                                    # labels_lps = labels_lps_corrected
                                    vips = [master_dict[rsn][subdivision][res][int(i)]['score'] for i in indices_lps]
                                    occurrences = [master_dict[rsn][subdivision][res][int(i)]['occurrence'] for i in indices_lps]
                                    
                                    dist = np.array(vips)*np.array(occurrences)
                                    bad_ixs = list(flatten([np.where(dist==x)[0].tolist() for x in dist[np.where(dist<np.percentile(dist, 25))]])) 
                                    parcellation_dict[rsn_abbr][res]['bad_indices'].extend(bad_ixs)
                                    
                                    # Create feature-importance "graph"
                                    df_case = df.loc[(df['network']==rsn_abbr) & (df['res'].astype('str')==str(res))]['lp_importance']
                                    
                                    # Create dataframe to house weighted vips
                                    lp_labels_long = [f"{i}_{l}" for i, l in list(zip(lp_ixs, labels_lps))]
                                    best_lps_dict = dict(sorted(dict(zip(lp_labels_long, dist.tolist())).items(), key=lambda item: item[1], reverse=True))
                                    df_vips = pd.DataFrame({'Best_regions': []})
                                    df_vips['Best_regions'] = df_vips['Best_regions'].astype('object')
                                    df_vips.at[1, 'Best_regions'] = sorted(dict(Counter(['_'.join(i.split('_')[1:]) for i in best_lps_dict.keys() if best_lps_dict[i]>1 and i != 'Unlabeled'])), reverse=True)
                                    df_vips['network'] = rsn_abbr
                                    df_vips['res'] = res
                                    df_vips['modality'] = modality
                                    df_vips['phenotype'] = pheno
                                    
                                    if modality == 'dwi':
                                        df_attr = df.loc[(df.network== 'language') & (df.res== res)][['directget', 'minlength', 'model', 'tol', 'Scores']]
                                        df_attr = df_attr.reset_index(drop=True)
                                        df_attr['directget'] = df_attr.directget.str.replace('det', 'Deterministic').replace('prob', 'Probabilistic')
                                        df_attr['model'] = df_attr.model.str.replace('sfm', 'Sparse Directionality').replace('csa', 'Peak Directionality')
                                        df_attr['minlength'] = df_attr.minlength.replace(0, 'Short fibers').replace(10, 'Medium Fibers').replace(30, 'Long Fibers')
                                        df_attr['tol'] = df_attr.tol.replace(5, 'Conservative Node-Edge interface').replace(10, 'Liberal Node-Edge Interface')
                                        df_attr = df_attr.iloc[df_attr.Scores.idxmax()].drop('Scores')
                                        
                                    elif modality == 'func':
                                        df_attr = df.loc[(df.network== 'kmeans') & (df.res == res)][['extract', 'hpass', 'model', 'smooth', 'Scores']]
                                        df_attr = df_attr.reset_index(drop=True)
                                        df_attr['extract'] = df_attr.extract.str.replace('mean', 'Average Activation').replace('median', 'Idle Activation').replace('maximum', 'Peak Activation').replace('mode', 'Reactivation Frequency').replace('sum', 'Cumulative Activation')
                                        df_attr['model'] = df_attr.model.str.replace('cov', 'Direct and Indirect Connections (Sparse)').replace('partcorr', 'Direct and Indirect Connections (Normalized)').replace('corr', 'Direct Connections Only')
                                        df_attr['hpass'] = df_attr.hpass.replace(0, 'All Intrinsic Frequencies').replace(0.028, 'Intrinsic Frequencies >0.028 Hz').replace(0.08, 'Intrinsic Frequencies >0.08 Hz')
                                        df_attr['smooth'] = df_attr.smooth.replace(0, 'Conservative Node-Edge interface').replace(3, 'Tolerant Node-Edge Interface').replace(6, 'Liberal Node-Edge Interface')
                                        df_attr = df_attr.iloc[df_attr.Scores.idxmax()].drop('Scores')
                                    
                                    df_vips = pd.concat([df_vips, pd.DataFrame({'Best_attributes': []})])
                                    df_vips['Best_attributes'][1] = df_attr.values.tolist()    
                                    dfs_vip.append(df_vips)
                                    
                                    G = nx.Graph(directed=False)
                                    G.add_nodes_from(lp_ixs)
                                    edge_combos = list(itertools.combinations(lp_ixs, 2))
                                    b = []
                                    seen = set()
                                    for t in edge_combos:
                                        s = tuple(sorted(t))
                                        if s not in seen:
                                            seen.add(s)
                                            b.append(t)
              
                                    for source, target in b:
                                        G.add_edge(source, target)
                                        co_occur = 0
                                        for feat_space in list(df_case.values):
                                            if source in feat_space and target in feat_space:
                                                co_occur += 1
                                        G[source][target]["weight"] = co_occur
                                    in_mat = nx.to_numpy_array(G)
                                    if modality == 'dwi':
                                        edge_cmap = 'binary'
                                    else:
                                        edge_cmap = 'Greens'
                                        
                                    in_mat = normalize(in_mat)
                                    
                                    vip_connectomes[modality][pheno][res][rsn_abbr] = {}
                                    vip_connectomes[modality][pheno][res][rsn_abbr]['labels'] = labels_lps
                                    vip_connectomes[modality][pheno][res][rsn_abbr]['coords'] = coords_lps
                                    vip_connectomes[modality][pheno][res][rsn_abbr]['ixs'] = indices_lps
                                    vip_connectomes[modality][pheno][res][rsn_abbr]['mat'] = in_mat
                                    vip_connectomes[modality][pheno][res][rsn_abbr]['vip'] = vips
                                    
                                    clust_pal = sns.color_palette(col_map, n_colors=len(occurrences))
                                    clust_pal_nodes = colors.to_rgba_array(clust_pal)
                                    
                                    connectome = niplot.plot_connectome(
                                        np.zeros(shape=(1, 1)), [(0, 0, 0)], node_size=0.0001,
                                        black_bg=True, display_mode=''.join(views), annotate=False
                                    )
                                    connectome.add_overlay(ch2better_loc, alpha=0.45, cmap=plt.cm.gray)
                        
                                    [
                                        conn_matrix,
                                        clust_pal_edges,
                                        _,
                                        node_sizes,
                                        edge_sizes,
                                        _,
                                        z_max,
                                        coords_lps,
                                        labels_lps,
                                    ] = create_gb_palette(in_mat, edge_cmap,
                                                          coords_lps, labels_lps,
                                                          prune=False,
                                                          centrality_type=vips,
                                                          max_node_size=60,
                                                          max_edge_size=3)
            
                                    scaler = StandardScaler()
                                    occurrences_scaled = scaler.fit_transform(np.array([float(i) for i in occurrences]).reshape(-1, 1))
            
                                    clust_pal_nodes = np.vstack([x for _, x in sorted(zip(list(occurrences_scaled[None,:]), list(clust_pal_nodes[None,:])))])
            
            
                                    if modality == 'dwi':
                                        edge_alpha = 0.20
                                        z_min = min(in_mat[in_mat>0.01])
                                        edge_thr = "20%"
                                        annote_color = 'purple'
                                        clust_pal_edges = plt.get_cmap('gray_r')
                                        edge_kwargs = {"alpha": 0.25, 'zorder': 1}
                                    else:
                                        edge_alpha = 0.50
                                        z_min = min(in_mat[in_mat>0.01])
                                        edge_thr = "20%"
                                        annote_color = 'orange'
                                        edge_kwargs = {"alpha": edge_alpha, 'zorder': 1}
                                        
                                    connectome.add_graph(
                                        in_mat,
                                        coords_lps,
                                        edge_threshold=edge_thr,
                                        edge_cmap=clust_pal_edges,
                                        edge_vmax=float(z_max),
                                        edge_vmin=float(z_min),
                                        node_size=node_sizes,
                                        node_color=clust_pal_nodes,
                                        edge_kwargs=edge_kwargs,
                                        node_kwargs={'zorder': 1000}
                                    )
                                    
                                    if modality == 'dwi':
                                        for view in views:
                                            mod_lines = []
                                            for line, edge_size in list(
                                                zip(connectome.axes[view].ax.lines, edge_sizes)
                                            ):
                                                line.set_lw(edge_size*0.1)
                                                mod_lines.append(line)
                                            connectome.axes[view].ax.lines = mod_lines
                                            mplcyberpunk.make_lines_glow(connectome.axes[view].ax,
                                                                         n_glow_lines=10, diff_linewidth=0.15,
                                                                         alpha_line=0.25)
                                    else:
                                        for view in views:
                                            mod_lines = []
                                            for line, edge_size in list(
                                                zip(connectome.axes[view].ax.lines, edge_sizes)
                                            ):
                                                line.set_lw(edge_size*0.35)
                                                mod_lines.append(line)
                                            connectome.axes[view].ax.lines = mod_lines
                                         
                                    zorder = 10000
                                    for view in views:
                                        coord_anns = []
                                        for coord, label in list(zip(coords_lps, labels_lps)):
                                            if view == 'x':
                                                coord_ann = (coord[1], coord[2])
                                            if view == 'y':
                                                coord_ann = (coord[0], coord[2])
                                            if view == 'z':
                                                coord_ann = (coord[0], coord[1])
                            
                                            if len(coord_anns) > 0:
                                                dists = []
                                                for c in coord_anns:
                                                    dists.append(distance.euclidean(coord_ann, c))
                                                if any([i < 15 for i in dists]):
                                                    continue
                                            if label == 'Unlabeled':
                                                continue
                                            coord_anns.append(coord_ann)
                                            connectome.axes[view].ax.set_axisbelow(False)
                                            connectome.axes[view].ax.annotate(label,
                                                                              coord_ann,
                                                                              xycoords='data',
                                                                              textcoords='offset points',
                                                                              xytext=(-0.0001, -0.0001),
                                                                              horizontalalignment='center',
                                                                              verticalalignment='top',
                                                                              fontsize='3',
                                                                              fontweight='extra bold',
                                                                              zorder=zorder,
                                                                              color='black')
                                            zorder += 10
                            
                                            connectome.axes[view].ax.annotate(label,
                                                                              coord_ann,
                                                                              xycoords='data',
                                                                              textcoords='offset points',
                                                                              xytext=(0, 0),
                                                                              horizontalalignment='center',
                                                                              verticalalignment='top',
                                                                              fontsize='3',
                                                                              fontweight='bold',
                                                                              zorder=zorder,
                                                                              color=annote_color)
                                            zorder += 100
                                    out_path_fig_conn = f"/tmp/{rsn}_{res}_{subdivision}_{modality}_{pheno}_vip_connectome_TrainTest.png"
                                    connectome.savefig(out_path_fig_conn, dpi=600)

with open(f"{results_dir}/vip_connectomes.pkl", 'wb') as handle:
    pickle.dump(vip_connectomes, handle, protocol=pickle.HIGHEST_PROTOCOL)
    
df_vip_final = pd.concat(dfs_vip)
def f(x):    
   return [y for y in x if 'Unlabeled' not in y]
   
df_vip_final['Best_regions'] = df_vip_final['Best_regions'].apply(f)
df_vip_final['network'] = df_vip_final.network.str.replace('kmeans', 'TN_intersection').replace('language', 'LN_dorsal')

df_vip_final.to_csv(f"{results_dir}/all_phenotype_weighted_vips_regions.csv", index=False)

image_dict = {}
for modality in ['func', 'dwi']:
    if modality == 'func':
        best_nets = [{'MDE_chronic': ('TN_intersection', '600')}, {'MDE_conversion': ('TN_intersection', '600')}]
    if modality == 'dwi':
        best_nets = [{'MDE_chronic': ('LN_dorsal', '400')}, {'MDE_conversion': ('LN_dorsal', '400')}]
      
    if modality not in image_dict.keys():
        image_dict[modality] = {}
    for pheno in phenotypes:
        out = [i[pheno] for i in best_nets if pheno == list(i.keys())[0]][0]
        best_rsn = out[0]
        best_res = out[1]
        if pheno not in image_dict[modality].keys():
            image_dict[modality][pheno] = {}
        for rsn in ['kmeans', 'language']:
            if rsn not in image_dict[modality][pheno].keys():
                image_dict[modality][pheno][rsn] = {}
            for subdivision in ['TN_intersection', 'LN_dorsal']:
                if subdivision not in image_dict[modality][pheno][rsn].keys():
                    image_dict[modality][pheno][rsn][subdivision] = {}
                for res in ['200', '400', '600', '800']:
                    if subdivision not in image_dict[modality][pheno][rsn][subdivision].keys():
                        image_dict[modality][pheno][rsn][subdivision][res] = {}
                    in_file = f"/tmp/{rsn}_{res}_{subdivision}_{modality}_{pheno}_vip_connectome_TrainTest.png"
                    if not os.path.isfile(in_file):
                        continue
                    else:
                        if subdivision == 'dorsal':
                            net = 'language'
                        else:
                            net = subdivision
                        if net == best_rsn and res == best_res:
                            image_dict[modality][pheno][rsn][subdivision][res] = in_file

image_dict = cleanNullTerms(image_dict)

pheno_map = {'MDE_conversion': 'Depression Conversion', 'MDE_chronic': 'Chronic Depression'}

res_map_viz = {'400': '400-Node Granularity, Whole-Network influence', '600': '600-Node Granularity, Whole-Network influence'}

def get_concat_h(im1, im2):
    dst = Image.new('RGB', (im1.width + im2.width, im1.height))
    dst.paste(im1, (0, 0))
    dst.paste(im2, (im1.width, 0))
    return dst

def get_concat_v(im1, im2):
    dst = Image.new('RGB', (im1.width, im1.height + im2.height))
    dst.paste(im1, (0, 0))
    dst.paste(im2, (0, im1.height))
    return dst
    
def add_margin(pil_img, top, right, bottom, left, color):
    width, height = pil_img.size
    new_width = width + right + left
    new_height = height + top + bottom
    result = Image.new(pil_img.mode, (new_width, new_height), color)
    result.paste(pil_img, (left, top))
    return result

final_imgs = {}
font_path = "/home/dpys/Desktop/misc/LIWC2015-app-1.3.1/org/apache/pdfbox/resources/ttf/Arial-BoldMT.ttf"
nl = '\n'
fnt_main = ImageFont.truetype(font_path, 72)
fnt_sub = ImageFont.truetype(font_path, 48)
for modality in ['func', 'dwi']:
    conversion_pheno_images = []
    chronic_pheno_images = []
    for pheno in phenotypes:
        rsn = list(image_dict[modality][pheno].keys())[0]
        subdivision = list(image_dict[modality][pheno][rsn].keys())[0]
        res = list(image_dict[modality][pheno][rsn][subdivision].keys())[0]
        img = Image.open(image_dict[modality][pheno][rsn][subdivision][res])
        draw = ImageDraw.Draw(img)
        draw.text((img.getbbox()[3]/2-100, 0), f"{pheno_map[pheno]}",(255,255,255),font=fnt_main, align='left')
        attrs = df_vip_final.loc[(df_vip_final.modality == modality) & (df_vip_final.phenotype == pheno)]['Best_attributes'].values[0]
        draw.text((img.getbbox()[3]/2-700, img.getbbox()[3]-200), f"Attributes:{nl}{res_map_viz[res]}, {nl.join([', '.join(attrs[0:1]), ', '.join(attrs[2:5])])}", (192, 192, 192),font=fnt_sub, align='left')
        img = add_margin(img, 15, 5, 15, 5, (0,0,0))
        if 'conversion' in pheno:
          conversion_pheno_images.append(img)
        if 'chronic' in pheno:
          chronic_pheno_images.append(img)    
    
    v_concatted_conversion = conversion_pheno_images[0]
    i = 1
    for h in range(len(conversion_pheno_images) - 1):
        v_concatted_conversion = get_concat_v(v_concatted_conversion, conversion_pheno_images[i])
        i += 1
    
    v_concatted_chronic = chronic_pheno_images[0]
    i = 1
    for h in range(len(chronic_pheno_images) - 1):
        v_concatted_chronic = get_concat_v(v_concatted_chronic, chronic_pheno_images[i])
        i += 1
    
    final_concat = add_margin(get_concat_h(v_concatted_conversion, v_concatted_chronic), 200, 0, 10, 0, (0,0,0))
    draw = ImageDraw.Draw(final_concat)
    if modality == 'func':
        mod = 'Functional'
    else:
        mod = 'Structural'
    draw.text((final_concat.getbbox()[2]/2 - 250, 0), f"{mod}",(218,165,32),font=fnt_main, align='center')

    final_concat = add_margin(final_concat, 200, 0, 0, 0, (0,0,0))
    final_imgs[modality] = final_concat
    
v_concatted_all_mods = get_concat_v(final_imgs['func'], final_imgs['dwi'])

v_concatted_all_mods.save(f"{figures_dir}/TrainTest_set_mosaic.png")
```

```{r eval=FALSE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
save.image(paste(root.dir, "/../AllCache_frequentist.RData", sep = ''))
rm(list = ls()[grep("out_", ls()) & !grep("out_stacking_func_dwi_beh", ls())])
rm(list = ls()[grep("tree_fit", ls())])
rm(list = ls()[grep("all_best_", ls())])
rm(list = ls()[grep("dat_", ls())])
```

# (Part III) Bayesian Model Evaluation: Searching Classifier Posterior Distributions for Evidence of Transferred Learning

Using the frequentist approach as we have done so far was helpful in that does not let us conclude that the first and second model have an equivalent performance. If we wanted to make this assertion we need to use a Bayesian approach.

```{r eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
if (file.exists(paste(root.dir, "/../AllCache_bayesian.RData", sep = ''))) load(paste(root.dir, "/../AllCache_bayesian.RData", sep = ''))
```

```{r message=FALSE, eval=TRUE, warning=FALSE, echo=FALSE}
# # brew install V8
# # tbb_ver = "2021.3.0"
# # Sys.setenv(TBB_VERSION=tbb_ver)
# # Sys.setenv(TBB="/usr/local/Cellar/tbb/2021.3.0")
# # Sys.setenv(TBB_INC="/usr/local/Cellar/tbb/2021.3.0/include")
# # Sys.setenv(TBB_LIB="/usr/local/Cellar/tbb/2021.3.0/lib")
# # Sys.setenv(TBB_INTERFACE_NEW ="true")

# Sys.setenv(DOWNLOAD_STATIC_LIBV8=1)
# 
# Sys.setenv(MAKEFLAGS = "-j8")
# Sys.setenv("R_REMOTES_NO_ERRORS_FROM_WARNINGS" = "true")
# Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 0) # only necessary for Linux without the nodejs library / headers
# dotR <- file.path(Sys.getenv("HOME"), ".R")
# if (!file.exists(dotR)) dir.create(dotR)
# M <- file.path(dotR, "Makevars")
# if (!file.exists(M)) file.create(M)
# cat("\nCXX14FLAGS += -O3 -mtune=native -arch x86_64 -ftemplate-depth-256",
#     file = M, sep = "\n", append = FALSE)
# 
# install.packages("lazyeval", "cli", "git2r", "V8")
# remotes::install_github("RcppCore/RcppParallel", force = TRUE)
# remotes::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan")
# remotes::install_github("stan-dev/rstanarm", INSTALL_opts = "--no-multiarch", force = TRUE)
# install.packages(c("loo", "coda", "bayesplot", "brms", "bridgesampling", "ProbBayes", "HDInterval", "bayestestR", "tidybayes", "psych", "cluster", "e1071", "MLeval", "pROC", "BayesFactor"))
# install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))

# Change /usr/local/lib/R/4.1/site-library/RcppParallel/include/tbb/parallel_reduce.h to https://raw.githubusercontent.com/stan-dev/math/92075708b1d1796eb82e3b284cd11e544433518e/lib/tbb_2020.3/include/tbb/parallel_reduce.h to achieve dual multi-threading with cmdstanr backend
# Note: The environment for (Part I) needs to be loaded FIRST before loading the following libraries for the Bayesian analysis:
library(V8); library(rstan); library(bridgesampling); library(MLeval); library(pROC); library(brms); library(rstanarm);  library(BayesFactor); library(loo); library(ProbBayes); library(coda); library(HDInterval); library(bayesplot); library(bayestestR); library(tidybayes); library(psych); library(cmdstanr); library(cluster); library(e1071); library(foreach); library(doParallel)

mc.cores=16
options(mc.cores=mc.cores)
rstan_options(auto_write = TRUE)

rstan_threading <- threading(mc.cores)
#rstan_threading <- NULL
# Change the above rstan_threading setting to NULL if rstan was installed from CRAN rather than not compiled + installed from the dev/source version.

inits <- list(list(Intercept = runif(n=1, min=0.0000001, max=0.999999)), list(Intercept = runif(n=1, min=0.000001, max=1.999999)), list(Intercept = runif(n=1, min=0.0000001, max=0.999999)), list(Intercept = runif(n=1, min=0.000001, max=1.999999)))

get_bayes_auc <- function(fit, Y, nsamples=1000){
  set.seed(42)
  ppred <- as.tibble(as.data.frame(posterior_epred(fit, ndraws=nsamples)) >= 0.5) %>% mutate_all(as.numeric) %>% mutate_all(as.integer)
  aucs_bayes <- vector(length=nsamples)
  cores=detectCores()
  cl <- makeCluster(cores[1]-1)
  registerDoParallel(cl)
  aucs_bayes <- foreach(i=1:nrow(ppred), .combine=cbind, .packages=c("pROC")) %dopar% {
     tempMatrix = roc(as.vector(as.matrix(ppred[i,])), Y)$auc[[1]]
  }
  stopCluster(cl)
  return(as.vector(aucs_bayes[1,]))
}

get_pd_cat <- function(pd_val) {
  df_pd <- tibble(pd_val) %>% mutate(pd_cat = case_when((pd_val <= 0.95) ~ "not existing", (pd_val > 0.95) ~ "possibly existing", (pd_val > 0.97) ~ "likely existing", (pd_val > 0.99) ~ "probably existing", (pd_val > 0.999) ~ "certainly existing"))
  return(df_pd$pd_cat)
}

relieve_interaction_priors <- function(formula, priors) {
    single_terms <- str_subset(strsplit(gsub("~, Y, ", "", toString(formula)), ' \\+ ')[[1]], "\\:", negate=T)
    
    inter_terms <- str_subset(strsplit(gsub("~, Y, ", "", toString(formula)), ' \\+ ')[[1]], "\\:")
    
    newpriors <- c(set_prior(as.matrix(as.data.frame(priors) %>% filter(source=="user") %>% dplyr::select(prior) %>% pull(1))[1,], class="b", coef=single_terms), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"), set_prior("normal(0, 10)", class = "b"))
    return (newpriors)
}

bayes.t.test <- function(mod_x, mod_y, mod_x_name, mod_y_name, data, nsamples=100){
  x_pred_AUC <- get_bayes_auc(mod_x, data$Y, nsamples=nsamples)
  y_pred_AUC <- get_bayes_auc(mod_y, data$Y, nsamples=nsamples)
  bf_auc <-ttestBF(x = x_pred_AUC, y = y_pred_AUC, paired=TRUE)
  ci_auc <- ci(bf_auc, method = "HDI")
  rope_auc <- rope(bf_auc, range = "default", ci = 1, ci_method = "HDI")
  pd_val <- pd(bf_auc)$pd[1]
  return(paste0("on the basis of ", nsamples, " posterior draws of AUC, there was ", gsub(" against", "", effectsize::interpret_bf(exp(bf_auc@bayesFactor$bf), include_value = TRUE, protect_ratio=F, exact=F)[1]), " in favor of ", mod_x_name, " over ", mod_y_name, ", which approached a ", round(100*pd_val, 4) ,"% probability of ",  get_pd_cat(pd_val)," within an 89% cred. interval [", round(ci_auc$CI_low, 3), ", ", round(ci_auc$CI_high, 3), "], and which was not ", effectsize::interpret_rope(rope_auc$ROPE_Percentage)[1], " evidence (approaching ", round(100*rope_auc$ROPE_Percentage, 4), "% in ROPE) against the null hypothesis in a test of practical equivalence"))
}

add_me_to_model <- function(fit, newdata, df_icc_long=NULL, mecorr=TRUE, null_compare=FALSE) {

    dwi_names <- sapply(strsplit(as.character(names(newdata)[which(names(newdata) %>% startsWith("dwi"))]), "\\_"), "[[", 2)
    func_names <- sapply(strsplit(as.character(names(newdata)[which(names(newdata) %>% startsWith("func"))]), "\\_"), "[[", 2)
    beh_names <- as.character(names(newdata)[which(names(newdata) %>% startsWith("Beh"))])
    single_terms <- c()
    
    if (length(func_names) > 0){
      modality = 'func'
      icc_sd = 0.07
    }
    if (length(dwi_names) > 0){
      modality = 'dwi'
      icc_sd = 0.088
    }
    if (length(beh_names) > 0){
      modality = 'beh'
      icc_sd = 0.05
    }
    
    if (is.null(df_icc_long) == FALSE) {
        df_icc_long <- outlierKD(df_icc_long, ICC) %>% na.omit()
        local_mes <- get_nodal_icc_errors(newdata, df_icc_long, modality)
        
        local_mes_names <- local_mes[[1]]
        single_terms <- str_subset(tail(strsplit(gsub("~, Y, ", "", gsub('\\)','', gsub('\\(','', toString(fit$formula$formula)))), ' \\+ ')[[1]], -2), "\\:", negate=T)
            
        single_terms <- single_terms[!sapply(strsplit(as.character(single_terms), "\\_"), "[[", 2) %in% local_mes_names]
        single_terms <- intersect(single_terms, names(newdata))
        
        local_mes_ms <- local_mes[[2]]
        local_mes_sds <- local_mes[[3]]
        
        beta_mes <- c()
        beta_names <- c()
        for (i in seq(1, length(local_mes_names))){
          beta_name <- names(newdata)[grep(local_mes_names[i], names(newdata))]
          beta_names <- c(beta_names, beta_name)
          beta_mes <- c(beta_mes, paste("me(", beta_name, ", ", as.character(local_mes_sds[i]/sqrt(abs(1 - local_mes_ms[i]))),") + ", sep = ""))
        }

    } else {
        
        if (null_compare == TRUE){
          # Random me / flat prior case
          if (modality == 'func'){
              local_mes_names <- names(newdata)[which(names(newdata) %>% startsWith("func"))]
          }
          if (modality == 'dwi'){
              local_mes_names <- names(newdata)[which(names(newdata) %>% startsWith("dwi"))]
          }
          if (modality == 'beh'){
              local_mes_names <- names(newdata)[which(names(newdata) %>% startsWith("Beh"))]
              single_terms <- c("Behavioral_disability")
              local_mes_names <- local_mes_names[!local_mes_names %in% single_terms]
          }
          local_mes_ms <- abs(rnorm(length(local_mes_names), icc_sd, 0.05))/sqrt(abs(1-runif(n=length(local_mes_names),min=0,max=1)))
        } else {
          # Behavioral Questionnaire case
          local_mes_names <- c("Behavioral_emotional_appraisal", "Behavioral_brooding_severity", "Behavioral_emotional_control", "Behavioral_perceptual_IQ", "Behavioral_State_anxiety", "Behavioral_emotion_utilization", "Behavioral_Life_satisfaction", "Behavioral_social_ability_sum", "Behavioral_Trait_anxiety")
          single_terms <- c("Behavioral_disability")
          local_mes_ms <- abs(rnorm(length(local_mes_names), icc_sd, 0.05))/sqrt(abs(1-c(0.68, 0.62, 0.69, 0.90, 0.89, 0.83, 0.89, 0.71, 0.85)))
        }
        
        beta_mes <- c()
        beta_names <- c()
        for (i in seq(1, length(local_mes_names))){
          beta_name <- names(newdata)[grep(local_mes_names[i], names(newdata))]
          beta_names <- c(beta_names, beta_name)
          beta_mes <- c(beta_mes, paste("me(", beta_name, ", ", as.character(local_mes_ms[i]),") + ", sep = ""))
        }
    }

    newpriors <- c(set_prior(as.matrix(as.data.frame(fit$prior) %>% filter(source=="user") %>% dplyr::select(prior) %>% pull(1))[1,], class="meanme"), set_prior("normal(0, 1)", class = "b"), set_prior("lkj_corr_cholesky(1)", class = "Lme"))
            
    apply_me_to_coefs <- function(i){
        return(paste("me(", i, ", ", as.character(abs(rnorm(1, icc_sd, 0.05))/sqrt(abs(1-abs(rnorm(1, mean(local_mes_ms, na.rm=TRUE), icc_sd))))),")", sep = ""))
    }
    
    if (length(single_terms) > 0) {
        newformula <- bf(as.formula(paste("Y ~ 0 + Intercept + ", 
                                          paste(paste(beta_mes, collapse = ' '),  paste(lapply(single_terms, apply_me_to_coefs), collapse = ' + '),
                                          sep="")))) 
    } else {
        form_tmp <- paste("Y ~ 0 + Intercept + ", 
                                          paste(paste(beta_mes, collapse = '')), 
                                          sep="")
        form_tmp <- substr(form_tmp,1,nchar(form_tmp)-3)
        newformula <- bf(as.formula(form_tmp))
    }

    newformula <- newformula + set_mecor(mecorr)
        
    # gg <- prior_predictive_check(newdata %>% dplyr::select(starts_with("dwi"), Y), "ME prior", newpriors, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, newformula)
  
    print(newformula)
        
    fit$prior <- empty_prior()
    
    return (update(fit, formula.=newformula, prior=newpriors, newdata=newdata, family = brms::bernoulli(link='logit'), silent=TRUE, save_pars = save_pars(latent = TRUE, all = TRUE), warmup = 2000, iter = 6000, control=list(adapt_delta=0.90, max_treedepth=15), seed=42, cores = 4, backend = "cmdstanr", threads = rstan_threading, recompile=TRUE, inits=0))
}

get_nodal_icc_errors <- function(df, df_icc_long, modality){
    
    if (modality == 'dwi'){
    dwi_rois <- intersect(sapply(strsplit(as.character(names(df)[which(names(df) %>% startsWith("dwi"))]), "\\_"), "[[", 2), unique(df_icc_long$ROI))
    mes_icc <- vector(length=length(dwi_rois))
    mes_sd_icc <- vector(length=length(dwi_rois))
    mes_icc_names <- vector(length=length(dwi_rois))
    i = 1
    for (roi in dwi_rois){
        mes_icc[[i]] <- df_icc_long %>% filter(modality=='dwi' & network == 'LN-Dorsal', grepl(rlang::as_character(roi), ROI)) %>% summarise(median = median(ICC, na.rm = TRUE)) %>% pull(.)
        mes_icc_names[[i]] <- roi
        mes_sd_icc[[i]] <- df_icc_long %>% filter(modality=='dwi' & network == 'LN-Dorsal', grepl(rlang::as_character(roi), ROI)) %>% summarise(median = median(ICC_SD, na.rm = TRUE)) %>% pull(.)
        i = i + 1
        gc()
    } 
  
    } else {
    func_rois <- intersect(sapply(strsplit(as.character(names(df)[which(names(df) %>% startsWith("func"))]), "\\_"), "[[", 2), unique(df_icc_long$ROI))
    mes_icc <- vector(length=length(func_rois))
    mes_sd_icc <- vector(length=length(func_rois))
    mes_icc_names <- vector(length=length(func_rois))
    i = 1
    for (roi in func_rois){
        mes_icc[[i]] <- df_icc_long %>% filter(modality=='func' & network == 'TN-Inter', grepl(rlang::as_character(roi), ROI)) %>% summarise(median = median(ICC, na.rm = TRUE)) %>% pull(.)
         mes_icc_names[[i]] <- roi
         mes_sd_icc[[i]] <- df_icc_long %>% filter(modality=='func' &network == 'TN-Inter', grepl(rlang::as_character(roi), ROI)) %>% summarise(median = median(ICC_SD, na.rm = TRUE)) %>% pull(.)
        i = i + 1
        gc()
    }    
    }
        
    return(list(mes_icc_names, mes_icc, mes_sd_icc))
}

performance_summary <- function(logisticfit, Y=NULL, ppaverage=FALSE) {
    set.seed(42)
    if (ppaverage == FALSE) {
      pred <- predict(logisticfit, type = "response")[, "Estimate"]
      # Predicted logodds or probabilities
      linpred <- posterior_linpred(logisticfit)
      epred <- colMeans(posterior_epred(logisticfit))
      ppred <- as.integer(epred >= 0.5)
      Y <- logisticfit$data$Y
    } else {
      pred <- logisticfit[, "Estimate"]
      Y <- as.numeric(Y) - 1
    }
    
    pred <- as.numeric(pred > mean(Y, na.rm = T))

    ROC <- roc(Y, ppred)
    auc <- ROC$auc[[1]]
    print(paste0("AUC: ", auc))
    
    # Classification table
    classtab1 <- table(predicted = pred, observed = Y)
    print("Predicted:")
    print(classtab1)
    acc1 <- sum(diag(classtab1)) / sum(classtab1)
    print(paste("Accuracy:", acc1, sep= " "))
    classerror1=1-acc1
    print(paste("Error:", classerror1, sep= " "))
    
    classtab2 <- table(predicted = ppred, observed = Y)
    print("Predicted (Log-Odds):")
    print(classtab2)
    acc2 <- sum(diag(classtab2)) / sum(classtab2)
    print(paste("Accuracy:", acc2, sep= " "))
    classerror2=1-acc2
    print(paste("Error:", classerror2, sep= " "))
    
    return(list(auc, acc1, classerror1))
}

diagnostic_check <- function(logisticfit, model_name, plotting=0) {
    min_beta_diag <- diagnostic_posterior(logisticfit) %>% filter(Parameter!='b_Intercept') %>% dplyr::select(Rhat, ESS, MCSE) %>% summarise_all(list(~(min(., na.rm = TRUE))))
    mean_beta_diag <- diagnostic_posterior(logisticfit) %>% filter(Parameter!='b_Intercept') %>% dplyr::select(Rhat, ESS, MCSE) %>% summarise_all(list(~(mean(., na.rm = TRUE))))
    max_beta_diag <- diagnostic_posterior(logisticfit) %>% filter(Parameter!='b_Intercept') %>% dplyr::select(Rhat, ESS, MCSE) %>% summarise_all(list(~(max(., na.rm = TRUE))))
    intercept_diag <- diagnostic_posterior(logisticfit) %>% filter(Parameter=='b_Intercept') %>% dplyr::select(Rhat, ESS, MCSE) %>% summarise_all(list(~(mean(., na.rm = TRUE))))
    out_trace <- NULL
    out_pairs <- NULL
    if (plotting > 0){
        out_trace <- bayesplot::mcmc_combo(logisticfit, gg_theme=ggplot2::labs(title=strsplit(model_name, '\n')[[1]][[1]]))
    }

    if (plotting > 1){
        out_trace <- bayesplot::mcmc_pairs(logisticfit, grid_args = list(top = textGrob(strsplit(model_name, '\n')[[1]][[1]])))
    }    
            
    get_neff_cat <- function(fit) {
    df_neff_cat <- as_tibble(t(neff_ratio(fit))) %>% dplyr::select(-lp__) %>% mutate(neff_cat = case_when((sum(., na.rm=T) > 0.5) ~ "very good", (sum(., na.rm=T) <= 0.5 & sum(., na.rm=T) > 0.1) ~ "satisfactory", (sum(., na.rm=T) <= 0.1) ~ "concerning"))
  return(df_neff_cat$neff_cat)
        }

    get_rhat_cat <- function(fit) {
    df_neff_cat <- as_tibble(t(neff_ratio(fit))) %>% dplyr::select(-lp__) %>% mutate(neff_cat = case_when((sum(., na.rm=T) > 0.5) ~ "very good", (sum(., na.rm=T) <= 0.5 & sum(., na.rm=T) > 0.1) ~ "satisfactory", (sum(., na.rm=T) <= 0.1) ~ "concerning"))
  return(df_neff_cat$neff_cat)
    }
    
    n_eff <- round(mean(as_tibble(t(neff_ratio(logisticfit))) %>% dplyr::select(-lp__) %>% as.matrix(), na.rm=T), 2)
    
    autocorr <- n_eff/length(logisticfit$data$Y)

    out <- paste0("For the model '", strsplit(model_name, '\n')[[1]][[1]], "' ", round(sum(get_divergent_iterations(logisticfit$fit))/length(get_divergent_iterations(logisticfit$fit)), 2), "% of iterations ended with a divergence. ", round(sum(get_max_treedepth_iterations(logisticfit$fit))/length(get_max_treedepth_iterations(logisticfit$fit)), 2), "% of iterations saturated the maximum tree depth of 10. ", sum(get_bfmi(logisticfit$fit)<0.2), " of the chains sampled had E-BFMI values < 0.2. In regards to numerical diagnostics of the posterior for each model term, we observed that for the intercept, ESS=", round(intercept_diag$ESS, 2), ", Rhat=", round(intercept_diag$Rhat, 2), ", and MCSE=", round(intercept_diag$MCSE, 2), ". For the betas, mean Rhat=", round(mean_beta_diag$Rhat, 2), " mean ESS=", round(mean_beta_diag$ESS, 2), " with a minimum of ", round(min_beta_diag$ESS, 2), " and maximum of ", round(max_beta_diag$ESS, 2), ", and mean MCSE=", round(mean_beta_diag$MCSE, 2), " with a minimum of ", round(min_beta_diag$MCSE, 2), " and maximum of ", round(max_beta_diag$MCSE, 2), ". Across predictors, the average N_eff=",  n_eff," which indicated a ", get_neff_cat(logisticfit$fit), ' ability of the sampler to draw posterior estimates that approximate the true mean value of the parameters.')
    
  sims <- as.array(logisticfit)
  rhat <- apply(sims, MARGIN = 3, FUN = Rhat)
  if (any(rhat > 1.05, na.rm = TRUE))
      out <- paste0(out, " The largest beta R-hat was ", round(max_beta_diag$Rhat, 2),", indicating chains poor chain mixing.")
  bulk_ess <- apply(sims, MARGIN = 3, FUN = ess_bulk)
  if (any(bulk_ess < 100 * ncol(sims), na.rm = TRUE))
    out <- paste0(out, " Bulk Effective Samples Size (ESS) was low, indicating posterior means and medians were likely unreliable.")
  tail_ess <- apply(sims, MARGIN = 3, FUN = ess_tail)
  if (any(tail_ess < 100 * ncol(sims), na.rm = TRUE))
        out <- paste0(out, " Tail Effective Samples Size (ESS) was low, indicating posterior variances and tail quantiles were likely unreliable. ")
  
  if ((autocorr > 0.02) && (autocorr < 0.15)) {
        out <- paste0(out, " Some autocorrelation detected.") 
  }
  if (autocorr > 0.15) {
        out <- paste0(out, " High autocorrelation detected.")  
  }
  
    return(list(out, out_trace, out_pairs))
}

prior_predictive_check <- function(df, model_name, priors, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, FORMULA=NULL) {
    
    if (is.null(FORMULA) == TRUE) {
        fit <- brm(Y ~ 0 + Intercept + ., sample_prior = "only", data = df, 
                         family = brms::bernoulli(link='logit'), 
                         prior = priors, silent=TRUE, seed=42, cores = 4, 
                   backend = "cmdstanr", threads = threading(mc.cores))
    } else {
        fit <- brm(FORMULA, sample_prior = "only", data = df, 
                         family = brms::bernoulli(link='logit'), 
                         prior = priors, silent=TRUE, seed=42, cores = 4, 
                   backend = "cmdstanr", threads = threading(mc.cores))      
    }

    prior_y = fit$data$Y
    prior_yrep = posterior_predict(fit,nsamples=nsim)
    
    # summarize prior distribution of response
    sum_prior <- apply(prior_yrep, 1, sum_fun)

    # get the quantiles
    qq <- quantile(sum_prior, probs = probs, na.rm = TRUE)
    # quantile range
    r_qq <- (probs[2] - probs[1]) * 100

    chk_fit <- check_prior(fit)
    
    out <- paste0(r_qq, "% of ", nsim, " simulated response draws from the ", unique(chk_fit$Prior_Quality)," prior distributions ", priors$prior[[1]], " and ", priors$prior[[2]], " for '", strsplit(model_name, '\n')[[1]][[1]], "' had a ", sum_fun, " value between ", round(qq[1], 2), " and ", round(qq[2], 2), " with all simulated values falling between ", round(range(sum_prior)[[1]], 2), " and ", round(range(sum_prior)[[2]], 2), ".")
        
    prior_dens <- ppc_dens_overlay(prior_y,prior_yrep[sample(1:4000,200),],
                                  size = .1,alpha=.5) + xlim(-5,10) + 
      ggtitle(strsplit(model_name, '\n')[[1]][[1]]) + theme(plot.title = element_text(hjust = 0.5, colour="white"), plot.background = element_rect(fill = "black"), panel.background = element_rect(fill = "black"), legend.key = element_rect(fill = "black"))
    return(list(prior_dens, out))
}

posterior_predictive_check <- function(logisticfit, model_name) {
    pp_mean_out <- pp_check(logisticfit) + ggtitle(paste('PPC:', strsplit(model_name, '\n')[[1]][[1]], 'Mean', sep = ' '))

    # DESCRIPTIVES - INTERCEPT
    draws_beta0 <- as.matrix(posterior_samples(logisticfit, pars = "b_Intercept"))
    logistic_beta0 <- plogis(draws_beta0)
    out_beta0 <- psych::describe(logistic_beta0) 
    intercept_areas <- mcmc_areas(logisticfit, pars = "b_Intercept", 
               transformations = list("b_Intercept" = "plogis")) + ggtitle(paste('PPC:', strsplit(model_name, '\n')[[1]][[1]], 'Intercept (plogis)', sep = ' '))
    
    # Difference in using all draws versus the credible interval values
    quantile(logistic_beta0, probs = c(.025, .975))
    # Transform the credible interval limits of beta0:
    pp_interval_intercept <- round(100*plogis(posterior_interval(logisticfit, pars = "b_Intercept"))[[2]], 3)
    
    # DESCRIPTIVES - SLOPE
    draws_beta1 <- as.matrix(posterior_samples(logisticfit, pars = "b"))
    exp_beta1 <- exp(draws_beta1)
    out_beta1 <- psych::describe(exp_beta1)
    quant_b <- quantile(exp_beta1, probs = c(.025, .975))
    # Extract coefficients
    fixefs <- t(data.frame(fixef(logisticfit) %>% data.frame %>% dplyr::select(contains("Estimate"))))
    # Exponential the credible interval
    pp_interval_slope <- as_tibble(plogis(exp(posterior_interval(logisticfit, pars = "b")))[2,]) %>% pull(value)
    pp_interval_slope <- round(100*pp_interval_slope[[2]], 3)

    # Change in probability with increase of 1 unit in the predictor
    # Extract posterior samples
    df_fixefs_change <- tibble(vars = numeric(), n = numeric(), mean = numeric(), sd = numeric(), median = numeric(), trimmed = numeric(), mad = numeric(), min = numeric(), max = numeric(), range = numeric(), skew  = numeric(), kurtosis = numeric(), se = numeric())
    for(i in 2:ncol(fixefs) ){
        df_fixefs_change <- add_row(df_fixefs_change, psych::describe(plogis(draws_beta0 + draws_beta1[,i] * 1) - plogis(draws_beta0)))
    }
    
    get_pp_cat <- function(pp_interval_intercept, pp_interval_slope) {
    df_pp <- tibble(pp_interval_intercept, pp_interval_slope) %>% mutate(pp_cat = case_when((pp_interval_intercept > 99 | pp_interval_slope > 99) ~ "very good", (pp_interval_intercept > 95 | pp_interval_slope > 95) ~ "good", (pp_interval_intercept > 75 | pp_interval_slope > 75) ~ "moderately good", (pp_interval_intercept < 50 | pp_interval_slope < 50) ~ "poor"))
  return(df_pp$pp_cat)
    }
    
    # (Gelman and Hill, 2007)
    out <- paste0("When simulating replicated data under the fitted '", strsplit(model_name, '\n')[[1]][[1]], "' model and comparing these posterior samples to the observed data, we found that the 95% credible interval for the intercept contained ", pp_interval_intercept, "% of the actual data, and the average 95% credible interval across all beta coefficients contained ", pp_interval_slope, "% of the actual data. With every 1-unit increase in the each of the ", length(df_fixefs_change$vars), " betas, the mean posterior probabilities of ", sum(df_fixefs_change$mean > 0.01), " predictors changed by > 1% and that of ", sum(df_fixefs_change$mean < 0.01), " predictors changed by < 1%. Hence, the model exhibited ", get_pp_cat(pp_interval_intercept, pp_interval_slope)," fit to the observed data.")
    
    #plot(conditional_effects(logisticfit, spaghetti=TRUE), ask=FALSE)
    return(list(pp_mean_out, intercept_areas, out))
}

outlierKD <- function(dt, var) {
  var_name <- eval(substitute(var),eval(dt))
  tot <- sum(!is.na(var_name))
  na1 <- sum(is.na(var_name))
  m1 <- mean(var_name, na.rm = T)
  outlier <- boxplot.stats(var_name)$out
  mo <- mean(outlier)
  var_name <- ifelse(var_name %in% outlier, NA, var_name)
  na2 <- sum(is.na(var_name))
  m2 <- mean(var_name, na.rm = T)
  dt[as.character(substitute(var))] <- invisible(var_name)
  df <- as.character(as.list(match.call())$dt)
  return(invisible(dt))
}
```

### Selecting Informative Priors
#### Measurement Error
```{python eval=FALSE, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE}
import os
import pandas as pd
import numpy as np
from sklearn import tree
import graphviz
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score
from sklearn.inspection import partial_dependence
from sklearn.inspection import plot_partial_dependence
from pdpbox.pdp import pdp_interact, pdp_interact_plot, pdp_isolate, pdp_plot
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score
from joblib import load
import seaborn as sns

def clean_dataset(df):
    df.dropna(inplace=True)
    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)
    return df[indices_to_keep].astype(np.float64)
  
# Load estimators
rf_func = load(f"/home/dpys/Documents/Dissertation/rf_estimator_func.joblib")
rf_dwi = load(f"/home/dpys/Documents/Dissertation/rf_estimator_dwi.joblib")

calculator_r2_dict = {}
for est in ['rf']:
    if est not in calculator_r2_dict.keys():
        calculator_r2_dict[est] = {}
    for mod in ['func', 'dwi']:
        if mod not in calculator_r2_dict[est].keys():
            calculator_r2_dict[est][mod] = {}
        df = pd.read_csv(f"/home/dpys/Documents/Dissertation/Chapter_IV/data/TrainTest_set/results/raw_tuning_{mod}.csv", index_col=0)
        if mod == 'func':
            cols = ['network', 'hpass', 'smooth', 'res', 'model', 'extract', 'embedding']
        elif mod == 'dwi':
            cols = ['network', 'minlength', 'tol', 'res', 'model', 'directget', 'embedding']
        grid_col = df[['grid']]
        embed_col = df[['embedding']]
        df= df[cols]
        df[cols] = df[cols].astype('category')
        df = pd.get_dummies(df, columns = cols)
        X_predict = clean_dataset(df)
        if mod == 'func':
            for i in list(set(all_func_cols) - set(X_predict.columns)) + list(set(X_predict.columns) - set(all_func_cols)):
                if i not in X_predict.columns:
                    X_predict[i] = 0
                else:
                    X_predict = X_predict.drop(columns=[i])
            pred_Y = rf_func.predict(imp_func.transform(X_predict))
        elif mod == 'dwi':
            for i in list(set(all_dwi_cols) - set(X_predict.columns)) + list(set(X_predict.columns) - set(all_dwi_cols)):
                if i not in X_predict.columns:
                    X_predict[i] = 0
                else:
                    X_predict = X_predict.drop(columns=[i])
            pred_Y = rf_dwi.predict(imp_dwi.transform(X_predict))
        pd.concat([grid_col, embed_col, pd.DataFrame(pred_Y, columns=['Discriminability_predicted'])], axis=1).to_csv(f"/home/dpys/Documents/Dissertation/Chapter_IV/data/TrainTest_set/results/df_{mod}_predicted_discrim_{est}.csv", index=False)
```

```{r discrim_as_me_error, fig.width = 16, fig.height=10, fig.align="center", message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
load(paste(repro_dir, "/df_reproducibility_func.RData", sep = ''))
load(paste(repro_dir, "/df_reproducibility_dwi.RData", sep = ''))

# Functional CI Widths
df_func <- df_func %>% dplyr::mutate(Error_95CI_upper = rowMeans(dplyr::select(., matches("*Error_95CI_upper")), na.rm = TRUE)) %>% dplyr::mutate(Error_95CI_lower = rowMeans(dplyr::select(., matches("*Error_95CI_lower")), na.rm = TRUE)) %>% dplyr::mutate(Score_95CI_upper = rowMeans(dplyr::select(., matches("*Score_95CI_upper")), na.rm = TRUE)) %>% dplyr::mutate(Score_95CI_lower = rowMeans(dplyr::select(., matches("*Score_95CI_lower")), na.rm = TRUE))
df_func$Score_95CI_width <- (df_func$Score_95CI_upper - df_func$Score_95CI_lower)
df_func$Error_95CI_width <- (df_func$Error_95CI_upper - df_func$Error_95CI_lower)
df_func_predicted_discrim_random_forest = read.csv(paste0(results_dir, "df_func_predicted_discrim_rf.csv"))
df_func_predicted_discrim_random_forest <- df_func_predicted_discrim_random_forest[!(is.na(df_func_predicted_discrim_random_forest$grid) | df_func_predicted_discrim_random_forest$grid==""), ]
names(df_func_predicted_discrim_random_forest) <- c("grid", "embedding", "predicted_discrim_rf")

names(df_func)[2:7] <- c('ExtractionMethod', 'FrequencyBandwidth', 'ConnectivityEstimator', 'NodeGranularity', 'SmoothingTolerance', 'NetworkDefinition')

if ("Pheno" %in% names(df_func)){
    df_func <- df_func %>% rename_with(~"Phenotype", "Pheno")  
}

df_func_CI <- df_func %>% dplyr::select(grid, 'ExtractionMethod', 'FrequencyBandwidth', 'ConnectivityEstimator', 'NodeGranularity', 'SmoothingTolerance', 'NetworkDefinition', Phenotype, R2, Error_mean, Score_95CI_width, Error_95CI_width) %>% filter(Phenotype!='Random', Phenotype!='Age')

discrim_pheno_map_func <- df_func %>% dplyr::select(ExtractionMethod, FrequencyBandwidth, ConnectivityEstimator,  NodeGranularity, NetworkDefinition, SmoothingTolerance, Phenotype) %>% filter(Phenotype!='Random', Phenotype!='Age') %>% dplyr::select(-Phenotype) %>% as_tibble() %>% mutate_if(is.character, as.factor)

repro_func_predicted <- join_cols_by_grid(df_reproducibility_func_long_pruned, df_func_predicted_discrim_random_forest) %>% drop_na() %>% filter(network=='LN_dorsal' | network=='TN_intersection') %>% dplyr::select(-grid, -embedding) %>% as_tibble() %>% mutate_if(is.character, as.factor)

names(repro_func_predicted)[1:6] <- c('NetworkDefinition', 'FrequencyBandwidth', 'SmoothingTolerance', 'NodeGranularity', 'ConnectivityEstimator', 'ExtractionMethod')

avg_discr_best_performing_func_discrim <- mean(inner_join(repro_func_predicted, discrim_pheno_map_func, by=c('ExtractionMethod', 'FrequencyBandwidth', 'NodeGranularity', 'ConnectivityEstimator', 'NetworkDefinition', 'SmoothingTolerance')) %>% pull(Discriminability), na.rm=TRUE)

sd_discr_best_performing_func_discrim <- sd(inner_join(repro_func_predicted, discrim_pheno_map_func, by=c('ExtractionMethod', 'FrequencyBandwidth', 'NodeGranularity', 'ConnectivityEstimator', 'NetworkDefinition', 'SmoothingTolerance')) %>% pull(Discriminability), na.rm=TRUE)

# Structural CI Widths
df_dwi <- df_dwi %>% dplyr::mutate(Error_95CI_upper = rowMeans(dplyr::select(., matches("*Error_95CI_upper")), na.rm = TRUE)) %>% dplyr::mutate(Error_95CI_lower = rowMeans(dplyr::select(., matches("*Error_95CI_lower")), na.rm = TRUE)) %>% dplyr::mutate(Score_95CI_upper = rowMeans(dplyr::select(., matches("*Score_95CI_upper")), na.rm = TRUE)) %>% dplyr::mutate(Score_95CI_lower = rowMeans(dplyr::select(., matches("*Score_95CI_lower")), na.rm = TRUE))
df_dwi$Score_95CI_width <- (df_dwi$Score_95CI_upper - df_dwi$Score_95CI_lower)
df_dwi$Error_95CI_width <- (df_dwi$Error_95CI_upper - df_dwi$Error_95CI_lower)
df_dwi_predicted_discrim_random_forest = read.csv(paste0(results_dir, "df_dwi_predicted_discrim_rf.csv"))
df_dwi_predicted_discrim_random_forest <- df_dwi_predicted_discrim_random_forest[!(is.na(df_dwi_predicted_discrim_random_forest$grid) | df_dwi_predicted_discrim_random_forest$grid==""), ]
names(df_dwi_predicted_discrim_random_forest) <- c("grid", "embedding", "predicted_discrim_rf")

names(df_dwi)[2:7] <- c('NetworkDefinition', 'MinimumFiberLength', 'SmoothingTolerance', 'ConnectivityEstimator', 'NodeGranularity', 'ExtractionMethod')

if ("Pheno" %in% names(df_dwi)){
    df_dwi <- df_dwi %>% rename_with(~"Phenotype", "Pheno")  
}

df_dwi_CI <- df_dwi %>% dplyr::select(grid, 'NetworkDefinition', 'MinimumFiberLength', 'SmoothingTolerance', 'ConnectivityEstimator', 'NodeGranularity', 'ExtractionMethod', Phenotype, R2, Error_mean, Score_95CI_width, Error_95CI_width) %>% filter(Phenotype!='Random', Phenotype!='Age')

discrim_pheno_map_dwi <- df_dwi %>% dplyr::select(ExtractionMethod, MinimumFiberLength, ConnectivityEstimator,  NodeGranularity, NetworkDefinition, SmoothingTolerance, Phenotype) %>% filter(Phenotype!='Random', Phenotype!='Age') %>% dplyr::select(-Phenotype) %>% as_tibble() %>% mutate_if(is.character, as.factor)

repro_dwi_predicted <- join_cols_by_grid(df_reproducibility_dwi_long, df_dwi_predicted_discrim_random_forest) %>% drop_na() %>% filter(network=='LN_dorsal' | network == 'TN_intersection') %>% dplyr::select(-grid, -embedding) %>% as_tibble() %>% mutate_if(is.character, as.factor)

names(repro_dwi_predicted)[1:6] <- c('NetworkDefinition', 'MinimumFiberLength', 'SmoothingTolerance', 'NodeGranularity', 'ConnectivityEstimator', 'ExtractionMethod')

avg_discr_best_performing_dwi_discrim <- mean(inner_join(repro_dwi_predicted, discrim_pheno_map_dwi, by=c('ExtractionMethod', 'MinimumFiberLength', 'NodeGranularity', 'ConnectivityEstimator', 'NetworkDefinition', 'SmoothingTolerance')) %>% pull(Discriminability), na.rm=TRUE)

sd_discr_best_performing_dwi_discrim <- sd(inner_join(repro_dwi_predicted, discrim_pheno_map_dwi, by=c('ExtractionMethod', 'MinimumFiberLength', 'NodeGranularity', 'ConnectivityEstimator', 'NetworkDefinition', 'SmoothingTolerance')) %>% pull(Discriminability), na.rm=TRUE)

# Join reproducibility data with predicted Error width
# Decision-tree reproducibility
repro_func_predicted <- repro_func_predicted %>% filter(FrequencyBandwidth!="0.15 Hz", FrequencyBandwidth!="0.22 Hz")
repro_func_predicted$FrequencyBandwidth <- as.factor(as.character(repro_func_predicted$FrequencyBandwidth))
levels(repro_func_predicted$FrequencyBandwidth) <- c("0.0 Hz", "0.028 Hz", "0.08 Hz")

repro_func_predicted <- repro_func_predicted %>% filter(ExtractionMethod!="sum")
repro_func_predicted$ExtractionMethod <- as.factor(as.character(repro_func_predicted$ExtractionMethod))
levels(repro_func_predicted$ExtractionMethod) <- c("maximum", "mean", "median")

repro_func_predicted <- repro_func_predicted %>% filter(NetworkDefinition=="TN_intersection")
repro_func_predicted$NetworkDefinition <- as.factor(as.character(repro_func_predicted$NetworkDefinition))

df_func_CI <- df_func_CI %>% filter(NetworkDefinition=="TN_intersection")
df_func_CI$NetworkDefinition <- as.factor(as.character(df_func_CI$NetworkDefinition))

df_func_rep <- distinct(df_func_CI %>% left_join(repro_func_predicted)  %>% na.omit())

df_dwi_rep <- distinct(df_dwi_CI %>% left_join(repro_dwi_predicted)  %>% na.omit())

df_func_rep$Modality <- as.factor('func')
df_dwi_rep$Modality <- as.factor('dwi')

df_func_rep <- dplyr::rename(df_func_rep, Grid = grid)
df_func_rep <- df_func_rep  %>% filter(Discriminability > 0.80)
df_func_rep$Discriminability_Error <- 1 - df_func_rep$Discriminability
df_func_rep$Discriminability_RF_Error <- 1 - df_func_rep$predicted_discrim_rf
df_func_rep <- outlierKD(outlierKD(df_func_rep, Discriminability_Error), R2)
df_func_rep$Phenotype <- as.factor(as.character(df_func_rep$Phenotype))
#levels(df_func_rep$Phenotype) <- c("Depression_Severity", "Rumination_Severity", "Depression_Persistence", "Rumination_Persistence")

df_dwi_rep <- dplyr::rename(df_dwi_rep, Grid = grid)
df_dwi_rep <- df_dwi_rep  %>% filter(Discriminability > 0.80)
df_dwi_rep$Discriminability_Error <- 1 - df_dwi_rep$Discriminability
df_dwi_rep$Discriminability_RF_Error <- 1 - df_dwi_rep$predicted_discrim_rf
df_dwi_rep <- outlierKD(outlierKD(df_dwi_rep, Discriminability_Error), R2)
df_dwi_rep$Phenotype <- as.factor(as.character(df_dwi_rep$Phenotype))
#levels(df_dwi_rep$Phenotype) <- c("Depression_Severity", "Rumination_Severity", "Depression_Persistence", "Rumination_Persistence")

df_all_rep <- rbind(dplyr::rename(df_func_rep, Fiber_Phase = FrequencyBandwidth), dplyr::rename(df_dwi_rep, Fiber_Phase = MinimumFiberLength))
df_all_rep$Modality <- as.factor(df_all_rep$Modality)
df_all_rep_bayes <- df_all_rep

# Explore associations between
## R2 ~ Discrim. Error
out_r2 <- lmer(R2 ~ Discriminability_Error + (1 | Modality) + (1 | Phenotype), data=df_all_rep)

summary_score_r2 <- report_statistics(out_r2)
r_square_score_r2 <- r.squaredGLMM(out_r2)[1,]

## Error CI Width ~ Discrim. Error
df_all_rep <- df_all_rep %>% filter(Grid!='TN_intersection_det_0_csa_400_5')
df_all_rep$Error_95CI_width <- as.double(df_all_rep$Error_95CI_width*100)
out_ci <- lmer(Error_95CI_width ~ Discriminability_Error + (1 | Modality) + (1 | Phenotype), data=df_all_rep)

summary_score_ci <- report_statistics(out_ci)
r_square_score_ci <- r.squaredGLMM(out_ci)[1,]

new_cols <- as.tibble(data.frame(do.call('rbind', strsplit(as.character(df_all_rep$Phenotype),'_',fixed=TRUE))))
colnames(new_cols) <- c("Mood Phenotype", "Temporality Phenotype")
new_cols <- new_cols %>% mutate_if(is.character, as.factor)
levels(new_cols$`Temporality Phenotype`) <- c("Persistence", "Severity")
df_all_rep <- cbind(df_all_rep, new_cols)

options(ggrepel.max.overlaps = 8)

map_to_derivs_func <- function(x){
  y <- str_split(x, pattern="_")[[1]]
  return(paste0("net-", toupper(y[1]), "_extract-", toupper(y[3]), "_freq-", toupper(y[4]), "Hz_mod-", toupper(y[5]), "_gran-", toupper(y[6]), "_tol-", toupper(y[7])))
}

map_to_derivs_dwi <- function(x){
  y <- str_split(x, pattern="_")[[1]]
  return(paste0("net-", toupper(y[1]), "_dg-", toupper(y[3]), "_ml-", toupper(y[4]), "_mod-", toupper(y[5]), "_gran-", toupper(y[6]), "_tol-", toupper(y[7])))
}

df_all_rep_dwi <- df_all_rep %>% filter(Modality=='dwi')

df_all_rep_func <- df_all_rep %>% filter(Modality=='func')

df_all_rep_func$Grid <- sapply(df_all_rep_func %>% select(Grid) %>% pull(.), map_to_derivs_func)

df_all_rep_dwi$Grid <- sapply(df_all_rep_dwi %>% select(Grid) %>% pull(.), map_to_derivs_dwi)

df_all_rep <- rbind(df_all_rep_dwi, df_all_rep_func) %>% as.tibble() %>% na.omit()

plt_discrim_R2 <- ggscatter(df_all_rep, facet.by = "Modality", merge=TRUE, x = "Discriminability_Error", y = "R2", color = "Mood Phenotype", shape = "Temporality Phenotype", ellipse = TRUE, label="Grid", font.label = c(10, "plain"), repel = TRUE, mean.point = TRUE, star.plot = TRUE, ggtheme = theme_void(), palette=pal_tron("legacy")(5), title = "The Association of Multiverse Connectome Discriminability and Regression R2/MSE in the Source Domain\n", panel.labs=list(Modality = c("Functional\nConnectomes\n(TN)", "Structural\nConnectomes\n(LN)"))) + theme(plot.title = element_text(hjust = 0.5, size=20, colour="white"), strip.text = element_text(size=18, colour="white"), axis.text.y=element_text(size=18, colour="white"), axis.text.x=element_text(size=18, colour="white"), legend.text=element_text(size=18, colour="white"), axis.title=element_text(size=20, colour="white"), panel.grid = element_blank(), plot.background = element_rect(fill = "black"), panel.background = element_rect(fill = "black"), legend.key = element_rect(), plot.margin = unit(c(1,1,1,1), "cm")) + scale_size(range = c(4, 12))
plt_discrim_R2

plt_discrim_CI <- ggscatter(df_all_rep, facet.by = "Modality", merge=TRUE, x = "Discriminability_Error", y = "Error_95CI_width", color = "Mood Phenotype", shape = "Temporality Phenotype", ellipse = TRUE, label="Grid", font.label = c(10, "plain", alpha=0.9), repel = TRUE, mean.point = TRUE, star.plot = TRUE, ggtheme = theme_void(), palette=rev(pal_tron("legacy")(5)), title = "The Association of Multiverse Connectome Discriminability and Regression R2/MSE CI Width in the Source Domain\n", xlab="Discriminability Error", ylab="MSE x 10-2 95% CI Width", panel.labs=list(Modality = c("Functional\nConnectomes\n(TN)", "Structural\nConnectomes\n(LN)"))) + theme(plot.title = element_text(hjust = 0.5, size=20, colour="white"), strip.text = element_text(size=18, colour="white"), axis.text.y=element_text(size=20, colour="white"), axis.text.x=element_text(size=18, colour="white"), legend.text=element_text(size=18, colour="white"), axis.title.x=element_text(size=20, colour="white"), axis.title.y=element_text(size=18, colour="white", angle=90), panel.grid = element_blank(), plot.background = element_rect(fill = "black"), panel.background = element_rect(fill = "black"), legend.key = element_rect(), plot.margin = unit(c(1,1,1,1), "cm")) + scale_size(range = c(4, 12))
plt_discrim_CI
  
# Get ICC values from individual ROI's
icc_long_dwi <- read.csv(paste(repro_dir, "/icc_long_dwi.csv", sep = ''))
icc_long_func <- read.csv(paste(repro_dir, "/icc_long_func.csv", sep = ''))

func_icc_vec <- as.data.frame(outlierKD(icc_long_func, ICC) %>% na.omit() %>% select("ROI", "ICC", "ICC_SD"))
dwi_icc_vec <- as.data.frame(outlierKD(icc_long_dwi, ICC) %>% na.omit() %>% select("ROI", "ICC", "ICC_SD"))

# Discriminability
mean_disc_func = avg_discr_best_performing_func_discrim
sd_disc_func = sd_discr_best_performing_func_discrim
mean_disc_dwi = avg_discr_best_performing_dwi_discrim
sd_disc_dwi = sd_discr_best_performing_dwi_discrim
mean_disc_beh = 0.80
sd_disc_beh = 0.05
```

When controlling for modality and choice of phenotype criterion variable as random effects of a linear mixed model, the known discriminability values of each attributed connectome recipe were strongly associated with the predictive $MSE$ benchmarks ($R^{2}_{cond}$=`r round(r_square_score_r2[2][[1]],3)`, `r summary_score_r2[1]`), and the width of their multiverse confidence intervals ($R^{2}_{cond}$=`r round(r_square_score_ci[2][[1]],3)`, `r summary_score_ci[1]`), achieved when using those connectomes as features in the regression models learned in the source domain (see star plots in Figure \ref{fig:discrim_as_me_errorCI}). We regarded the strength of these findings, which alluded to the benefits of discriminability-based transfer learning (DBT)~\cite{Pratt1993} even in the context of predicting continuous outcomes, as a clear indication of the importance of connectome measurement-error for yielding generalizable predictions. Hence, we hypothesized that incorporating known measurement error values of each connectome recipe (among those determined in the source and target domains to be optimal), might further boost classification performance if incorporated in a Bayesian transfer learning setting. Rather than recycle discriminability-based priors, which is a measure of global similarity, the incorporation of which would risk "double-dipping", we instead reverse-engineered known test-retest reliability ($ICC$) priors at the local (i.e. nodal) level, which we further weighted by their multiverse standard-deviations derived from the same previous study.

<!-- ::: {.center data-latex=""} -->
<!-- \begin{figure} -->
<!-- \centering -->
<!-- \includegraphics[width=\textwidth,height=\textheight,keepaspectratio=true,angle=270]{../figures/discrim_as_me_error-1.pdf} -->
<!-- \caption{\label{fig:discrim_as_me_errorR2MSE}\scriptsize{This figure is a star-plot that depicts the multiverse of R2/MSE benchmarks (y-axis) derived from the orthogonal predictions of distinct structural (right) and functional (left) connectome feature-spaces as a function of their known discriminability-error estimates. Here, "stars" are colored by the phenotype-associated recipe of connectome attribution (rumination=blue, depression=red), where shape is the temporality of that phenotype (circle=persistence, triangle=severity).}} -->
<!-- \end{figure} -->
<!-- ::: -->

::: {.center data-latex=""}
\begin{figure}
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio=true,angle=270]{../figures/discrim_as_me_error-2.pdf}
\caption{(Target Domain) \label{fig:discrim_as_me_errorCI}\scriptsize{This figure is a star-plot that depicts the multiverse of prediction confidence interval widths (y-axis) derived from the orthogonal R2/MSE bechmarks associated with distinct structural (right) and functional (left) connectome feature-spaces as a function of their known discriminability-error estimates. Here, "stars" are colored by the phenotype-associated recipe of connectome attribution (rumination=green, depression=grey), where shape is the temporality of that phenotype (circle=persistence, triangle=severity).}}
\end{figure}
\setlength{\belowcaptionskip}{-10pt}
:::

#### Phenotypic Affinity
Transferred functional connectome hyperpriors for rumination severity were:  $\beta \sim Normal(0, 0.56)$ and $\alpha \sim Normal(0, 0.54)$ for depression severity, $\beta \sim Normal(0, 0.64)$ and $\alpha \sim Uniform(0, 1.0)$. Transferred structural connectome hyperpriors for rumination persistence were: $\beta \sim Uniform(0, 1.0)$, and $\alpha \sim Uniform(0, 1.0)$ and for depression persistence, $\beta \sim Normal(0, 0.62)$ and $\alpha \sim Uniform(0, 1.0)$. All flat priors included $\beta \sim Normal(0, 10)$ and $\alpha \sim Uniform(0, 1)$.

```{r message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
# FUNC priors dict:
 # 'dep_1': {
 #  'inter': {'betas': ['norm', (0, 0.56)],
 #   'intercept': ['norm', (0, 0.54)]}},
 # 'rum_1': {
 #  'inter': {'betas': ['norm', (0, 0.635)],
 #   'intercept': ['uniform', (0.0, 1.0)]}},

# DWI priors dict:
# {'dep_persistence': {
#   'language': {'betas': ['norm', (0.0, 1.0)],
#    'intercept': ['uniform', (0.0, 1.0)]}},
#  'rum_persistence': {
#   'language': {'betas': ['norm', (0, 0.62)],
#    'intercept': ['uniform', (0.0, 1.0)]}}}}

# Instantiate priors
## Penalized LASSO-like "Horseshoe" prior
priors_pen1 <- c(prior(horseshoe(df = 1), class="b"), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"))
priors_pen2 <- c(prior(horseshoe(df = 1), class="b"), set_prior("normal(0, 1)", class = "Intercept"))

## Chronic Depression
priors_weak_func_chronic <- c(prior(normal(0, 10), class="b"), set_prior("normal(0, 1)", class = "b", coef = "Intercept"))
priors_func_dep_chronic <- c(prior(normal(0, 0.59), class="b"), set_prior("normal(0, 0.54)", class = "b", coef = "Intercept"))
priors_func_rum_chronic <- c(prior(normal(0, 0.63), class="b"), set_prior("uniform(0, 1.0)", class = "b", coef = "Intercept"))

priors_weak_dwi_chronic <- c(prior(normal(0, 10), class="b"), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"))
priors_dwi_dep_chronic <- c(prior(normal(0, 1), class="b"), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"))
priors_dwi_rum_chronic <- c(prior(normal(0, 0.62), class="b"), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"))

priors_weak_beh_chronic <- c(prior(normal(0, 10), class="b"), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"))

## Depression Conversion
priors_weak_func_conversion <- c(prior(normal(0, 10), class="b"), set_prior("normal(0, 1)", class = "b", coef = "Intercept"))
priors_func_dep_conversion <- c(prior(normal(0, 0.59), class="b"), set_prior("normal(0, 0.54)", class = "b", coef = "Intercept"))
priors_func_rum_conversion <- c(prior(normal(0, 0.63), class="b"), set_prior("uniform(0, 1.0)", class = "b", coef = "Intercept"))

priors_weak_dwi_conversion <- c(prior(normal(0, 10), class="b"), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"))
priors_dwi_dep_conversion <- c(prior(normal(0, 1), class="b"), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"))
priors_dwi_rum_conversion <- c(prior(normal(0, 0.62), class="b"), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"))

priors_weak_beh_conversion <- c(prior(normal(0, 10), class="b"), set_prior("uniform(0, 1)", class = "b", coef = "Intercept"))
```

Next, we proceed to evaluate the priors obtained from the source domain (and more generally from previous literature) in light of the present "evidence"---i.e. the dataset used for classifier evaluation in the target domain. Before estimating each logistic-regression model with MCMC, we therefore first considered a scenario with no predictors of each of the binary responses (i.e. depression conversion and chronic depression). This enabled us to estimate an optimal distribution of weights implied by choice of priors and likelihood. Ideally these distributions would have at least some mass centralized around all or most of the plausible data. We confirmed this through a series of prior predictive checks whereby the priors and likelihood were simulated for each classification scenario, and the resulting posterior distributions were subsequently evaluated.

```{r echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
setwd(base_dir)
# Chronic
X_chronic <- cbind(read.csv(paste(base_dir, 'data/TrainTest_set/X_BEH_chronic_stack-func_dwi_Beh.csv', sep='')), read.csv(paste(base_dir, 'data/TrainTest_set/X_DWI_chronic_stack-func_dwi.csv', sep='')), read.csv(paste(base_dir, 'data/TrainTest_set/X_FUN_chronic_stack-func_dwi_Beh.csv', sep='')))
y_chronic <- read.csv(paste(base_dir, 'data/TrainTest_set/y_chronic_stack-func_dwi_Beh.csv', sep=''))$MDE_chronic

Y <- y_chronic

df_chronic <- data.frame(cbind(center_apply(X_chronic), Y))

# Conversion
X_conv <- cbind(read.csv(paste(base_dir, 'data/TrainTest_set/X_BEH_conversion_stack-func_dwi_Beh.csv', sep='')), read.csv(paste(base_dir, 'data/TrainTest_set/X_DWI_conversion_stack-func_dwi_Beh.csv', sep='')), read.csv(paste(base_dir, 'data/TrainTest_set/X_FUN_conversion_stack-func_dwi_Beh.csv', sep='')))
y_conv <- read.csv(paste(base_dir, 'data/TrainTest_set/y_conversion_stack-func_dwi_Beh.csv', sep=''))$MDE_conversion

Y <- y_conv

df_conversion <- data.frame(cbind(center_apply(X_conv), Y))
```

### Comparing the Classifier Posterior Distributions of Prior-Attributed Connectome Models
Following prior predictive checks, we estimated separate Bayesian logistic regression models for classifying each of chronic depression and depression conversion using the selected functional connectome features, structural connectome features, behavioral features, and multimodal combination of features. For each of these models, we performed MCMC using Stan's default No U-Turn Sampler (NUTS)~\cite{STAN}, configured with the default 4 chains, 2000 warmup samples drawn to adapt sampling, and 5000 total iterations per chain while specifying several variations of priors---flat / weakly informative, informative (i.e. based on phenotypic affinity to rumination-persistence and depression persistence), and a "horseshoe" prior (i.e. a shrinkage distribution akin to lasso/ridge penalties in regularized regression).

```{r Prior_Pred_Checks_Chronic, fig.width = 10, fig.height=7, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, results="hide", cache=FALSE, eval=FALSE}
# Chronic
## Check func predictors case
### Weak / Flat Priors
prior_check_weak_func_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("func"), Y), "Flat Prior (Functional)", priors_weak_func_chronic, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_weak_func_chronic <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_weak_func_chronic)

### Penalized "Horseshoe" prior (Bayesian Elastic-Net equivalent)
prior_check_pen_func_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("func"), Y), "Horseshoe Prior (Functional)", priors_pen1, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

priors_pen_func_chronic <- priors_pen1

### Strong / Optimized to depression-persistence
prior_check_func_dep_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("func"), Y), "Depression-Persistence Prior (Functional)", priors_func_dep_chronic, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_func_dep_chronic <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_func_dep_chronic)

### Strong / Optimized to rumination-persistence
prior_check_func_rum_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("func"), Y), "Rumination-Persistence Prior (Functional)", priors_func_rum_chronic, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_func_rum_chronic <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_func_rum_chronic)

## Check dwi predictors case
### Weak / Flat Priors
prior_check_weak_dwi_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("dwi"), Y), "Flat Prior (Structural)", priors_weak_dwi_chronic, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_weak_dwi_chronic <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_weak_dwi_chronic)

### Penalized "Horseshoe" prior (Bayesian Elastic-Net equivalent)
prior_check_pen_dwi_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("dwi"), Y), "Horseshoe Prior (Structural)", priors_pen1, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

priors_pen_dwi_chronic <- priors_pen1

### Strong / Optimized to depression-persistence
prior_check_dwi_dep_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("dwi"), Y), "Depression-Persistence Prior (Structural)", priors_dwi_dep_chronic, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_dwi_dep_chronic <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_dwi_dep_chronic)

### Strong / Optimized to rumination-persistence
prior_check_dwi_rum_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("dwi"), Y), "Rumination-Persistence Prior (Structural)", priors_dwi_rum_chronic, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_dwi_rum_chronic <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_dwi_rum_chronic)

## Check behavioral predictors case
### Weak / Flat Priors
prior_check_weak_beh_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("Beh"), Y), "Flat Prior (Behavioral)", priors_weak_beh_chronic, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_weak_beh_chronic <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_weak_beh_chronic)

### Penalized "Horseshoe" prior (Bayesian Elastic-Net equivalent)
prior_check_pen_beh_chronic <- prior_predictive_check(df_chronic %>% dplyr::select(starts_with("Beh"), Y), "Horseshoe Prior (Behavioral)", priors_pen1, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

priors_pen_beh_chronic <- priors_pen1

do.call(grid.arrange, list(grobs=list(prior_check_weak_func_chronic[[1]], prior_check_func_dep_chronic[[1]], prior_check_func_rum_chronic[[1]], prior_check_weak_dwi_chronic[[1]], prior_check_dwi_dep_chronic[[1]], prior_check_dwi_rum_chronic[[1]]), layout_matrix = rbind(c(1, 2, 3), c(4, 5, 6)), top = textGrob("\nPrior Predictive Checks (Chronic Depression)",gp=gpar(fontsize=20,font=1))))
```

```{r MCMC_Models_Chronic, fig.width = 20, fig.height=20, message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, results="hide", cache=FALSE, eval=FALSE}
set.seed(42)
# FUNC-predictors-only model
## Weak / Flat Priors
fit_flat_func_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("func"), Y), family = brms::bernoulli(link='logit'), prior = priors_weak_func_chronic, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

## Penalized / "Horseshoe" Prior
fit_pen_func_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("func"), Y), family = brms::bernoulli(link='logit'), prior = priors_pen_func_chronic, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

## Strong Priors (dep)
fit_strong_dep_func_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("func"), Y), family = brms::bernoulli(link='logit'), prior = priors_func_dep_chronic, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

## Strong Priors (rum)
fit_strong_rum_func_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("func"), Y), family = brms::bernoulli(link='logit'), prior =  priors_func_rum_chronic, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

diag_weak_func_chronic <- diagnostic_check(fit_flat_func_chronic, 'Functional Connectome Predictors-Only, Flat Priors, (Chronic Depression)', 2)
diag_pen_func_chronic <- diagnostic_check(fit_pen_func_chronic, 'Functional Connectome Predictors-Only, "Horseshoe" Prior\n(Chronic Depression)', 2)
diag_strong_dep_func_chronic <- diagnostic_check(fit_strong_dep_func_chronic, 'Functional Connectome Predictors-Only, Strong Priors: Depression Persistence\n(Chronic Depression)', 2)
diag_strong_rum_func_chronic <- diagnostic_check(fit_strong_rum_func_chronic, 'Functional Connectome Predictors-Only, Strong Priors: Rumination Persistence\n(Chronic Depression)', 2)

# DWI-predictors-only model
## Weak / Flat Priors
fit_flat_dwi_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("dwi"), Y), family = brms::bernoulli(link='logit'), prior = priors_weak_dwi_chronic, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

## Penalized / "Horseshoe" Prior
fit_pen_dwi_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("dwi"), Y), family = brms::bernoulli(link='logit'), prior = priors_pen_dwi_chronic, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

## Strong Priors (dep)
fit_strong_dep_dwi_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("dwi"), Y), family = brms::bernoulli(link='logit'), prior = priors_dwi_dep_chronic, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

## Strong Priors (rum)
fit_strong_rum_dwi_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("dwi"), Y), family = brms::bernoulli(link='logit'), prior = priors_dwi_rum_chronic, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

diag_weak_dwi_chronic <- diagnostic_check(fit_flat_dwi_chronic, 'Structural Connectome Predictors-Only, Flat Priors, (Chronic Depression)', 2)
diag_pen_dwi_chronic <- diagnostic_check(fit_pen_dwi_chronic, 'Structural Connectome Predictors-Only, "Horseshoe" Prior\n(Chronic Depression)', 2)
diag_strong_dep_dwi_chronic <- diagnostic_check(fit_strong_dep_dwi_chronic, 'Structural Connectome Predictors-Only, Strong Priors: Depression Persistence\n(Chronic Depression)', 2)
diag_strong_rum_dwi_chronic <- diagnostic_check(fit_strong_rum_dwi_chronic, 'Structural Connectome Predictors-Only, Strong Priors: Rumination Persistence\n(Chronic Depression)', 2)

# Behavioral-predictors-only model
## Weak / Flat Priors
fit_flat_beh_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("Beh"), Y), family = brms::bernoulli(link='logit'), prior = priors_weak_beh_chronic, silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", save_pars = save_pars(all = TRUE), threads = threading(mc.cores), inits = inits)

## Penalized / "Horseshoe" Prior
fit_pen_beh_chronic <- brm(Y ~ 0 + Intercept + ., data = df_chronic %>% dplyr::select(starts_with("Beh"), Y), family = brms::bernoulli(link='logit'), prior = priors_pen_beh_chronic, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

diag_weak_beh_chronic <- diagnostic_check(fit_flat_beh_chronic, 'Behavioral Predictors-Only, Flat Priors\n(Chronic Depression)', 2)
diag_pen_beh_chronic <- diagnostic_check(fit_pen_beh_chronic, 'Behavioral Predictors-Only, "Horseshoe" Prior\n(Chronic Depression)', 2)

# do.call(grid.arrange, list(grobs=list(diag_weak_beh_chronic[[2]], diag_pen_beh_chronic[[2]]), ncol=2, top = textGrob("\nDiagnostic Checks---Trace Plots Behavioral Features (Chronic Depression)",gp=gpar(fontsize=20,font=1))))
# do.call(grid.arrange, list(grobs=list(diag_strong_dep_func_chronic[[2]], diag_strong_rum_func_chronic[[2]]), ncol=2, top = textGrob("\nDiagnostic Checks---Trace Plots Functional Connectomes (Chronic Depression)",gp=gpar(fontsize=20,font=1))))
# do.call(grid.arrange, list(grobs=list(diag_strong_dep_dwi_chronic[[2]], diag_strong_rum_dwi_chronic[[2]]), ncol=2, top = textGrob("\nDiagnostic Checks---Trace Plots Structural Connectomes (Chronic Depression)",gp=gpar(fontsize=20,font=1))))
```

```{r PPC_Comparisons_Chronic, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, results="hide", cache=FALSE, eval=FALSE}
# Func predictors
loo_fit_flat_func_chronic <- brms::loo(fit_flat_func_chronic, k_threshold=0.7, save_psis = TRUE)
loo_fit_pen_func_chronic <- brms::loo(fit_pen_func_chronic, k_threshold=0.7, save_psis = TRUE)
loo_fit_strong_dep_func_chronic <- brms::loo(fit_strong_dep_func_chronic, k_threshold=0.7, save_psis = TRUE)
loo_fit_strong_rum_func_chronic <- brms::loo(fit_strong_rum_func_chronic, k_threshold=0.7, save_psis = TRUE)
loo_func_chronic <- loo_compare(loo_fit_pen_func_chronic, loo_fit_flat_func_chronic, loo_fit_strong_dep_func_chronic, loo_fit_strong_rum_func_chronic)
func_best_chronic <- get(names(loo_func_chronic[,1])[[1]])
func_me_chronic <- add_me_to_model(func_best_chronic, df_chronic %>% dplyr::select(starts_with("func"), Y), icc_long_func)
func_me_chronic_flat <- add_me_to_model(func_best_chronic, df_chronic %>% dplyr::select(starts_with("func"), Y), null_compare = TRUE)
loo_func_me_chronic <- brms::loo(func_me_chronic, k_threshold=0.7, save_psis = TRUE)
loo_func_me_chronic_flat <- brms::loo(func_me_chronic_flat, k_threshold=0.7, save_psis = TRUE)
loo_comp_func_chronic_final <- loo_compare(loo_func_me_chronic, loo_func_me_chronic_flat)
loo_comp_func_chronic_final
func_chronic_perc_gain <- pergain(performance_summary(func_best_chronic)[[1]], performance_summary(func_me_chronic)[[1]])
out_func_perf_chronic <- performance_summary(get(names(loo_comp_func_chronic_final[,1])[[1]]))
bayesT_func_chronic_rum_dep <- bayes.t.test(fit_strong_rum_func_chronic, fit_strong_dep_func_chronic, "the rumination-attributed functional connectome features", "the depression-attributed functional connectome features", df_chronic, nsamples=1000)

# Dwi predictors
loo_fit_flat_dwi_chronic <- brms::loo(fit_flat_dwi_chronic, k_threshold=0.7, save_psis = TRUE)
loo_fit_pen_dwi_chronic <- brms::loo(fit_pen_dwi_chronic, k_threshold=0.7, save_psis = TRUE)
loo_fit_strong_dep_dwi_chronic <- brms::loo(fit_strong_dep_dwi_chronic, k_threshold=0.7, save_psis = TRUE)
loo_fit_strong_rum_dwi_chronic <- brms::loo(fit_strong_rum_dwi_chronic, k_threshold=0.7, save_psis = TRUE)
loo_dwi_chronic <- loo_compare(loo_fit_pen_dwi_chronic, loo_fit_flat_dwi_chronic, loo_fit_strong_dep_dwi_chronic, loo_fit_strong_rum_dwi_chronic)
dwi_best_chronic <- get(names(loo_dwi_chronic[,1])[[1]])
dwi_me_chronic <- add_me_to_model(dwi_best_chronic, df_chronic %>% dplyr::select(starts_with("dwi"), Y), icc_long_dwi)
dwi_me_chronic_flat <- add_me_to_model(dwi_best_chronic, df_chronic %>% dplyr::select(starts_with("dwi"), Y), null_compare = TRUE)
loo_dwi_me_chronic <- brms::loo(dwi_me_chronic, k_threshold=0.7, save_psis = TRUE)
loo_dwi_me_chronic_flat <- brms::loo(dwi_me_chronic_flat, k_threshold=0.7, save_psis = TRUE)
loo_comp_dwi_chronic_final <- loo_compare(loo_dwi_me_chronic, loo_dwi_me_chronic_flat)
loo_comp_dwi_chronic_final
dwi_chronic_perc_gain <- pergain(performance_summary(dwi_best_chronic)[[1]], performance_summary(dwi_me_chronic)[[1]])
out_dwi_perf_chronic <- performance_summary(get(names(loo_comp_dwi_chronic_final[,1])[[1]]))
bayesT_dwi_chronic_rum_dep <- bayes.t.test(fit_strong_rum_dwi_chronic, fit_strong_dep_dwi_chronic, "the rumination-attributed structural connectome features", "the depression-attributed structural connectome features", df_chronic, nsamples=1000)

# Behavioral predictors
loo_weak_beh_chronic <- brms::loo(fit_flat_beh_chronic, k_threshold=0.7, save_psis = TRUE)
loo_pen_beh_chronic <- brms::loo(fit_pen_beh_chronic, k_threshold=0.7, save_psis = TRUE)
loo_beh_chronic <- loo_compare(loo_weak_beh_chronic, loo_pen_beh_chronic)
beh_me_chronic <- add_me_to_model(get(names(loo_beh_chronic[,1])[[2]]), df_chronic %>% dplyr::select(starts_with("Beh"), Y))
beh_me_chronic_flat <- add_me_to_model(get(names(loo_beh_chronic[,1])[[2]]), df_chronic %>% dplyr::select(starts_with("Beh"), Y), null_compare = TRUE)
loo_beh_me_chronic <- brms::loo(beh_me_chronic, k_threshold=0.7, save_psis = TRUE)
loo_beh_me_chronic_flat <- brms::loo(beh_me_chronic_flat, k_threshold=0.7, save_psis = TRUE)
loo_beh_chronic_me <- loo_compare(loo_beh_me_chronic, loo_pen_beh_chronic, loo_beh_me_chronic_flat)
beh_best_chronic <- get(names(loo_beh_chronic_me[,1])[[1]])
loo_beh_best_chronic <- brms::loo(beh_best_chronic, k_threshold=0.7, save_psis = TRUE)
loo_comp_beh_chronic_final <- loo_compare(loo_beh_me_chronic, loo_beh_best_chronic)
loo_comp_beh_chronic_final
beh_chronic_perc_gain <- pergain(performance_summary(beh_best_chronic)[[1]], performance_summary(beh_me_chronic)[[1]])
out_beh_perf_chronic <- performance_summary(get(names(loo_comp_beh_chronic_final[,1])[[1]]))

# Compare best models per modality
loo_compare_all_models_chronic <- loo_compare(brms::loo(get(names(loo_comp_func_chronic_final[,1])[[1]])), brms::loo(get(names(loo_comp_dwi_chronic_final[,1])[[1]])), brms::loo(get(names(loo_comp_beh_chronic_final[,1])[[1]])))

# Stacking
epred_chronic_beh <- posterior_epred(get(names(loo_comp_beh_chronic_final[,1])[[1]]), nsamples=1000) %>% as_tibble() %>% summarise(across(everything(), mean))
epred_chronic_dwi <- posterior_epred(get(names(loo_comp_dwi_chronic_final[,1])[[1]]), nsamples=1000) %>% as_tibble() %>% summarise(across(everything(), mean))
epred_chronic_func <- posterior_epred(get(names(loo_comp_func_chronic_final[,1])[[1]]), nsamples=1000) %>% as_tibble() %>% summarise(across(everything(), mean))
```


```{r PPC_Comparisons_Chronic_stacked, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, results="hide", cache=FALSE, eval=FALSE}
stacked_dat_chronic <- cbind(t(epred_chronic_beh)[,1], t(epred_chronic_dwi)[,1], t(epred_chronic_func)[,1], df_chronic$Y) %>% as.tibble()

names(stacked_dat_chronic) <- c("beh", "dwi", "func", "Y")

## Flat priorf
stacked_chronic_bayes_flat <- brm(Y ~ dwi + func + beh, data = stacked_dat_chronic, family = brms::bernoulli(link='logit'), prior = set_prior("normal(0, 1)", class="b"), save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

## Horseshoe prior
stacked_chronic_bayes_pen <- brm(Y ~ dwi + func + beh, data = stacked_dat_chronic, family = brms::bernoulli(link='logit'), prior = priors_pen2, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

# ## Horseshoe prior ME
# stacked_chronic_bayes_pen_me <- brm(Y ~ me(dwi, 0.101) + me(func, 0.130) + me(beh, 0.2), data = stacked_dat_chronic, family = brms::bernoulli(link='logit'), prior = priors_pen2, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 16, inits = inits)

## Compare all
# stacked_chronic_loo_comp <- loo_compare(brms::loo(stacked_chronic_bayes_flat), brms::loo(stacked_chronic_bayes_pen), brms::loo(stacked_chronic_bayes_pen_me))
stacked_chronic_loo_comp <- loo_compare(brms::loo(stacked_chronic_bayes_flat), brms::loo(stacked_chronic_bayes_pen))
stacked_chronic_loo_comp

aucs_chronic_stacking <- get_bayes_auc(get(names(stacked_chronic_loo_comp[,1])[[1]]), stacked_dat_chronic$Y)

post_samples_chronic_stacked <- posterior_samples(get(names(stacked_chronic_loo_comp[,1])[[1]]))
```

```{r chronic_stacked_plot, message=FALSE, warning=FALSE, fig.width = 5, fig.height=5, fig.align="center", echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
pp_predictors_chronic <- post_samples_chronic_stacked %>%
  transmute(Intercept = b_Intercept,
            DWI       = b_dwi,
            FUNC      = b_func,
            BEHAVIORAL= b_beh) %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = value)) + 
  geom_histogram(aes(y = after_stat(density)), size = .2, bins = 40, color=pal_tron(alpha=0.75)(7)[2]) + 
  geom_density(color=pal_tron(alpha=0.75)(7)[1], size = .5) +
  scale_y_continuous(NULL, breaks = NULL) +
  ggtitle("Chronic") +
  DARK_THEME_GRAY +
  xlab(NULL) +
  theme(strip.text = element_text(size=18, colour="white"), axis.text.y=element_text(size=16, colour="white"), axis.text.x=element_text(size=16, colour="white"), axis.title=element_text(size=16, colour="white"), plot.background = element_rect(fill = "black"), panel.background = element_rect(fill = "black"), legend.key = element_rect(fill = "black")) + facet_wrap(~name, scales = "free", ncol = 2)

epred <- posterior_epred(get(names(stacked_chronic_loo_comp[,1])[[1]]), ndraws=100)
list_rocs <- list()
for (i in 1:100){
  list_rocs[[i]] <- roc(get(names(stacked_chronic_loo_comp[,1])[[1]])$data$Y, as.vector(as.matrix(as.data.frame(epred) %>% as.tibble())[i,]))
}

g_chronic <- ggroc(list_rocs, size = 0.5, aes=c("color"), legacy.axes = TRUE) + scale_colour_manual(values=rep(pal_tron(alpha=0.95)(7), times=100)) + geom_abline() +
    ggtitle(paste0('Chronic: E(AUC) = ', round(mean(aucs_chronic_stacking, na.rm=T), 3))) +
    xlab("Sensitivity") + ylab("Specificity") + DARK_THEME_GRAY + theme(axis.text.y=element_text(size=12, colour="white"), axis.text.x=element_text(size=12, colour="white"), plot.title=element_text(size=14, hjust=0.5), axis.title=element_text(size=14, colour="white"), legend.position="none", panel.border=element_blank(), plot.background = element_rect(fill = "black", colour = 'black')) + scale_fill_discrete(guide=FALSE) + 
      labs(tag = "B", colour = "white")

feats <- fixef(get(names(loo_comp_dwi_chronic_final[,1])[[1]]))
rois <- rownames(as.matrix(feats))
hubs <- cbind(rois, as_tibble(feats)) %>% mutate(Estimate = scale(Estimate)) %>% arrange(desc(abs(Estimate))) %>% filter(rois!="Intercept") %>% mutate(rois = gsub("dwi_", "", rois)) %>% mutate(rois = gsub("me", "", rois)) %>% select(-Est.Error) %>% dplyr::rename(., Hub = rois) %>% dplyr::rename(., `Std. Beta Weight` = Estimate) %>% select(-"Q2.5", -"Q97.5") %>% filter(abs(`Std. Beta Weight`)>0.1) %>% mutate(Hub = sapply(str_split(Hub, "_L"), function(x) x[1])) %>% mutate(Hub = sapply(str_split(Hub, "_R"), function(x) x[1]))

knitr::kable(hubs %>% mutate_if(is.numeric, format, digits=4), format = "latex", booktabs = TRUE) %>%
          kable_styling(latex_table_env = "tabular", latex_options = c("striped"), full_width = FALSE, position = "left", protect_latex = TRUE) %>% gsub("\\\\end\\{table\\}\n", "", .) %>% gsub("\n\\\\begin\\{table\\}", "", .) %>% gsub("\n\\\\centering", "", .) %>% gsub("\\_", "-", .) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% save_kable("hub_ranking_bayesian_model_chronic.tex")
```

```{r Prior_Pred_Checks_Conversion, fig.height=10, fig.width=10, message=FALSE, warning=FALSE, include=FALSE, results="hide", cache=FALSE, eval=FALSE}
# Conversion 
## Check func predictors case
### Weak / Flat Priors
prior_check_weak_func_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("func"), Y), "Flat Prior (Functional)", priors_weak_func_conversion, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_weak_func_conversion <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_weak_func_conversion)

### Penalized "Horseshoe" prior (Bayesian Elastic-Net equivalent)
prior_check_pen_func_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("func"), Y), "Horseshoe Prior (Functional)", priors_pen1, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

priors_pen_func_conversion <- priors_pen1

### Strong / Optimized to depression-persistence
prior_check_func_dep_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("func"), Y), "Depression-Persistence Prior (Functional)", priors_func_dep_conversion, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_func_dep_conversion <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_func_dep_conversion)

### Strong / Optimized to rumination-persistence
prior_check_func_rum_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("func"), Y), "Rumination-Persistence Prior (Functional)", priors_func_rum_conversion, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_func_rum_conversion <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_func_rum_conversion)

## Check dwi predictors case
### Weak / Flat Priors
prior_check_weak_dwi_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("dwi"), Y), "Flat Prior (Structural)", priors_weak_dwi_conversion, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_weak_dwi_conversion <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_weak_dwi_conversion)

### Penalized "Horseshoe" prior (Bayesian Elastic-Net equivalent)
prior_check_pen_dwi_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("dwi"), Y), "Horseshoe Prior (Structural)", priors_pen1, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

priors_pen_dwi_conversion <- priors_pen1

### Strong / Optimized to depression-persistence
prior_check_dwi_dep_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("dwi"), Y), "Depression-Persistence Prior (Structural)", priors_dwi_dep_conversion, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_dwi_dep_conversion <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_dwi_dep_conversion)

### Strong / Optimized to rumination-persistence
prior_check_dwi_rum_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("dwi"), Y), "Rumination-Persistence Prior (Structural)", priors_dwi_rum_conversion, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_dwi_rum_conversion <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_dwi_rum_conversion)

## Check behavioral predictors case
### Weak / Flat Priors
prior_check_weak_beh_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("Beh"), Y), "Flat Prior (Behavioral)", priors_weak_beh_conversion, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

#priors_weak_beh_conversion <- relieve_interaction_priors(Y ~ 0 + Intercept + ., priors_weak_beh_conversion)

### Penalized "Horseshoe" prior (Bayesian Elastic-Net equivalent)
prior_check_pen_beh_conversion <- prior_predictive_check(df_conversion %>% dplyr::select(starts_with("Beh"), Y), "Horseshoe Prior (Behavioral)", priors_pen1, sum_fun="mean", probs = c(0.05, 0.95), nsim=4000, Y ~ 0 + Intercept + .)

priors_pen_beh_conversion <- priors_pen1

do.call(grid.arrange, list(grobs=list(prior_check_weak_func_conversion[[1]], prior_check_func_dep_conversion[[1]], prior_check_func_rum_conversion[[1]], prior_check_weak_dwi_conversion[[1]], prior_check_dwi_dep_conversion[[1]], prior_check_dwi_rum_conversion[[1]]), layout_matrix = rbind(c(1, 2, 3), c(4, 5, 6)), top = textGrob("\nPrior Predictive Checks (Conversion  Depression)",gp=gpar(fontsize=20,font=1))))
```

```{r MCMC_Models_Conversion, fig.width = 20, fig.height=20, message=FALSE, warning=FALSE, include=FALSE, results="hide", cache=FALSE, eval=FALSE}
set.seed(42)
# FUNC-predictors-only model
## Weak / Flat Priors
fit_flat_func_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("func"), Y), family = brms::bernoulli(link='logit'), prior = priors_weak_func_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores))

## Penalized / "Horseshoe" Prior
fit_pen_func_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("func"), Y), family = brms::bernoulli(link='logit'), prior = priors_pen_func_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores))

## Strong Priors (dep)
fit_strong_dep_func_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("func"), Y), family = brms::bernoulli(link='logit'), prior = priors_func_dep_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores))

## Strong Priors (rum)
fit_strong_rum_func_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("func"), Y), family = brms::bernoulli(link='logit'), prior =  priors_func_rum_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores))

diag_weak_func_conversion <- diagnostic_check(fit_flat_func_conversion, 'Functional Connectome Predictors-Only, Flat Priors, (Depression Conversion)', 2)
diag_pen_func_conversion <- diagnostic_check(fit_pen_func_conversion, 'Functional Connectome Predictors-Only, "Horseshoe" Prior\n(Depression Conversion)', 2)
diag_strong_dep_func_conversion <- diagnostic_check(fit_strong_dep_func_conversion, 'Functional Connectome Predictors-Only, Strong Priors: Depression Persistence\n(Depression Conversion)', 2)
diag_strong_rum_func_conversion <- diagnostic_check(fit_strong_rum_func_conversion, 'Functional Connectome Predictors-Only, Strong Priors: Rumination Persistence\n(Depression Conversion)', 2)

# DWI-predictors-only model
## Weak / Flat Priors
fit_flat_dwi_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("dwi"), Y), family = brms::bernoulli(link='logit'), prior = priors_weak_dwi_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores))

## Penalized / "Horseshoe" Prior
fit_pen_dwi_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("dwi"), Y), family = brms::bernoulli(link='logit'), prior = priors_pen_dwi_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores))

## Strong Priors (dep)
fit_strong_dep_dwi_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("dwi"), Y), family = brms::bernoulli(link='logit'), prior = priors_dwi_dep_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores))

## Strong Priors (rum)
fit_strong_rum_dwi_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("dwi"), Y), family = brms::bernoulli(link='logit'), prior = priors_dwi_rum_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores))

diag_weak_dwi_conversion <- diagnostic_check(fit_flat_dwi_conversion, 'Structural Connectome Predictors-Only, Flat Priors\n(Depression Conversion)', 2)
diag_pen_dwi_conversion <- diagnostic_check(fit_pen_dwi_conversion, 'Structural Connectome Predictors-Only, "Horseshoe" Prior\n(Depression Conversion)', 2)
diag_strong_dep_dwi_conversion <- diagnostic_check(fit_strong_dep_dwi_conversion, 'Structural Connectome Predictors-Only, Strong Priors: Depression Persistence\n(Depression Conversion)', 2)
diag_strong_rum_dwi_conversion <- diagnostic_check(fit_strong_rum_dwi_conversion, 'Structural Connectome Predictors-Only, Strong Priors: Rumination Persistence\n(Depression Conversion)', 2)

# Behavioral-predictors-only model
## Weak / Flat Priors
fit_flat_beh_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("Beh"), Y), family = brms::bernoulli(link='logit'), prior = priors_weak_beh_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), warmup = 2000, iter = 6000, control=list(adapt_delta=0.99, max_treedepth=15), inits=inits)

## Penalized / "Horseshoe" Prior
fit_pen_beh_conversion <- brm(Y ~ 0 + Intercept + ., data = df_conversion %>% dplyr::select(starts_with("Beh"), Y), family = brms::bernoulli(link='logit'), prior = priors_pen_beh_conversion, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), warmup = 2000, iter = 6000, control=list(adapt_delta=0.99, max_treedepth=15), inits=inits)

diag_weak_beh_conversion <- diagnostic_check(fit_flat_beh_conversion, 'Behavioral Predictors-Only, Flat Priors\n(Depression Conversion)', 2)
diag_pen_beh_conversion <- diagnostic_check(fit_pen_beh_conversion, 'Behavioral Predictors-Only, "Horseshoe" Prior\n(Depression Conversion)', 2)

# do.call(grid.arrange, list(grobs=list(diag_weak_beh_conversion[[2]], diag_pen_beh_conversion[[2]]), ncol=2, top = textGrob("\nDiagnostic Checks---Trace Plots Behavioral Features (Depression Conversion)",gp=gpar(fontsize=20,font=1))))
# do.call(grid.arrange, list(grobs=list(diag_strong_dep_func_conversion[[2]], diag_strong_rum_func_conversion[[2]]), ncol=2, top = textGrob("\nDiagnostic Checks---Trace Plots Functional Connectomes (Depression Conversion)",gp=gpar(fontsize=20,font=1))))
# do.call(grid.arrange, list(grobs=list(diag_strong_dep_dwi_conversion[[2]], diag_strong_rum_dwi_conversion[[2]]), ncol=2, top = textGrob("\nDiagnostic Checks---Trace Plots Structural Connectomes (Depression Conversion)",gp=gpar(fontsize=20,font=1))))
```

```{r PPC_Comparisons_Conversion, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, results="hide", cache=FALSE, eval=FALSE}
# Func predictors
loo_fit_flat_func_conversion <- brms::loo(fit_flat_func_conversion, k_threshold=0.7, save_psis = TRUE)
loo_fit_pen_func_conversion <- brms::loo(fit_pen_func_conversion, k_threshold=0.7, save_psis = TRUE)
loo_fit_strong_dep_func_conversion <- brms::loo(fit_strong_dep_func_conversion, k_threshold=0.7, save_psis = TRUE)
loo_fit_strong_rum_func_conversion <- brms::loo(fit_strong_rum_func_conversion, k_threshold=0.7, save_psis = TRUE)
loo_func_conversion <- loo_compare(loo_fit_pen_func_conversion, loo_fit_flat_func_conversion, loo_fit_strong_dep_func_conversion, loo_fit_strong_rum_func_conversion)
#func_best_conversion <- get(names(loo_func_conversion[,1])[[1]])
func_best_conversion <- get(names(loo_func_conversion[,1])[!grepl("pen", names(loo_func_conversion[,1]))][[1]])
func_me_conversion <- add_me_to_model(func_best_conversion, df_conversion %>% dplyr::select(starts_with("func"), Y), icc_long_func)
func_me_conversion_flat <- add_me_to_model(func_best_conversion, df_conversion %>% dplyr::select(starts_with("func"), Y), null_compare = TRUE)
loo_func_me_conversion <- brms::loo(func_me_conversion, k_threshold=0.7, save_psis = TRUE)
loo_func_me_conversion_flat <- brms::loo(func_me_conversion_flat, k_threshold=0.7, save_psis = TRUE)
loo_comp_func_conversion_final <- loo_compare(loo_func_me_conversion, loo_func_me_conversion_flat)
loo_comp_func_conversion_final
func_conversion_perc_gain <- pergain(performance_summary(func_best_conversion)[[1]], performance_summary(func_me_conversion)[[1]])
out_func_perf_conversion <- performance_summary(get(names(loo_comp_func_conversion_final[,1])[[1]]))
bayesT_func_conversion_rum_dep <- bayes.t.test(fit_strong_rum_func_conversion, fit_strong_dep_func_conversion, "the rumination-attributed functional connectome features", "the depression-attributed functional connectome features", df_conversion, nsamples=1000)

# Dwi predictors
loo_fit_flat_dwi_conversion <- brms::loo(fit_flat_dwi_conversion, k_threshold=0.7, save_psis = TRUE)
loo_fit_pen_dwi_conversion <- brms::loo(fit_pen_dwi_conversion, k_threshold=0.7, save_psis = TRUE)
loo_fit_strong_dep_dwi_conversion <- brms::loo(fit_strong_dep_dwi_conversion, k_threshold=0.7, save_psis = TRUE)
loo_fit_strong_rum_dwi_conversion <- brms::loo(fit_strong_rum_dwi_conversion, k_threshold=0.7, save_psis = TRUE)
loo_dwi_conversion <- loo_compare(loo_fit_pen_dwi_conversion, loo_fit_flat_dwi_conversion, loo_fit_strong_dep_dwi_conversion, loo_fit_strong_rum_dwi_conversion)
dwi_best_conversion <- get(names(loo_dwi_conversion[,1])[[1]])
dwi_me_conversion <- add_me_to_model(fit_strong_rum_dwi_conversion, df_conversion %>% dplyr::select(starts_with("dwi"), Y), icc_long_dwi)
dwi_me_conversion_flat <- add_me_to_model(fit_strong_rum_dwi_conversion, df_conversion %>% dplyr::select(starts_with("dwi"), Y), null_compare = TRUE)
loo_dwi_me_conversion <- brms::loo(dwi_me_conversion, k_threshold=0.7, save_psis = TRUE)
loo_dwi_me_conversion_flat <- brms::loo(dwi_me_conversion_flat, k_threshold=0.7, save_psis = TRUE)
loo_comp_dwi_conversion_final <- loo_compare(loo_dwi_me_conversion, loo_dwi_me_conversion_flat)
loo_comp_dwi_conversion_final
dwi_conversion_perc_gain <- pergain(performance_summary(dwi_best_conversion)[[1]], performance_summary(dwi_me_conversion)[[1]])
out_dwi_perf_conversion <- performance_summary(get(names(loo_comp_dwi_conversion_final[,1])[[1]]))
bayesT_dwi_conversion_rum_dep <- bayes.t.test(fit_strong_rum_dwi_conversion, fit_strong_dep_dwi_conversion, "the depression-attributed structural connectome features", "the rumination-attributed structural connectome features", df_conversion, nsamples=1000)

# Behavioral predictors
loo_weak_beh_conversion <- brms::loo(fit_flat_beh_conversion, k_threshold=0.7, save_psis = TRUE)
loo_pen_beh_conversion <- brms::loo(fit_pen_beh_conversion, k_threshold=0.7, save_psis = TRUE)
loo_beh_conversion <- loo_compare(loo_weak_beh_conversion, loo_pen_beh_conversion)
beh_me_conversion <- add_me_to_model(get(names(loo_beh_conversion[,1])[[2]]), df_conversion %>% dplyr::select(starts_with("Beh"), Y))
beh_me_conversion_flat <- add_me_to_model(get(names(loo_beh_conversion[,1])[[2]]), df_conversion %>% dplyr::select(starts_with("Beh"), Y), null_compare = TRUE)
loo_beh_me_conversion <- brms::loo(beh_me_conversion, k_threshold=0.7, save_psis = TRUE)
loo_beh_me_conversion_flat <- brms::loo(beh_me_conversion_flat, k_threshold=0.7, save_psis = TRUE)
loo_beh_conversion2 <- loo_compare(loo_beh_me_conversion, loo_pen_beh_conversion, loo_beh_me_conversion_flat)
beh_best_conversion <- get(names(loo_beh_conversion2[,1])[[1]])
loo_beh_best_conversion <- brms::loo(beh_best_conversion, k_threshold=0.7, save_psis = TRUE)
loo_comp_beh_conversion_final <- loo_compare(loo_beh_me_conversion, loo_beh_best_conversion)
loo_comp_beh_conversion_final
beh_conversion_perc_gain <- pergain(performance_summary(beh_best_conversion)[[1]], performance_summary(beh_me_conversion)[[1]])
out_beh_perf_conversion <- performance_summary(get(names(loo_comp_beh_conversion_final[,1])[[1]]))

# Use Bayes Factor to Compare Conditions
# Compare best models per modality
loo_compare_all_models_conversion <- loo_compare(brms::loo(get(names(loo_comp_func_conversion_final[,1])[[1]])), brms::loo(get(names(loo_comp_dwi_conversion_final[,1])[[1]])), brms::loo(get(names(loo_comp_beh_conversion_final[,1])[[1]])))

epred_conversion_beh <- posterior_epred(get(names(loo_comp_beh_conversion_final[,1])[[1]]), nsamples=1000) %>% as_tibble() %>% summarise(across(everything(), mean))
epred_conversion_dwi <- posterior_epred(get(names(loo_comp_dwi_conversion_final[,1])[[1]]), nsamples=1000) %>% as_tibble() %>% summarise(across(everything(), mean))
epred_conversion_func <- posterior_epred(get(names(loo_comp_func_conversion_final[,1])[[1]]), nsamples=1000) %>% as_tibble() %>% summarise(across(everything(), mean))
```

```{r PPC_Comparisons_Conversion_stacked, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, results="hide", cache=FALSE, eval=FALSE}
stacked_dat_conversion <- cbind(t(epred_conversion_beh)[,1], t(epred_conversion_dwi)[,1], t(epred_conversion_func)[,1], df_conversion$Y) %>% as.tibble()

names(stacked_dat_conversion) <- c("beh", "dwi", "func", "Y")

## Flat prior
stacked_conversion_bayes_flat <- brm(Y ~ dwi + func + beh, data = stacked_dat_conversion, family = brms::bernoulli(link='logit'), prior = set_prior("normal(0, 1)", class="b"), save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

## Horseshoe prior
stacked_conversion_bayes_pen <- brm(Y ~ dwi + func + beh, data = stacked_dat_conversion, family = brms::bernoulli(link='logit'), prior = priors_pen2, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 4, backend = "cmdstanr", threads = threading(mc.cores), inits = inits)

## Horseshoe prior ME
#stacked_conversion_bayes_pen_me <- brm(Y ~ me(dwi, 0.101) + me(func, 0.130) + me(beh, 0.2), data = stacked_dat_conversion, family = brms::bernoulli(link='logit'), prior = priors_pen2, save_pars = save_pars(all = TRUE), silent=TRUE, seed=42, cores = 16, inits = inits)

## Compare all
#stacked_conversion_loo_comp <- loo_compare(brms::loo(stacked_conversion_bayes_flat), brms::loo(stacked_conversion_bayes_pen), brms::loo(stacked_conversion_bayes_pen_me))
stacked_conversion_loo_comp <- loo_compare(brms::loo(stacked_conversion_bayes_flat), brms::loo(stacked_conversion_bayes_pen))
stacked_conversion_loo_comp

aucs_conversion_stacking <- get_bayes_auc(get(names(stacked_conversion_loo_comp[,1])[[1]]), stacked_dat_conversion$Y)

post_samples_conversion_stacked <- posterior_samples(get(names(stacked_conversion_loo_comp[,1])[[1]]))
```

```{r conversion_stacked_plot, message=FALSE, warning=FALSE, fig.width = 5, fig.height=5, fig.align="center", echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
pp_predictors_conversion <- post_samples_conversion_stacked %>%
  transmute(Intercept = b_Intercept,
            DWI       = b_dwi,
            FUNC      = b_func,
            BEHAVIORAL= b_beh) %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = value)) + 
  geom_histogram(aes(y = after_stat(density)), size = .2, bins = 40, color=pal_tron(alpha=0.75)(7)[2]) + 
  geom_density(color=pal_tron(alpha=0.75)(7)[1], size = .5) +
  scale_y_continuous(NULL, breaks = NULL) +
  ggtitle("Conversion") +
  DARK_THEME_GRAY +
  xlab(NULL) +
  theme(strip.text = element_text(size=18, colour="white"), axis.text.y=element_text(size=16, colour="white"), axis.text.x=element_text(size=16, colour="white"), axis.title=element_text(size=16, colour="white"), plot.background = element_rect(fill = "black"), panel.background = element_rect(fill = "black"), legend.key = element_rect(fill = "black")) + facet_wrap(~name, scales = "free", ncol = 2)

epred <- posterior_epred(get(names(stacked_conversion_loo_comp[,1])[[1]]), ndraws=100)
list_rocs <- list()
for (i in 1:100){
  list_rocs[[i]] <- roc(get(names(stacked_conversion_loo_comp[,1])[[1]])$data$Y, as.vector(as.matrix(as.data.frame(epred) %>% as.tibble())[i,]))
}

g_conv <- ggroc(list_rocs, size = 0.5, aes=c("color"), legacy.axes = TRUE) + scale_colour_manual(values=rep(pal_tron(alpha=0.95)(7), times=100)) + geom_abline() +
    ggtitle(paste0('Conversion: E(AUC) = ', round(mean(aucs_conversion_stacking, na.rm=T), 3))) +
    xlab("Sensitivity") + ylab("Specificity") + DARK_THEME_GRAY + theme(axis.text.y=element_text(size=12, colour="white"), axis.text.x=element_text(size=12, colour="white"), plot.title=element_text(size=14, hjust=0.5), axis.title=element_text(size=14, colour="white"), legend.position="none", panel.border=element_blank(), plot.background = element_rect(fill = "black", colour = 'black')) + scale_fill_discrete(guide=FALSE) + 
      labs(tag = " ", colour = "white")

feats <- fixef(get(names(loo_comp_dwi_conversion_final[,1])[[1]]))
rois <- rownames(as.matrix(feats))
hubs <- cbind(rois, as_tibble(feats)) %>% mutate(Estimate = scale(Estimate)) %>% arrange(desc(abs(Estimate))) %>% filter(rois!="Intercept") %>% mutate(rois = gsub("dwi_", "", rois)) %>% mutate(rois = gsub("me", "", rois)) %>% select(-Est.Error) %>% dplyr::rename(., Hub = rois) %>% dplyr::rename(., `Std. Beta` = Estimate) %>% select(-"Q2.5", -"Q97.5") %>% filter(abs(`Std. Beta Weight`)>0.1) %>% mutate(Hub = sapply(str_split(Hub, "0"), function(x) x[1]))

knitr::kable(hubs %>% mutate_if(is.numeric, format, digits=4), format = "latex", booktabs = TRUE) %>%
          kable_styling(latex_table_env = "tabular", latex_options = c("striped"), full_width = FALSE, position = "left", protect_latex = TRUE) %>% gsub("\\\\end\\{table\\}\n", "", .) %>% gsub("\n\\\\begin\\{table\\}", "", .) %>% gsub("\n\\\\centering", "", .) %>% gsub("\\_", "-", .) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% gsub("(^|[[:space:]])([[:alpha:]])", "\\1\\U\\2", ., perl=TRUE) %>% save_kable("hub_ranking_bayesian_model_conversion.tex")
```

```{r all_comparisons, message=FALSE, warning=FALSE, fig.width = 20, fig.height=20, fig.align="center", echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
bayesian_chronic_stacking <- as.data.frame(aucs_chronic_stacking)
bayesian_chronic_stacking$Response <- "Chronic"
bayesian_chronic_stacking$Feature_Space <- "Bayesian"
bayesian_chronic_stacking$boot <- seq(1, 1000)
names(bayesian_chronic_stacking) <- c("AUC", "Response", "Feature_Space", "boot")

bayesian_conversion_stacking <- as.data.frame(aucs_conversion_stacking)
bayesian_conversion_stacking$Response <- "Conversion"
bayesian_conversion_stacking$Feature_Space <- "Bayesian"
bayesian_conversion_stacking$boot <- seq(1, 1000)
names(bayesian_conversion_stacking) <- c("AUC", "Response", "Feature_Space", "boot")

dat_bayesian_stacking <- bind_rows(bayesian_chronic_stacking,  bayesian_conversion_stacking) %>% as.tibble() %>% mutate_if(is.character, as.factor)

dat_stack <- data.frame(out_stacking_func_dwi_beh) %>% as.tibble() %>% mutate_if(is.character, as.factor)
dat_stack$Feature_Space <- 'Frequentist'

dat_all_multi <- data.frame(bind_rows(bind_rows(dat_bayesian_stacking, dat_stack)))
dat_all_mult_clean <- clean_pairs(dat_all_multi, facet='Response', subsample = 100)

out_all <- paired_compare(dat_all_mult_clean, "\nStacked Bayesian Vs. Frequentist Classification", "A", 'Response')

bf_auc <-ttestBF(x = dat_all_mult_clean %>% filter((Feature_Space=='Bayesian') & (Response=='Chronic')) %>% pull(AUC), y = dat_all_mult_clean %>% filter((Feature_Space=='Frequentist') & (Response=='Chronic')) %>% pull(AUC), paired=TRUE)
ci_auc <- ci(bf_auc, method = "HDI")
rope_auc <- rope(bf_auc, range = "default", ci = 1, ci_method = "HDI")
pd_val <- pd(bf_auc)$pd[1]
bayes_t_multi_chronic <- paste0("on the basis of 100 posterior draws of AUC, there was ", gsub(" against", "", effectsize::interpret_bf(exp(bf_auc@bayesFactor$bf), include_value = TRUE, protect_ratio=F, exact=F)[1]), " in favor of the stacked Bayesian multimodal model over the stacked frequentist multimodal model, which approached a ", round(100*pd_val, 4) ,"% probability of ",  get_pd_cat(pd_val)," within an 89% cred. interval [", round(ci_auc$CI_low, 3), round(ci_auc$CI_high, 3), "], and which was not ", effectsize::interpret_rope(rope_auc$ROPE_Percentage)[1], " evidence (approaching ", round(100*rope_auc$ROPE_Percentage, 4), "% in ROPE) against the null hypothesis of practical equivalence")

bf_auc <-ttestBF(x = dat_all_mult_clean %>% filter((Feature_Space=='Bayesian') & (Response=='Conversion')) %>% pull(AUC), y = dat_all_mult_clean %>% filter((Feature_Space=='Frequentist') & (Response=='Conversion')) %>% pull(AUC), paired=TRUE)
ci_auc <- ci(bf_auc, method = "HDI")
rope_auc <- rope(bf_auc, range = "default", ci = 1, ci_method = "HDI")
pd_val <- pd(bf_auc)$pd[1]
bayes_t_multi_conversion <- paste0("on the basis of 100 posterior draws of AUC, there was ", gsub(" against", "", effectsize::interpret_bf(exp(bf_auc@bayesFactor$bf), include_value = TRUE, protect_ratio=F, exact=F)[1]), " in favor of the stacked Bayesian multimodal model over the stacked frequentist multimodal model, which approached a ", round(100*pd_val, 4) ,"% probability of ",  get_pd_cat(pd_val)," within an 89% cred. interval [", round(ci_auc$CI_low, 3), round(ci_auc$CI_high, 3), "], and which was not ", effectsize::interpret_rope(rope_auc$ROPE_Percentage)[1], " evidence (approaching ", round(100*rope_auc$ROPE_Percentage, 4), "% in ROPE) against the null hypothesis of practical equivalence")
```

```{r all_comparisons_bayes, fig.width = 9.1, fig.height=10.1, fig.align="center", message=FALSE, warning=FALSE, echo=FALSE, include=FALSE, cache=FALSE, eval=FALSE}
grid.newpage()
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
plt <- do.call(grid.arrange, list(grobs=list(g_chronic, g_conv), vp=viewport(height=0.9, y = unit(0.3, "npc")), nrow=1, ncol=2, top = grobTree(rectGrob(gp=gpar(fill="black", color = "black", size = 0.2)), textGrob("Posterior Predictive Receiver Operating Characterics (ROC)\n", vjust=0.1, gp=gpar(fontsize=14, col="white")))))
grid.draw(plt)
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
grid.draw(plt)

grid.newpage()
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
plt2 <- do.call(grid.arrange, list(grobs=list(ggplotGrob(out_all[[1]]), plt), vp=viewport(height=0.8, width=0.9), nrow=2, ncol=1, top = grobTree(rectGrob(gp=gpar(fill="black", color = "black", size = 0.2)), textGrob("Bayesian Model-Based Transfer Learning Framework\n", vjust=0.1, gp=gpar(fontsize=16, col="white")))))
grid.draw(plt2)
grid.draw(grobTree(rectGrob(gp=gpar(fill="black", color="black", lwd = 0))))
grid.draw(plt2)
plt2
```

Following prior predictive checks, posterior estimation of each Bayesian logistic-regression classifier, convergence diagnostics, and posterior predict checks~\cite{Gabry2019}(see supplementary results \ref{A-posterior-predictive-checks-conversion}, \ref{A-mcmc-diagnostics-conversion}, \ref{A-prior-predictive-checks-conversion}, \ref{A-posterior-predictive-checks-chronic},\ref{A-prior-predictive-checks-chronic}, and \ref{A-mcmc-diagnostics-chronic}), we performed a series of model comparisons using LOO-CV~\cite{Vehtari2016} to evaluate the quality of each phenotypically-attributed set of informative priors, for each feature modality. Through this approach, we could perhaps determine whether priors associated with predicting a particular phenotype (i.e. rumination or depression/ severity or persistence) in the source domain was more or less beneficial for improving classification of those at risk of future depression onset or persistence. When using functional connectome features, we found that both sets of strong priors, optimized for each phenotype of interest (i.e. depression and rumination), outperformed equivalent models fitted with flat priors and a regularized horseshoe prior (i.e. a Bayesian "elastic-net"-equivalent). 

##### Functional
In the case of using functional connectome features, priors derived from predicting a rumination phenotype in particular outperformed the others for predicting both chronic and conversion outcomes ($\mathrm{\textit{E}}(\mathrm{\hat{\text{AUC}}})$=`r round(out_func_perf_chronic[[1]], 2)`; $\mathrm{\textit{E}}(\mathrm{\hat{\text{AUC}}})$=`r round(out_func_perf_conversion[[1]], 2)`), where the rankings in terms of the difference in expected log predictive density was as follows for classifying chronic (depression priors: $elpd$=`r round(as.data.frame(loo_func_chronic)$elpd_loo[[2]], 2)`, $SE$=`r round(as.data.frame(loo_func_chronic)$se_elpd_loo[[2]], 2)`), ("horseshoe" priors: $elpd$=`r round(as.data.frame(loo_func_chronic)$elpd_loo[[3]], 2)`, $SE$=`r round(as.data.frame(loo_func_chronic)$se_elpd_loo[[3]], 2)`), (flat priors: $elpd$=`r round(as.data.frame(loo_func_chronic)$elpd_loo[[4]], 2)`, $SE$=`r round(as.data.frame(loo_func_chronic)$se_elpd_loo[[4]], 2)`) and for classifying depression conversion: (depression priors: $elpd_{diff}$=`r round(as.data.frame(loo_func_conversion)$elpd_diff[[2]], 2)`, $SE_{diff}$=`r round(as.data.frame(loo_func_conversion)$se_diff[[2]], 2)`), ("horsehoe" priors: $elpd_{diff}$=`r round(as.data.frame(loo_func_conversion)$elpd_diff[[3]], 2)`, $SE_{diff}$=`r round(as.data.frame(loo_func_conversion)$se_diff[[3]], 2)`), (flat priors: $elpd_{diff}$=`r round(as.data.frame(loo_func_conversion)$elpd_diff[[4]], 2)`, $SE_{diff}$=`r round(as.data.frame(loo_func_conversion)$se_diff[[4]], 2)`). Further incorporating measurement-error priors for each respective functional connectome hub revealed a `r round(as.data.frame(loo_comp_func_chronic_final)$se_diff[[2]], 2)`-SE difference (chronic, $elpd$=`r round(as.data.frame(loo_comp_func_chronic_final)$elpd_loo[[1]], 2)`) and `r round(as.data.frame(loo_comp_func_conversion_final)$se_diff[[2]], 2)`-SE difference (conversion, $elpd$=`r round(as.data.frame(loo_comp_func_conversion_final)$elpd_loo[[1]], 2)`) in performance with predictive gains of `r func_chronic_perc_gain` and `r func_conversion_perc_gain` for classifying chronic and conversion, respectively. When performing Bayesian paired t-tests of the classifiers of chronic depression, we found that `r bayesT_func_chronic_rum_dep`. Similarly, for classifiers of depression conversion, we found that `r bayesT_func_conversion_rum_dep`.

##### Structural
Unlike with functional connectome features, in the structural case, optimal priors diverged for classifying chronic as compared to conversion. When classifying chronic, for instance, priors derived from predicting a rumination phenotype again outperformed the others ($\mathrm{\textit{E}}(\mathrm{\hat{\text{AUC}}})$ = `r round(out_dwi_perf_chronic[[1]], 2)`), where the rankings in terms of the difference in expected log predictive density proceeded as follows: (depression priors: $elpd$=`r round(as.data.frame(loo_dwi_chronic)$elpd_loo[[2]], 2)`, $SE$=`r round(as.data.frame(loo_dwi_chronic)$se_elpd_loo[[2]], 2)`), ("horsehoe" priors: $elpd$=`r round(as.data.frame(loo_dwi_chronic)$elpd_loo[[3]], 2)`, $SE$=`r round(as.data.frame(loo_dwi_chronic)$se_elpd_loo[[3]], 2)`), (flat priors: $elpd$=`r round(as.data.frame(loo_dwi_chronic)$elpd_loo[[4]], 2)`, $SE$=`r round(as.data.frame(loo_dwi_chronic)$se_elpd_loo[[4]], 2)`). When classifying conversion, on the other hand, the "horseshoe" prior-informed model was best ($\mathrm{\textit{E}}(\mathrm{\hat{\text{AUC}}})$=`r round(out_dwi_perf_conversion[[1]], 2)`). And this time, although the phenotypically-informative priors still improved predictive performance over and above the flat-prior model, the model informed with depression priors outperformed that informed with rumination priors (depression priors: $elpd_{diff}$=`r round(as.data.frame(loo_dwi_conversion)$elpd_diff[[2]], 2)`, $SE_{diff}$=`r round(as.data.frame(loo_dwi_conversion)$se_diff[[2]], 2)`), (rumination priors: $elpd_{diff}$=`r round(as.data.frame(loo_dwi_conversion)$elpd_diff[[3]], 2)`, $SE_{diff}$=`r round(as.data.frame(loo_dwi_conversion)$se_diff[[3]], 2)`), (flat priors: $elpd_{diff}$=`r round(as.data.frame(loo_dwi_conversion)$elpd_diff[[4]], 2)`, $SE_{diff}$=`r round(as.data.frame(loo_dwi_conversion)$se_diff[[4]], 2)`). Further incorporating measurement-error priors for each respective structural connectome hub revealed a `r round(as.data.frame(loo_comp_dwi_chronic_final)$se_diff[[2]], 2)`-SE difference (chronic, $elpd$=`r round(as.data.frame(loo_comp_dwi_chronic_final)$elpd_loo[[1]], 2)`) and `r round(as.data.frame(loo_comp_dwi_conversion_final)$se_diff[[2]], 2)`-SE difference (conversion, $elpd$=`r round(as.data.frame(loo_comp_dwi_conversion_final)$elpd_loo[[1]], 2)`) in performance with predictive gains of `r dwi_chronic_perc_gain` and `r dwi_conversion_perc_gain` for classifying chronic and conversion, respectively. When performing Bayesian paired t-tests of the classifiers of chronic depression, we found that `r bayesT_dwi_chronic_rum_dep`. Similarly, for classifiers of depression conversion, we found that `r bayesT_dwi_conversion_rum_dep`. 

See Table \ref{tab:bayesian_hubs_chronic} for a summary of the relative importance of structural connectome hubs used to classify chronic depression with Bayesian optimization. As indicated in the table, those hubs with largest feature importances (with respect to their connectivity to all other hubs in the LN), were the medial temporal gyrus(MTG), postcentral gyrus (PoG), inferior frontal gyrus (IFG), and the precuneus (Pcun).

::: {.center data-latex=""}
\begin{table}
    \centering
    \adjustbox{width=0.3\textwidth,keepaspectratio=true}{\subfile{Chapter_IV/results/hub_ranking_bayesian_model_chronic}}
    \caption{(Target Domain) \label{tab:bayesian_hubs_chronic}\scriptsize{This table summarizes the beta coefficients for each of the structural connectome hubs of the LN that were used to train a Bayesian logistic regression model of chronic depression. These weights, which have also been standardized, further reflect the boosting effect of transferring phenotypically-encoded hyperiors, along with the deconfounded influence of their associated measurement-errors priors. The neuroanatomical location for the named hubs in the first column were assigned by consensus-labeling~\cite{Craddock2013a} in PyNets, but ultimately names here using the Brainnetome Atlas~\cite{Fan2016}. Specifically, the acronyms, followed by an underscore _R and _L for their right/left disctinctions respectively, reflect the following regional mappings: the cingulate gyrus (CG), inferior frontal gyrus (IFG), inferior parietal lobe (IPL), superior parietal lobe (SPL), medial frontal gyrus (MFG), medial temporal gyrus (MTG), orbital frontal gyrus (OrG), paracentral gyrus (PCL, lower limb region) postcentral gyrus (PoG), precuneus (Pcun), orbitofrontal gyrus (OrG), and superior frontal gyrus (SFG).}}
\end{table}
\setlength{\belowcaptionskip}{-10pt}

\begin{sidewaysfigure}
\centering
\hspace{-2cm}
\includegraphics[width=\textheight,keepaspectratio=true]{Chapter_IV/figures/TrainTest_set_mosaic.png}
% \captionsetup{margin=-2.5cm}
  \caption{\label{fig:TrainTest_feature_imp_connectome}\scriptsize{This figure is a mosaic of connectome feature ``co-importance'' for nodes of the LN (structural, bottom row) subnetworks used to train bootstrapped classifiers. Nodes are annotated according to the Brainnetome atlas, and the size of each node is proportional to its relative importance for driving classification of each of the two definitions of future depression under investigation. Color brightness corresponds to the standard deviation of feature importance across bootstrapped predictions.}}
\end{sidewaysfigure}
\setlength{\belowcaptionskip}{-10pt}

\begin{sidewaysfigure}
\centering
\includegraphics[width=\textheight,keepaspectratio=true]{Chapter_IV/figures/anomaly_matrices_mosaic.pdf}
% \captionsetup{margin=-2.5cm}
\caption{\label{fig:AnomalyMatricesMosaic}\scriptsize{This figure depicts a set of feature co-importance anomaly matrices that correspond to the feature-importance connectome mappings depicted in Figure \ref{fig:TrainTest_feature_imp_connectome}. For each matrix of the eight shown, the x-axis lists each of the highest-importance (structural/functional) connectome hubs found to be most predictive of the indicated output variable, and the y-axis lists the same hubs such that the color intensity of their connectivity in the matrix (red=strongest, blue=weakest) reflects the degree of hub co-occurrence in the same bootstrapped feature-space. Whereas the top row depicts the raw anomaly matrices, the bottom row depicts a smoothed variant of the same as further estimated on the basis of the Network-Based Statistic (NBS)~\cite{Zalesky2010}}}
\end{sidewaysfigure}
\setlength{\belowcaptionskip}{-10pt}
:::

##### Multimodal
Although there was no phenotypically-relevant prior knowledge that was incorporated into the behavioral-features-only model, using the "horseshoe" prior did lend to improved prediction as compared to using the "flat" prior (Chronic: $\mathrm{\textit{E}}(\mathrm{\hat{\text{AUC}}})$=`r round(out_beh_perf_chronic[[1]], 2)`; $elpd$=`r round(as.data.frame(loo_beh_chronic)$elpd_loo[[2]], 2)`, $SE$=`r round(as.data.frame(loo_beh_chronic)$se_elpd_loo[[2]], 2)`; Conversion: $\mathrm{\textit{E}}(\mathrm{\hat{\text{AUC}}})$=`r round(out_beh_perf_conversion[[1]], 2)`; $elpd_{diff}$=`r round(as.data.frame(loo_beh_conversion)$elpd_diff[[2]], 2)`, $SE_{diff}$=`r round(as.data.frame(loo_beh_conversion)$se_diff[[2]], 2)`), and the measurement-error model. Nevertheless, the behavioral model outperformed the functional connectome model for classifying both outcomes (Chronic: $elpd$=`r round(as.data.frame(loo_compare_all_models_chronic)$elpd_loo[[2]]-as.data.frame(loo_compare_all_models_chronic)$elpd_loo[[3]], 2)`; Conversion: $elpd_{diff}$=`r round(as.data.frame(loo_compare_all_models_conversion)$elpd_diff[[2]]-as.data.frame(loo_compare_all_models_conversion)$elpd_diff[[3]], 3)`), though the posterior distributions of predicted probabilities were similar between the two and hinted that they may explain similar underlying variance. Further incorporating published measurement-error priors for each behavioral measure again yielded a `r round(as.data.frame(loo_comp_func_chronic_final)$se_diff[[2]], 2)`-SE difference (Chronic, $elpd$=`r round(as.data.frame(loo_comp_func_chronic_final)$elpd_loo[[1]], 2)`) and a `r round(as.data.frame(loo_comp_beh_conversion_final)$se_diff[[2]], 2)`-SE difference (Conversion, $elpd$=`r round(as.data.frame(loo_comp_beh_conversion_final)$elpd_loo[[1]], 2)`) in performance, with associated performance gains of `r func_chronic_perc_gain` and `r beh_conversion_perc_gain` for chronic and conversion, respectively. Finally, when stacking the best model identified for each modality into hierarchical ensembles, in a similar spirit to that performed in the frequentist context, we again found that this approach outperformed each of the unimodal models for classifying both outcomes (Chronic: $\mathrm{\textit{E}}(\mathrm{\hat{\text{AUC}}})$=`r round(mean(aucs_chronic_stacking[[1]]), 2)`; Conversion: $\mathrm{\textit{E}}(\mathrm{\hat{\text{AUC}}})$=`r round(mean(aucs_conversion_stacking[[1]]), 2)`, see bottom row of Figure \ref{fig:all_comparisons_bayes})) and that incorporating the "horseshoe" prior on the super-learner improved model performance over and above using a flat prior as well (Chronic: $elpd$=`r round(as.data.frame(stacked_chronic_loo_comp)$elpd_loo[[2]], 2)`, $elpd$=`r round(as.data.frame(stacked_chronic_loo_comp)$se_elpd_loo[[2]], 2)`; Conversion: $elpd_{diff}$=`r round(as.data.frame(stacked_conversion_loo_comp)$elpd_diff[[2]], 2)`, $SE_{diff}$=`r round(as.data.frame(stacked_conversion_loo_comp)$se_diff[[2]], 2)`).

#### Does a stacked Bayesian model improve classification performance beyond that achieved from the stacked frequentist model?

Finally, we (informally) compared the best stacked classifiers attained from the non-Bayesian (i.e. "frequentist") framework with those attained from the Bayesian framework. This was only a "pseudo-comparison" because the distributions of AUC for the latter were posterior samples rather than bootstraps, and hence the comparisons were not technically paired either. Still, this final test provided a helpful way of conceptualizing the impact of transferring learning directly via the use of strongly-informed priors and indirectly via feature-space rankings with mostly arbitrary cut-points. In general, the range of bootstrapped ROC AUC among the frequentist classifiers was much wider (`r paste0("[", toString(range(dat_stack %>% pull(AUC)) %>% round(3)), "]")`) than that of the posterior distribution of ROC AUC sampled from the Bayesian classifiers (`r paste0("[", toString(range(dat_bayesian_stacking %>% pull(AUC)) %>% round(3)), "]")`). Furthermore, the results showed that including rumination and depression priors as a form of direct model-based transfer learning further benefited prediction over and above that achieved through feature-based transfer learning alone (see bottom rows of Figure \ref{fig:all_comparisons_bayes}). This could be observed using both frequentist corrected paired t-testing and Bayesian paired t-testing, and when classifying chronic depression and depression conversion. For predicting chronic, this amounted to a `r pergain(round(mean(dat_all_multi %>% filter(Response=="Chronic", Feature_Space=="Frequentist") %>% pull(AUC), na.rm=TRUE), 3), round(mean(dat_all_multi %>% filter(Response=="Chronic", Feature_Space=="Bayesian") %>% pull(AUC), na.rm=TRUE), 3))` gain in AUC (paired t(`r as.integer(out_all[[2]]$df)`) = `r out_all[[2]]$t_stat %>% round(2)`, 95% CI [`r out_all[[2]]$conf.int[1] %>% round(3)`, `r out_all[[2]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_all[[2]]$p, digits = 3, prefix = NULL)`)). Expressed in terms of Bayes Factor, `r bayes_t_multi_chronic`. For predicting conversion, this amounted to a `r pergain(round(mean(dat_all_multi %>% filter(Response=="Conversion", Feature_Space=="Frequentist") %>% pull(AUC), na.rm=TRUE), 3), round(mean(dat_all_multi %>% filter(Response=="Conversion", Feature_Space=="Bayesian") %>% pull(AUC), na.rm=TRUE), 3))` gain in AUC (paired t(`r as.integer(out_all[[3]]$df)`) = `r out_all[[3]]$t_stat %>% round(2)`, 95% CI [`r out_all[[3]]$conf.int[1] %>% round(3)`, `r out_all[[3]]$conf.int[2] %>% round(3)`], *p* = `r finalfit::p_tidy(out_all[[3]]$p, digits = 3, prefix = NULL)`). Expressed in terms of Bayes Factor, `r bayes_t_multi_conversion`.

::: {.center data-latex=""}
\begin{figure}
\centering
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio=true]{../figures/all_comparisons_bayes-4.pdf}
\caption{(Target Domain) \label{fig:all_comparisons_bayes}\scriptsize{The figure mosaic is a Bayesian Transfer Learning (TL) variant of the frequentist bootstrapped paired comparisons summaries in Figure \ref{fig:all_comparison_freq}, that were accordingly evaluated within a Bayesian framework for model evaluation that helped to triangulate the findings made in the frequentist case. Namely, paired comparisons were conducted on the basis of Bayesian paired t-tests with Bayes factor and Leave-One-Out (LOO) log predictive density~\cite{Vehtari2016,Gelman2013} using N=100 posterior draws of ROC AUC from Bayesian logistic regression classifiers of chronic depression and depression conversion, trained the same underlying connectome features as those used in Figures \ref{fig:all_comparison_freqA} and \ref{fig:all_comparison_freqC}. Aside from leveraging alternative benchmarks of model evaluation, the Bayesian case permitted an extension of model-based TL through the use of prior distributions~\cite{Chandra2020,Yang2020} available for best-performing connectome feature recipes identified from the frequentist classifier comparisons. More specifically, these priors comprised measurement-error priors of connectome hubs learned from a previous reproducibility benchmarking study~\cite{Pisner2021a} and model coefficient hyperpriors learned from the frequentist elastic-net models learned in the source domain. In this context, the Bayesian variant of null models (akin to those used in the frequentist, feature-based TL case shown in \ref{fig:all_comparison_freqC}) amounted to "flat priors" (i.e. an uninformed, uniform distribution). After comparative evaluations again revealed the benefit of transferring phenotypic knowledge of rumination persistence for classifying those at risk of chronic depression, the incremental and combined addition of a "horseshoe" prior shrinkage~\cite{Carvalho2009} akin to the elastic-net, multimodal model stacking~\cite{Yao2018} across structural, functional, and behavioral modalities, and the measurement error penalties all substantially boosted prediction~\cite{Richardson1993}. In fact, the Bayesian model outperformed the frequentist by `r pergain(round(mean(dat_all_multi %>% filter(Response=="Chronic", Feature_Space=="Frequentist") %>% pull(AUC), na.rm=TRUE), 3), round(mean(dat_all_multi %>% filter(Response=="Chronic", Feature_Space=="Bayesian") %>% pull(AUC), na.rm=TRUE), 3))`. As in the plots of \ref{fig:all_comparison_freq}, plot A is again faceted by outcome type (albeit any direct comparison of AUC distributions across outcome types would be inappropriate since they are not paired). The bottom plot (B) consists of two Bayesian ROC curves that depicts the log predictive density of AUC for classifying chronic (left) and conversion (right) (where the variety of overlaid curve line colors correspond to separate posterior draws). In both cases, sensitivity is shown along the x-axis and represents the proportion of those who were correctly identifying as being chronic (left) and converted (right), whereas specificity is shown along the y-axis and represents the proportion of those who were correctly identified as being episodic (left) and remained healthy (right), respectively.}}
\end{figure}
\setlength{\belowcaptionskip}{-10pt}
:::

For results from additional exploratory (frequentist) comparisons (e.g. logistic regression vs. `dummy' regression, TN/LN subgraphical connectomes vs. whole-brain connectomes, structural vs. functional connectomes, learned connectomes vs. graph-free learned signal), see supplemental results~\ref{exploratory_frequentist_tests}.

```{r eval=FALSE, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
rm(list = ls()[grep("plt", ls())])
rm(list = ls()[grep("diag_", ls())])
save.image(paste(root.dir, "/../AllCache_bayesian.RData", sep = ''))
```
